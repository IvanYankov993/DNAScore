{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "00f409cc-b28b-4f92-91bd-2bcd05c1d1d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "from sklearn.model_selection import ShuffleSplit\n",
    "from sklearn.model_selection import KFold"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73ff8cdc-b760-444f-868a-d9c2f72dbae7",
   "metadata": {},
   "source": [
    "# DataBlock"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 348,
   "id": "3711ab8c-b3aa-464c-ba13-eb499db92665",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/users/qdb16186/CNN_stk'"
      ]
     },
     "execution_count": 348,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "home=os.getcwd()\n",
    "home"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "edb56de3-474d-4cb4-a79b-d953fc57c674",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### MAC sklearn for CNN\n",
    "\n",
    "###set global variables\n",
    "# train test split\n",
    "test_frac = 0.3\n",
    "mc_cv=50\n",
    "n_folds=5\n",
    "n_jobs=1\n",
    "epochs=200\n",
    "grid_number=1\n",
    "# Initialise train test split:\n",
    "train_test_split = ShuffleSplit(mc_cv, test_size=test_frac, random_state=1)\n",
    "train_test_split_hp = ShuffleSplit(1, test_size=test_frac, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 498,
   "id": "b3c58e12-040d-4ba8-9917-1e42fc2a0a2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "prop='Granulated' \n",
    "GSHT='dH'\n",
    "file=pd.read_csv(\"/users/qdb16186/CNN_stk/Lomzov_dataset_IY.csv\")\n",
    "# obtain y and x data\n",
    "# y_1, y_2, y_3, y_4, x, X= load_data(file,prop)\n",
    "desc_type = ['Granulated','OHEP','LP_dec2','DNA-Groups']\n",
    "GSHT_list=['dH','dS','dG','Tm'] #get the order correct"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b22ddced-900b-4b49-a5d8-08070bd4fffb",
   "metadata": {},
   "source": [
    "# Data CV Block\n",
    "\n",
    "to adjust CV and hyper parameter setup access:\n",
    "cv_hp,\n",
    "adjust test_size and shuffle split\n",
    "<!--  -->\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 349,
   "id": "b9fb3a9b-5b58-4887-b805-309a4dfae8ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "def path_fold(home,resample,i_fold):\n",
    "    path=\"{}/CV/{}/fold_{}\".format(os.getcwd(),resample,i_fold)\n",
    "        \n",
    "    # Define the directory path\n",
    "    directory_path = Path(f\"{home}/CV/{resample}/{i_fold}\")\n",
    "    \n",
    "    # Ensure the directory exists, create it if necessary\n",
    "    directory_path.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    return directory_path\n",
    "\n",
    "def path_resample(home,resample):\n",
    "    path=\"{}/CV/{}/\".format(os.getcwd(),resample)\n",
    "        \n",
    "    # Define the directory path\n",
    "    directory_path = Path(f\"{home}/CV/{resample}\")\n",
    "    \n",
    "    # Ensure the directory exists, create it if necessary\n",
    "    directory_path.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    return directory_path\n",
    "\n",
    "def cv_hp(df,home):\n",
    "    resample_split  = ShuffleSplit(50, test_size=0.3, random_state=1)\n",
    "    fold_split      = ShuffleSplit(5 , test_size=0.3, random_state=1)\n",
    "    train_val_split = ShuffleSplit(1 , test_size=0.3, random_state=1)\n",
    "    \n",
    "    for resample, (train_val_index, test_index) in enumerate(resample_split.split(df)):\n",
    "        train_val = pd.DataFrame(df['ID'].iloc[train_val_index])\n",
    "        test = pd.DataFrame(df['ID'].iloc[test_index])\n",
    "        for i, (train_index, val_index) in enumerate(train_val_split.split(train_val)):\n",
    "            train = pd.DataFrame(df['ID'].iloc[train_index])\n",
    "            val   = pd.DataFrame(df['ID'].iloc[val_index])\n",
    "        resample_path = path_resample(home,resample)\n",
    "        train.to_csv(f'{resample_path}/train.csv')\n",
    "        val.to_csv(f'{resample_path}/val.csv')\n",
    "        test.to_csv(f'{resample_path}/test.csv')\n",
    "        # train,val,test to_csv\n",
    "        for i_fold, (train_val_fold_index, test_fold_index) in enumerate(fold_split.split(train)):\n",
    "            train_val_fold = pd.DataFrame(train['ID'].iloc[train_val_fold_index])\n",
    "            test_fold = pd.DataFrame(train['ID'].iloc[test_fold_index])\n",
    "            for i, (train_fold_index, val_fold_index) in enumerate(train_val_split.split(train_val_fold)):\n",
    "                train_fold = pd.DataFrame(train_val_fold['ID'].iloc[train_fold_index])\n",
    "                val_fold   = pd.DataFrame(train_val_fold['ID'].iloc[val_fold_index])\n",
    "            i_fold_path = path_fold(home,resample,i_fold)\n",
    "            train_fold.to_csv(f'{i_fold_path}/train.csv')\n",
    "            val_fold.to_csv(f'{i_fold_path}/val.csv')\n",
    "            test_fold.to_csv(f'{i_fold_path}/test.csv')\n",
    "            \n",
    "\n",
    "    return print(\"data organised into 50 CV with 5-fold inner CV\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 350,
   "id": "51d7ecf5-81e0-463d-aa55-57a8303af23a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data organised into 50 CV with 5-fold inner CV\n"
     ]
    }
   ],
   "source": [
    "df=pd.read_csv(\"Lomzov_dataset_IY.csv\")\n",
    "home=os.getcwd()\n",
    "# pathlib.Path(\"Lomzov_dataset_IY.csv\").parent.absolute()\n",
    "cv_hp(df,home)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1aee8447-32fa-4d77-91ea-cb2542568a68",
   "metadata": {},
   "source": [
    "# Accessing Data Via ID CV and full table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0c51f375-0739-4ab2-b551-8c13630d1e96",
   "metadata": {},
   "outputs": [],
   "source": [
    "def access_fold_csv(df,home,resample,fold):\n",
    "    df_path = path_fold(home,resample,fold)\n",
    "    train_df=pd.read_csv(f'{df_path}/train.csv')\n",
    "    val_df=pd.read_csv(f'{df_path}/val.csv')\n",
    "    test_df=pd.read_csv(f'{df_path}/test.csv')\n",
    "\n",
    "    train_df=df[df[\"ID\"].isin(train_df['ID'])]\n",
    "    val_df=df[df[\"ID\"].isin(val_df['ID'])]\n",
    "    test_df=df[df[\"ID\"].isin(test_df['ID'])]\n",
    "    return train_df, val_df, test_df\n",
    "\n",
    "\n",
    "def access_resample_csv(df,home,resample):\n",
    "    df_path = path_resample(home,resample)\n",
    "    train_df=pd.read_csv(f'{df_path}/train.csv')\n",
    "    val_df=pd.read_csv(f'{df_path}/val.csv')\n",
    "    test_df=pd.read_csv(f'{df_path}/test.csv')\n",
    "\n",
    "    train_df=df[df[\"ID\"].isin(train_df['ID'])]\n",
    "    val_df=df[df[\"ID\"].isin(val_df['ID'])]\n",
    "    test_df=df[df[\"ID\"].isin(test_df['ID'])]\n",
    "    return train_df, val_df, test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "296e27f5-635d-4c36-8414-e2d48d4d4641",
   "metadata": {},
   "outputs": [],
   "source": [
    "resample=1\n",
    "fold=1\n",
    "train_fold, val_fold, test_fold = access_resample_csv(df,home,resample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "76831e65-af11-4af3-a091-e46bfabec4ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(149, 383) (64, 383) (92, 383)\n",
      "305\n"
     ]
    }
   ],
   "source": [
    "print(train_fold.shape, val_fold.shape, test_fold.shape)\n",
    "# train_fold.shape\n",
    "print(train_fold.shape[0] + val_fold.shape[0] + test_fold.shape[0])\n",
    "# train_fold.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25e502d7-3c87-4963-9e18-d03b40519dfb",
   "metadata": {},
   "source": [
    "# Load X, Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "01cefe09-de92-4703-86c8-f26bda05a934",
   "metadata": {},
   "outputs": [],
   "source": [
    "def padding(X_descr_train_scaled):\n",
    "#     Padding function so X data is always 250 dimensions\n",
    "# Must be coupled with load_data. NB! double check if the scalling is not affected\n",
    "# https://www.geeksforgeeks.org/python-call-function-from-another-function/\n",
    "    a=X_descr_train_scaled.to_numpy()\n",
    "    b=np.zeros((len(X_descr_train_scaled), \n",
    "                (250-int(X_descr_train_scaled.to_numpy().shape[1]))\n",
    "               )\n",
    "              )\n",
    "    padded=np.concatenate((a,b),\n",
    "                           axis=1, \n",
    "                          out=None, \n",
    "                          dtype=None\n",
    "                         )\n",
    "    return padded\n",
    "\n",
    "\n",
    "def load_xy(file,desc):\n",
    "    # Universal funciton for loading\n",
    "# y_1, y_2, y_3, y_4 and x data from input csv (All, Train, Val or Train)\n",
    "    y_1 = file[['dH']].copy()\n",
    "    y_2 = file[['dS']].copy()\n",
    "    y_3 = file[['dG']].copy()\n",
    "    y_4 = file[['Tm']].copy()\n",
    "\n",
    "    Y = file[['dH','dS','dG','Tm']].copy()\n",
    "    # Convert y data into required input shape\n",
    "    y_1 = y_1.to_numpy()\n",
    "    y_1 = y_1.reshape(y_1.shape[0])\n",
    "    y_2 = y_2.to_numpy()\n",
    "    y_2 = y_2.reshape(y_2.shape[0])\n",
    "    y_3 = y_3.to_numpy()\n",
    "    y_3 = y_3.reshape(y_3.shape[0])\n",
    "    y_4 = y_4.to_numpy()\n",
    "    y_4 = y_4.reshape(y_4.shape[0])\n",
    "    \n",
    "    # Load features based on prop\n",
    "    X = file[[col for col in file.columns if f'{desc}_'in col]]\n",
    "    \n",
    "    return y_1, y_2, y_3, y_4, Y, padding(X), X\n",
    "\n",
    "    \n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "68497666-4046-45b3-a0d6-d2a909c16387",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data organised into 50 CV with 5-fold inner CV\n"
     ]
    }
   ],
   "source": [
    "df=pd.read_csv(\"Lomzov_dataset_IY.csv\")\n",
    "home=os.getcwd()\n",
    "# pathlib.Path(\"Lomzov_dataset_IY.csv\").parent.absolute()\n",
    "cv_hp(df,home)\n",
    "\n",
    "resample=1\n",
    "fold=1\n",
    "train, val, test = access_resample_csv(df,home,resample)\n",
    "train_fold, val_fold, test_fold = access_fold_csv(df,home,resample,fold)\n",
    "\n",
    "desc='RF-Score'\n",
    "y_1_train, y_2_train, y_3_train, y_4_train, Y_train, X_padded_train, X_train = load_xy(train_fold,desc)\n",
    "y_1_val,   y_2_val,   y_3_val,   y_4_val,   Y_val,   X_padded_val,   X_val   = load_xy(val_fold,desc)\n",
    "y_1_test,  y_2_test,  y_3_test,  y_4_test,  Y_test,  X_padded_test,  X_test  = load_xy(test_fold,desc)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8140c06f-b69b-4f3f-8e93-6d2926c495e1",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "54c58c59-e802-473b-ab29-39d42f0bbcd3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-26 17:02:47.949161: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-01-26 17:02:51.460543: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-01-26 17:02:51.461625: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-01-26 17:03:20.110481: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import keras_tuner as kt\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import Input, Model\n",
    "from tensorflow.keras import layers, models, initializers, optimizers\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, CSVLogger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "14b55184-ec57-431b-9bd1-b09ea4fdf130",
   "metadata": {},
   "outputs": [],
   "source": [
    "def r2_func(y_true, y_pred, **kwargs):\n",
    "    return metrics.r2_score(y_true, y_pred)\n",
    "def rmse_func(y_true, y_pred, **kwargs):\n",
    "    return np.sqrt(metrics.mean_squared_error(y_true, y_pred))  \n",
    "def bias_func(y_true, y_pred, **kwargs):\n",
    "    return np.mean(y_true-y_pred)\n",
    "def sdep_func(y_true, y_pred, **kwargs):\n",
    "    return (np.mean((y_true-y_pred-(np.mean(y_true-y_pred)))**2))**0.5\n",
    "#these 4 are for tensorflow formats\n",
    "def r2_func_tf(y_true, y_pred, **kwargs):\n",
    "    numerator = tf.reduce_sum(tf.square(y_true - y_pred))\n",
    "    denominator = tf.reduce_sum(tf.square(y_true - tf.reduce_mean(y_true)))\n",
    "    r2 = 1 - numerator / denominator\n",
    "    return r2\n",
    "def rmse_func_tf(y_true, y_pred, **kwargs):\n",
    "    mse = tf.reduce_mean(tf.square(y_true - y_pred))\n",
    "    rmse = tf.sqrt(mse)\n",
    "    return rmse\n",
    "def bias_func_tf(y_true, y_pred, **kwargs):\n",
    "    bias = tf.reduce_mean(y_true - y_pred)\n",
    "    return bias\n",
    "def sdep_func_tf(y_true, y_pred, **kwargs):\n",
    "    diff = y_true - y_pred\n",
    "    mean_diff = tf.reduce_mean(diff)\n",
    "    sdep = tf.sqrt(tf.reduce_mean(tf.square(diff - mean_diff)))\n",
    "    return sdep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "022c3085-8784-483f-9dc3-db7bc292e70b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def build_model(hp):\n",
    "    \n",
    "#     Hyper parameters         \n",
    "    model_type1 = hp.Choice(\"model_type1\", [\"CNN3\",\"CNN2\",\"CNN1\"])\n",
    "    model_type = hp.Choice(\"model_type\", [\"Dense3\"])\n",
    " \n",
    "    \n",
    "#     INPUT for NN\n",
    "    \n",
    "    inputs = keras.Input(shape=(250,1))\n",
    "    x_layer=inputs\n",
    "    \n",
    "#     MANDATORY CNN (optional to move into first condition hp.cond_scope\n",
    "    # with hp.conditional_scope(\"model_type1\", [\"CNN0\"]):\n",
    "    #         if model_type1 == \"CNN0\":\n",
    "    #             pass\n",
    "#     CONDITIONAL CONVOLUTION LAYERS (Consider moving the above into CNN1) test 0-3 CNN and 0-3 Dense\n",
    "    with hp.conditional_scope(\"model_type1\", [\"CNN1\",\"CNN2\"\"CNN3\"]):\n",
    "            if model_type1 != \"CNN0\":\n",
    "                x_layer = keras.layers.Conv1D(32, \n",
    "                        kernel_size=(3), \n",
    "                        strides=(2), \n",
    "                        padding='valid', \n",
    "                        activation='relu', \n",
    "                        input_shape=(250,1),\n",
    "                        name = 'conv1d_1'\n",
    "                        )(x_layer)\n",
    "                x_layer = keras.layers.MaxPooling1D((2), name = 'maxpooling_1')(x_layer)\n",
    "                x_layer = keras.layers.BatchNormalization(name = 'batchnorm_1')(x_layer)\n",
    "                pass\n",
    "                \n",
    "            if model_type1 != \"CNN1\":\n",
    "                x_layer = keras.layers.Conv1D(32, \n",
    "                                    kernel_size=(3), \n",
    "                                    strides=(2), \n",
    "                                    padding='valid', \n",
    "                                    activation='relu', \n",
    "                                    name = f'conv1d_2'\n",
    "                                    )(x_layer)\n",
    "                x_layer = keras.layers.MaxPooling1D((2), name = f'maxpooling_2')(x_layer)\n",
    "                x_layer = keras.layers.BatchNormalization(name = f'batchnorm_2')(x_layer)\n",
    "\n",
    "            if model_type1 != \"CNN1\" or \"CNN2\":               \n",
    "                x_layer = keras.layers.Conv1D(32, \n",
    "                                    kernel_size=(3), \n",
    "                                    strides=(2), \n",
    "                                    padding='valid', \n",
    "                                    activation='relu', \n",
    "                                    name = f'conv1d_3'\n",
    "                                    )(x_layer)\n",
    "                x_layer = keras.layers.MaxPooling1D((2), name = f'maxpooling_3')(x_layer)\n",
    "                x_layer = keras.layers.BatchNormalization(name = f'batchnorm_3')(x_layer)\n",
    "                \n",
    "#     FLATTEN AFTER CONVOLUTIONS\n",
    "    x_layer = keras.layers.Flatten(name = 'flatten')(x_layer)\n",
    "    \n",
    "#     CONDITIONAL DENSE LAYERS\n",
    "    # with hp.conditional_scope(\"model_type\", [\"Dense0\"]):\n",
    "    #     if model_type == \"Dense0\":\n",
    "    #         pass\n",
    "            \n",
    "    with hp.conditional_scope(\"model_type\", [\"Dense3\"]): #[\"Dense1\",\"Dense2\",\"Dense3\"]\n",
    "        if model_type != \"Dense0\":\n",
    "            hp_layer_1= hp.Choice(f'layer_1', values=[16,32,64,128])\n",
    "\n",
    "            x_layer = keras.layers.Dense(\n",
    "                        hp_layer_1,\n",
    "                        activation='relu',\n",
    "                        use_bias=True,\n",
    "                        # name='layer_1',\n",
    "                        kernel_initializer='glorot_uniform',\n",
    "                        bias_initializer='zeros',\n",
    "                        kernel_regularizer=None,\n",
    "                        bias_regularizer=None,\n",
    "                        activity_regularizer=None,\n",
    "                        kernel_constraint=None,\n",
    "                        bias_constraint=None\n",
    "                    )(x_layer)\n",
    "        if model_type != \"Dense1\":\n",
    "            hp_layer_2_2= hp.Choice(f'layer_2_2', values=[16,32,64,128])\n",
    "\n",
    "            x_layer = keras.layers.Dense(\n",
    "                        hp_layer_2_2,\n",
    "                        activation='relu',\n",
    "                        use_bias=True,\n",
    "                        kernel_initializer='glorot_uniform',\n",
    "                        bias_initializer='zeros',\n",
    "                        kernel_regularizer=None,\n",
    "                        bias_regularizer=None,\n",
    "                        activity_regularizer=None,\n",
    "                        kernel_constraint=None,\n",
    "                        bias_constraint=None\n",
    "                    )(x_layer)\n",
    "\n",
    "        if model_type != \"Dense1\" or \"Dense2\":\n",
    "            hp_layer_3_3= hp.Choice(f'layer_3_3',  values=[16,32,64])\n",
    "            \n",
    "            x_layer = keras.layers.Dense(\n",
    "                        hp_layer_3_3,\n",
    "                        activation='relu',\n",
    "                        use_bias=True,\n",
    "                        kernel_initializer='glorot_uniform',\n",
    "                        bias_initializer='zeros',\n",
    "                        kernel_regularizer=None,\n",
    "                        bias_regularizer=None,\n",
    "                        activity_regularizer=None,\n",
    "                        kernel_constraint=None,\n",
    "                        bias_constraint=None\n",
    "                    )(x_layer)\n",
    "#     OUTPUT LAYERS\n",
    "\n",
    "    # output_1 = keras.layers.Dense(1, name='enthalpy_pred')(x_layer)\n",
    "    # output_2 = keras.layers.Dense(1, name='entropy_pred')(x_layer)\n",
    "    # output_3 = keras.layers.Dense(1, name='free_energy_pred')(x_layer)\n",
    "    # output_4 = keras.layers.Dense(1, name='melting_temperature')(x_layer)\n",
    "\n",
    "    # output_1 = keras.layers.Dense(1, name='dH')(x_layer)\n",
    "    # output_2 = keras.layers.Dense(1, name='dS')(x_layer)\n",
    "    # output_3 = keras.layers.Dense(1, name='dG')(x_layer)\n",
    "    # output_4 = keras.layers.Dense(1, name='Tm')(x_layer)\n",
    "    \n",
    "\n",
    "    # model = Model(inputs=inputs, outputs=[output_1, output_2, output_3, output_4])\n",
    "    output_1 = keras.layers.Dense(1, name='output')(x_layer)\n",
    "    model = Model(inputs=inputs, outputs=output_1)\n",
    "    \n",
    "#     SETTINGS\n",
    "#     SETTINGS\n",
    "\n",
    "#     ADAPTIVE LEARNING RATE   \n",
    "    \n",
    "    initial_learning_rate = 0.01\n",
    "    decay_steps = 10.0\n",
    "    decay_rate = 0.5\n",
    "    learning_rate_fn = keras.optimizers.schedules.InverseTimeDecay(\n",
    "                                    initial_learning_rate, decay_steps, decay_rate)\n",
    "    \n",
    "#     SETTING ADAM OPTIMISER\n",
    "    optimiser = tf.keras.optimizers.Adam(learning_rate=learning_rate_fn)\n",
    "    \n",
    "#     COMPILE MODEl\n",
    "    model.compile(loss = \"mse\" , \n",
    "                  optimizer = optimiser, \n",
    "                  metrics = [\"mse\",'mean_absolute_error',r2_func_tf, rmse_func_tf, bias_func_tf, sdep_func_tf])   \n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48fd976b-85d5-45aa-8c53-92dab3997785",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a0c68c14-44f5-4c8b-b2cd-f0084adb85d1",
   "metadata": {},
   "source": [
    "# Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "94aa1bc9-a289-4f92-94a6-f4c10341fa80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reloading Tuner from /users/qdb16186/CNN_stk/CV/1/1/RF-Score/1DConv_st_dH/tunner/16/tuner0.json\n"
     ]
    }
   ],
   "source": [
    "epochs = 2\n",
    "batch  = 16\n",
    "# TODO: Use path lib to create path\n",
    "fold_path = path_fold(home,resample,fold)\n",
    "resample_path = path_resample(home,resample)\n",
    "\n",
    "# model_name = architecture of - Single task/RF/KNN + dH/dG/dS/Tm or - Multitask  \n",
    "prop = 'dH' \n",
    "model_name = f\"1DConv_st_{prop}\" \n",
    "\n",
    "\n",
    "# Define the directory path\n",
    "directory_path = Path(f\"{fold_path}/{desc}/{model_name}/\")\n",
    "\n",
    "tunner_path      = Path(f'{directory_path}/tunner')\n",
    "csv_logger_path  = Path(f'{directory_path}/csv_logger/')\n",
    "cp_callback_path = Path(f'{directory_path}/model_checkpoint/')\n",
    "tensorboard_path = Path(f'{directory_path}/tensorboard_logs/')\n",
    "\n",
    "# Ensure the directory exists, create it if necessary\n",
    "tunner_path.mkdir(parents=True, exist_ok=True)\n",
    "csv_logger_path.mkdir(parents=True, exist_ok=True)\n",
    "cp_callback_path.mkdir(parents=True, exist_ok=True)\n",
    "tensorboard_path.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "\n",
    "tuner = kt.GridSearch(build_model,\n",
    "                   objective=kt.Objective('val_loss', 'min'),\n",
    "                    # loss = 'val_loss',\n",
    "                   # objective = ['val_mse','val_free_energy_pred_mse'],\n",
    "                  directory=tunner_path,\n",
    "                  overwrite=False,\n",
    "                  project_name=f'{batch}')\n",
    "\n",
    "with open(f'{tunner_path}/tuner_path.txt', 'w') as f:\n",
    "    f.write(tuner.project_dir)\n",
    "f.close\n",
    "\n",
    "#### CALL BACKS!\n",
    "es = EarlyStopping(monitor      = 'val_loss', \n",
    "                        mode     = 'min', \n",
    "                        verbose  = 1, \n",
    "                        patience = 2000, \n",
    "                    restore_best_weights = True)\n",
    "# CSV Logger\n",
    "csv_logger = CSVLogger(f'{csv_logger_path}/model_history.csv' , append=True)\n",
    "\n",
    "# CP_callbacks      not required when using a tunner       \n",
    "# cp_callback = tf.keras.callbacks.ModelCheckpoint(filepath=f'{cp_callback_path}/cp.ckpt',\n",
    "#                                                  save_weights_only=True,\n",
    "#                                                  verbose=1)\n",
    "\n",
    "# TensorBoard\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=tensorboard_path, \n",
    "                                                       #/{batch}', # _ADAPTIVELEARNIGNRATE_01_10_Dense3_64_3CNN_lr_3_es\n",
    "                                                      update_freq = 1,\n",
    "                                                      # histogram_freq=1, \n",
    "                                                      write_graph=False, \n",
    "                                                      write_images=False)\n",
    "# https://www.tensorflow.org/api_docs/python/tf/keras/callbacks/TensorBoard\n",
    "\n",
    "# Covert to list and provide to Keras Regressor\n",
    "keras_callbacks = [es, csv_logger, tensorboard_callback]\n",
    "\n",
    "\n",
    "# history=tuner.search(x_hp_train, y_hp_train[:],\n",
    "#             epochs = epochs,\n",
    "#             batch_size=batch,\n",
    "#             verbose = 2,\n",
    "#             validation_data =(x_hp_val, y_hp_val[:]),\n",
    "#              # validation_split = 0.2,\n",
    "#             callbacks=keras_callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "76f0f545-c2b9-4a19-ade0-2028372ad234",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "y_1_train, y_2_train, y_3_train, y_4_train, Y_train, X_padded_train, X_train = load_xy(train_fold,desc)\n",
    "y_1_val,   y_2_val,   y_3_val,   y_4_val,   Y_val,   X_padded_val,   X_val   = load_xy(val_fold,desc)\n",
    "y_1_test,  y_2_test,  y_3_test,  y_4_test,  Y_test,  X_padded_test,  X_test  = load_xy(test_fold,desc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "67431921-1ac5-47d6-8da4-62b3487d04dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PosixPath('/users/qdb16186/CNN_stk/CV/1/1/RF-Score/1DConv_st_dH/tunner')"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tunner_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37888a17-e7aa-472f-ada3-514e0d85d115",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "history=tuner.search(X_padded_train, y_1_train,\n",
    "            epochs = epochs,\n",
    "            batch_size=batch,\n",
    "            verbose = 3,\n",
    "            validation_data =(X_padded_val, y_1_val),\n",
    "             # validation_split = 0.2,\n",
    "            callbacks=keras_callbacks)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82fe3105-1fb2-4fd1-b089-e6bbfcb6cde9",
   "metadata": {},
   "source": [
    "# Submit Job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7bff580e-53b0-4da9-a09d-9622dfbec4a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "desc_type = ['Granulated','OHEP','LP_dec2']\n",
    "GSHT_list=['dH','dS','dG','Tm']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5b46974-ecba-450a-80b9-42008be4bd49",
   "metadata": {},
   "source": [
    "# Code for Grid Search Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e7790de5-ec2c-43db-b745-d2d32b579fd2",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# from sklearn import metrics\n",
    "# from sklearn.metrics import make_scorer\n",
    "from sklearn.metrics import r2_score, mean_squared_error, explained_variance_score\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "id": "98c5c84b-740c-4db5-8ef9-f634299fcc8b",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def stats_hp(y_test_pred, Y_test, prop):\n",
    "    y_test_np = Y_test[f'{prop}'].to_numpy()\n",
    "    y_pred_test_np = y_test_pred\n",
    "\n",
    "    r2_test = r2_score(y_test_np, y_pred_test_np)\n",
    "    rmsd_test = (mean_squared_error(y_test_np, y_pred_test_np))**0.5\n",
    "    bias_test = np.mean(y_pred_test_np - y_test_np)\n",
    "    sdep_test = (np.mean((y_pred_test_np - y_test_np - bias_test)**2))**0.5\n",
    "    r2 = '{:.3f}'.format(r2_test)\n",
    "    rmsd = '{:.3f}'.format(rmsd_test)\n",
    "    bias = '{:.3f}'.format(bias_test)\n",
    "    sdep = '{:.3f}'.format(sdep_test)\n",
    "    \n",
    "    \n",
    "    mse=mean_squared_error(y_test_np, y_pred_test_np)\n",
    "    mse='{:.3f}'.format(mse)\n",
    "    mae=mean_absolute_error(y_test_np, y_pred_test_np)\n",
    "    mae='{:.3f}'.format(mae)\n",
    "    try:\n",
    "        a, b = np.polyfit(y_test_np, y_pred_test_np, 1)\n",
    "        plot_a = '{:.3f}'.format(a[0])\n",
    "        plot_b = '{:.3f}'.format(b[0])\n",
    "    except np.linalg.LinAlgError:\n",
    "        pass\n",
    "    \n",
    "    return r2, rmsd, bias, sdep, plot_a, plot_b, mse, mae"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "051fd862-f551-414b-b0ff-8fa6390b2d17",
   "metadata": {},
   "outputs": [],
   "source": [
    "def grid_analysis(df,home,resample,fold,prop,desc,model_name):\n",
    "    df2=pd.DataFrame()\n",
    "    keyList = ['trial',\n",
    "               'model_type1', 'model_type',\n",
    "               'layer_3_3', 'layer_2_2', 'layer_1',\n",
    "               f'r2_{prop}_{fold}',\n",
    "               f'rmsd_{prop}_{fold}',\n",
    "               f'bias_{prop}_{fold}',\n",
    "               f'SDEP_{prop}_{fold}',\n",
    "               f'gradient_{prop}_{fold}',\n",
    "               f'b_{prop}_{fold}',\n",
    "               f'mse_{prop}_{fold}',\n",
    "               f'mae_{prop}_{fold}']\n",
    "    n = dict(zip(keyList, [None]*len(keyList)))\n",
    "    \n",
    "    df_grid=pd.DataFrame(n,index=['a'])\n",
    "   \n",
    "    dir=path_fold(home, resample, fold)\n",
    "    # model_name = f\"1DConv_st_{prop}\" \n",
    "    tunner_path =f\"{dir}/{desc}/{model_name}/tunner\"\n",
    "    tuner = kt.GridSearch(build_model,\n",
    "                           objective=kt.Objective('val_loss', 'min'),\n",
    "                            # loss = 'val_loss',\n",
    "                           # objective = ['val_mse','epoch_entropy_pred_mse','val_free_energy_pred_mse'],\n",
    "                          directory=tunner_path,\n",
    "                          overwrite=False,\n",
    "                          project_name=f'{batch}')\n",
    "\n",
    "    # Find all trial number and cycle through them\n",
    "    selection=os.listdir(tuner.project_dir)\n",
    "    for dir_ in selection:\n",
    "        if \"trial_\" not in dir_:\n",
    "            continue\n",
    "        trial_number=str(dir_.replace(\"trial_\",\"\"))\n",
    "        trial=tuner.oracle.get_trial(trial_number)\n",
    "        model=tuner.load_model(trial)\n",
    "\n",
    "        # train, val, test = access_resample_csv(df,home,resample)\n",
    "        train_fold, val_fold, test_fold = access_fold_csv(df,home,resample,fold)\n",
    "        \n",
    "        y_1_train, y_2_train, y_3_train, y_4_train, Y_train, X_padded_train, X_train = load_xy(train_fold,desc)\n",
    "        y_1_val,   y_2_val,   y_3_val,   y_4_val,   Y_val,   X_padded_val,   X_val   = load_xy(val_fold,desc)\n",
    "        y_1_test,  y_2_test,  y_3_test,  y_4_test,  Y_test,  X_padded_test,  X_test  = load_xy(test_fold,desc)\n",
    "\n",
    "        y_test_pred = model.predict(X_padded_test)\n",
    "        \n",
    "        r2, rmsd, bias, sdep, plot_a, plot_b, mse, mae = stats_hp(y_test_pred, Y_test, prop)\n",
    "        if trial_number in df_grid.index:\n",
    "            n = df_grid.loc[trial_number].to_dict()\n",
    "        n.update({\"trial\":trial_number,})\n",
    "        n.update({f'r2_{prop}_{fold}':r2,f'rmsd_{prop}_{fold}': rmsd, \n",
    "                  f'bias_{prop}_{fold}': bias, f'SDEP_{prop}_{fold}': sdep,\n",
    "                  f'gradient_{prop}_{fold}': plot_a, f'b_{prop}_{fold}': plot_b, \n",
    "                  f'mse_{prop}_{fold}':mse, f'mae_{prop}_{fold}':mae,})\n",
    "\n",
    "        original_stdout = sys.stdout \t\n",
    "        with open(f'{prop}_{fold}_{resample}.txt', 'w') as f:\n",
    "            sys.stdout = f\n",
    "            trial.display_hyperparameters()\n",
    "            # Reset the standard output\n",
    "            sys.stdout = original_stdout \n",
    "        f.close\n",
    "        data = open(f'{prop}_{fold}_{resample}.txt', 'r').read()\n",
    "        data_hyp_param=data.replace(': ','\\n').split('\\n')\n",
    "        i_index=0\n",
    "        while i_index+1 < len(data_hyp_param):\n",
    "            n.update({data_hyp_param[i_index]:data_hyp_param[i_index+1]})\n",
    "            i_index+=2\n",
    "        os.system(f'rm {prop}_{fold}_{resample}.txt')\n",
    "\n",
    "        df_grid.loc[f'{trial_number}']=n\n",
    "    df_grid.to_csv(f'{dir}/{desc}/{model_name}/{prop}_{fold}.csv')\n",
    "    # df_grid.to_csv(f'{prop}_{fold}.csv')\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d14ba249-f054-4d20-bd0f-11292595f592",
   "metadata": {
    "editable": true,
    "scrolled": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "desc='Granulated'\n",
    "df=pd.read_csv(\"Lomzov_dataset_IY.csv\")\n",
    "batch=16\n",
    "os.chdir('/users/qdb16186/CNN_stk')\n",
    "for resample in range(0,1):\n",
    "    for prop in GSHT_list:\n",
    "        for fold in range(5):\n",
    "            grid_analysis(df,home,resample,fold,prop,desc,model_name)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# print(dir/\"Granulated\"/model_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a7b081f-b9f7-4d16-bf2e-ad6c66418522",
   "metadata": {},
   "source": [
    "## Add an archiving function after the Prop_fold.csv file is generated\n",
    "it will free 1400-3000 files and will allow for the workflow to continue sequentially "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "id": "935521d1-724c-409f-b946-0d202d66b812",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tarfile\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "id": "40da5740-65c4-4cc1-81f8-c8eee46a2bfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_tar_archive(work_dir,files):\n",
    "    # Create a tar.gz archive\n",
    "    with tarfile.open(f\"{work_dir}tuner_results.tar.gz\", \"w:gz\") as archive:\n",
    "        for file in files:\n",
    "            archive.add(f\"{work_dir}{file}\", arcname=os.path.basename(f\"{file}\"))\n",
    "        archive.close()\n",
    "        \n",
    "def archive_hyper_params(home,resample,fold,prop,desc,model_name):\n",
    "    # prop not required\n",
    "    dir=path_fold(home, resample, fold)\n",
    "    folder_dir=f'{dir}/{desc}/{model_name}/'\n",
    "    folders_to_archive=os.listdir(folder_dir)\n",
    "    create_tar_archive(folder_dir, folders_to_archive)\n",
    "\n",
    "def delete_folders_after_archive(home,resample,fold,prop,desc,model_name):\n",
    "    # prop not required\n",
    "    dir=path_fold(home, resample, fold)\n",
    "    folder_dir=f'{dir}/{desc}/{model_name}/'\n",
    "    folders_to_archive=os.listdir(folder_dir)\n",
    "    folders_to_archive = list(filter(lambda i:'.' not in i, folders_to_archive))\n",
    "    for folder in folders_to_archive:\n",
    "        os.system(f'rm -r {folder_dir}{folder}')\n",
    "\n",
    "# def untargz(home,resample,fold,prop,model_name):\n",
    "#     dir=path_fold(home, resample, fold)\n",
    "#     folder_dir=f'{dir}/{desc}/{model_name}/'\n",
    "#     archive_name=f'{folder_dir}tuner_results.tar.gz\"\n",
    "def display_tar_contents(file_path):\n",
    "    with tarfile.open(file_path, \"r:gz\") as archive:\n",
    "        print(\"Contents of the tar file:\")\n",
    "        archive.list() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "id": "608579ff-16bc-464e-9eaa-df8075f222d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "archive_hyper_params(home,resample,fold,prop,desc,model_name)\n",
    "delete_folders_after_archive(home,resample,fold,prop,desc,model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 347,
   "id": "12f055d3-5787-4d2f-947a-524704ae3fe8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Contents of the tar file:\n",
      "?rwxr-xr-x qdb16186/users          0 2024-01-28 14:25:22 csv_logger/ \n",
      "?rw-r--r-- qdb16186/users    1071714 2024-01-28 14:34:07 csv_logger/model_history.csv \n",
      "?rwxr-xr-x qdb16186/users          0 2024-01-28 14:25:19 tunner/ \n",
      "?rwxr-xr-x qdb16186/users          0 2024-01-28 14:33:49 tunner/16/ \n",
      "?rw-r--r-- qdb16186/users       3515 2024-01-28 14:34:07 tunner/16/oracle.json \n",
      "?rwxr-xr-x qdb16186/users          0 2024-01-28 14:25:45 tunner/16/trial_0000/ \n",
      "?rw-r--r-- qdb16186/users         77 2024-01-28 14:25:45 tunner/16/trial_0000/checkpoint \n",
      "?rw-r--r-- qdb16186/users     112979 2024-01-28 14:25:45 tunner/16/trial_0000/checkpoint.data-00000-of-00001 \n",
      "?rw-r--r-- qdb16186/users       4015 2024-01-28 14:25:45 tunner/16/trial_0000/checkpoint.index \n",
      "?rw-r--r-- qdb16186/users       2636 2024-01-28 14:26:02 tunner/16/trial_0000/trial.json \n",
      "?rwxr-xr-x qdb16186/users          0 2024-01-28 14:26:24 tunner/16/trial_0001/ \n",
      "?rw-r--r-- qdb16186/users         77 2024-01-28 14:26:24 tunner/16/trial_0001/checkpoint \n",
      "?rw-r--r-- qdb16186/users     116435 2024-01-28 14:26:24 tunner/16/trial_0001/checkpoint.data-00000-of-00001 \n",
      "?rw-r--r-- qdb16186/users       4021 2024-01-28 14:26:24 tunner/16/trial_0001/checkpoint.index \n",
      "?rw-r--r-- qdb16186/users       2638 2024-01-28 14:26:27 tunner/16/trial_0001/trial.json \n",
      "?rwxr-xr-x qdb16186/users          0 2024-01-28 14:26:53 tunner/16/trial_0002/ \n",
      "?rw-r--r-- qdb16186/users         77 2024-01-28 14:26:53 tunner/16/trial_0002/checkpoint \n",
      "?rw-r--r-- qdb16186/users     123347 2024-01-28 14:26:53 tunner/16/trial_0002/checkpoint.data-00000-of-00001 \n",
      "?rw-r--r-- qdb16186/users       4021 2024-01-28 14:26:53 tunner/16/trial_0002/checkpoint.index \n",
      "?rw-r--r-- qdb16186/users       2638 2024-01-28 14:27:10 tunner/16/trial_0002/trial.json \n",
      "?rwxr-xr-x qdb16186/users          0 2024-01-28 14:27:27 tunner/16/trial_0003/ \n",
      "?rw-r--r-- qdb16186/users         77 2024-01-28 14:27:27 tunner/16/trial_0003/checkpoint \n",
      "?rw-r--r-- qdb16186/users     119315 2024-01-28 14:27:27 tunner/16/trial_0003/checkpoint.data-00000-of-00001 \n",
      "?rw-r--r-- qdb16186/users       4018 2024-01-28 14:27:27 tunner/16/trial_0003/checkpoint.index \n",
      "?rw-r--r-- qdb16186/users       2634 2024-01-28 14:27:53 tunner/16/trial_0003/trial.json \n",
      "?rwxr-xr-x qdb16186/users          0 2024-01-28 14:28:09 tunner/16/trial_0004/ \n",
      "?rw-r--r-- qdb16186/users         77 2024-01-28 14:28:09 tunner/16/trial_0004/checkpoint \n",
      "?rw-r--r-- qdb16186/users     125843 2024-01-28 14:28:09 tunner/16/trial_0004/checkpoint.data-00000-of-00001 \n",
      "?rw-r--r-- qdb16186/users       4024 2024-01-28 14:28:09 tunner/16/trial_0004/checkpoint.index \n",
      "?rw-r--r-- qdb16186/users       2642 2024-01-28 14:28:36 tunner/16/trial_0004/trial.json \n",
      "?rwxr-xr-x qdb16186/users          0 2024-01-28 14:29:04 tunner/16/trial_0005/ \n",
      "?rw-r--r-- qdb16186/users         77 2024-01-28 14:29:04 tunner/16/trial_0005/checkpoint \n",
      "?rw-r--r-- qdb16186/users     138899 2024-01-28 14:29:04 tunner/16/trial_0005/checkpoint.data-00000-of-00001 \n",
      "?rw-r--r-- qdb16186/users       4024 2024-01-28 14:29:04 tunner/16/trial_0005/checkpoint.index \n",
      "?rw-r--r-- qdb16186/users       2644 2024-01-28 14:29:20 tunner/16/trial_0005/trial.json \n",
      "?rwxr-xr-x qdb16186/users          0 2024-01-28 14:29:48 tunner/16/trial_0006/ \n",
      "?rw-r--r-- qdb16186/users         77 2024-01-28 14:29:48 tunner/16/trial_0006/checkpoint \n",
      "?rw-r--r-- qdb16186/users     131987 2024-01-28 14:29:48 tunner/16/trial_0006/checkpoint.data-00000-of-00001 \n",
      "?rw-r--r-- qdb16186/users       4018 2024-01-28 14:29:48 tunner/16/trial_0006/checkpoint.index \n",
      "?rw-r--r-- qdb16186/users       2638 2024-01-28 14:30:03 tunner/16/trial_0006/trial.json \n",
      "?rwxr-xr-x qdb16186/users          0 2024-01-28 14:30:31 tunner/16/trial_0007/ \n",
      "?rw-r--r-- qdb16186/users         77 2024-01-28 14:30:31 tunner/16/trial_0007/checkpoint \n",
      "?rw-r--r-- qdb16186/users     144659 2024-01-28 14:30:31 tunner/16/trial_0007/checkpoint.data-00000-of-00001 \n",
      "?rw-r--r-- qdb16186/users       4024 2024-01-28 14:30:31 tunner/16/trial_0007/checkpoint.index \n",
      "?rw-r--r-- qdb16186/users       2636 2024-01-28 14:30:46 tunner/16/trial_0007/trial.json \n",
      "?rwxr-xr-x qdb16186/users          0 2024-01-28 14:31:13 tunner/16/trial_0008/ \n",
      "?rw-r--r-- qdb16186/users         77 2024-01-28 14:31:13 tunner/16/trial_0008/checkpoint \n",
      "?rw-r--r-- qdb16186/users     170003 2024-01-28 14:31:13 tunner/16/trial_0008/checkpoint.data-00000-of-00001 \n",
      "?rw-r--r-- qdb16186/users       4027 2024-01-28 14:31:13 tunner/16/trial_0008/checkpoint.index \n",
      "?rw-r--r-- qdb16186/users       2637 2024-01-28 14:31:30 tunner/16/trial_0008/trial.json \n",
      "?rwxr-xr-x qdb16186/users          0 2024-01-28 14:31:59 tunner/16/trial_0009/ \n",
      "?rw-r--r-- qdb16186/users         77 2024-01-28 14:31:59 tunner/16/trial_0009/checkpoint \n",
      "?rw-r--r-- qdb16186/users     157331 2024-01-28 14:31:59 tunner/16/trial_0009/checkpoint.data-00000-of-00001 \n",
      "?rw-r--r-- qdb16186/users       4027 2024-01-28 14:31:59 tunner/16/trial_0009/checkpoint.index \n",
      "?rw-r--r-- qdb16186/users       2639 2024-01-28 14:32:14 tunner/16/trial_0009/trial.json \n",
      "?rwxr-xr-x qdb16186/users          0 2024-01-28 14:32:22 tunner/16/trial_0010/ \n",
      "?rw-r--r-- qdb16186/users         77 2024-01-28 14:32:22 tunner/16/trial_0010/checkpoint \n",
      "?rw-r--r-- qdb16186/users     182291 2024-01-28 14:32:22 tunner/16/trial_0010/checkpoint.data-00000-of-00001 \n",
      "?rw-r--r-- qdb16186/users       4036 2024-01-28 14:32:22 tunner/16/trial_0010/checkpoint.index \n",
      "?rw-r--r-- qdb16186/users       2624 2024-01-28 14:32:57 tunner/16/trial_0010/trial.json \n",
      "?rwxr-xr-x qdb16186/users          0 2024-01-28 14:33:16 tunner/16/trial_0011/ \n",
      "?rw-r--r-- qdb16186/users         77 2024-01-28 14:33:16 tunner/16/trial_0011/checkpoint \n",
      "?rw-r--r-- qdb16186/users     232211 2024-01-28 14:33:16 tunner/16/trial_0011/checkpoint.data-00000-of-00001 \n",
      "?rw-r--r-- qdb16186/users       4036 2024-01-28 14:33:16 tunner/16/trial_0011/checkpoint.index \n",
      "?rw-r--r-- qdb16186/users       2638 2024-01-28 14:33:24 tunner/16/trial_0011/trial.json \n",
      "?rwxr-xr-x qdb16186/users          0 2024-01-28 14:33:47 tunner/16/trial_0012/ \n",
      "?rw-r--r-- qdb16186/users         77 2024-01-28 14:33:47 tunner/16/trial_0012/checkpoint \n",
      "?rw-r--r-- qdb16186/users     134675 2024-01-28 14:33:47 tunner/16/trial_0012/checkpoint.data-00000-of-00001 \n",
      "?rw-r--r-- qdb16186/users       4018 2024-01-28 14:33:47 tunner/16/trial_0012/checkpoint.index \n",
      "?rw-r--r-- qdb16186/users       2640 2024-01-28 14:33:49 tunner/16/trial_0012/trial.json \n",
      "?rwxr-xr-x qdb16186/users          0 2024-01-28 14:33:51 tunner/16/trial_0013/ \n",
      "?rw-r--r-- qdb16186/users         77 2024-01-28 14:33:51 tunner/16/trial_0013/checkpoint \n",
      "?rw-r--r-- qdb16186/users     138131 2024-01-28 14:33:51 tunner/16/trial_0013/checkpoint.data-00000-of-00001 \n",
      "?rw-r--r-- qdb16186/users       4024 2024-01-28 14:33:51 tunner/16/trial_0013/checkpoint.index \n",
      "?rw-r--r-- qdb16186/users       3011 2024-01-28 14:34:07 tunner/16/trial_0013/trial.json \n",
      "?rw-r--r-- qdb16186/users          2 2024-01-28 14:34:07 tunner/16/tuner0.json \n",
      "?rw-r--r-- qdb16186/users         64 2024-01-28 14:25:19 tunner/tuner_path.txt \n",
      "?rwxr-xr-x qdb16186/users          0 2024-01-28 14:33:49 tensorboard_logs/ \n",
      "?rwxr-xr-x qdb16186/users          0 2024-01-28 14:25:19 tensorboard_logs/0000/ \n",
      "?rwxr-xr-x qdb16186/users          0 2024-01-28 14:25:21 tensorboard_logs/0000/execution0/ \n",
      "?rw-r--r-- qdb16186/users        393 2024-01-28 14:25:50 tensorboard_logs/0000/execution0/events.out.tfevents.1706451919.node040.hpc.strath.ac.uk.3227737.0.v2 \n",
      "?rwxr-xr-x qdb16186/users          0 2024-01-28 14:25:19 tensorboard_logs/0000/execution0/train/ \n",
      "?rw-r--r-- qdb16186/users     970149 2024-01-28 14:25:50 tensorboard_logs/0000/execution0/train/events.out.tfevents.1706451919.node040.hpc.strath.ac.uk.3227737.1.v2 \n",
      "?rwxr-xr-x qdb16186/users          0 2024-01-28 14:25:21 tensorboard_logs/0000/execution0/validation/ \n",
      "?rw-r--r-- qdb16186/users     355093 2024-01-28 14:25:50 tensorboard_logs/0000/execution0/validation/events.out.tfevents.1706451921.node040.hpc.strath.ac.uk.3227737.2.v2 \n",
      "?rwxr-xr-x qdb16186/users          0 2024-01-28 14:26:02 tensorboard_logs/0001/ \n",
      "?rwxr-xr-x qdb16186/users          0 2024-01-28 14:26:04 tensorboard_logs/0001/execution0/ \n",
      "?rw-r--r-- qdb16186/users        393 2024-01-28 14:26:27 tensorboard_logs/0001/execution0/events.out.tfevents.1706451962.node040.hpc.strath.ac.uk.3227737.3.v2 \n",
      "?rwxr-xr-x qdb16186/users          0 2024-01-28 14:26:03 tensorboard_logs/0001/execution0/train/ \n",
      "?rw-r--r-- qdb16186/users     970149 2024-01-28 14:26:27 tensorboard_logs/0001/execution0/train/events.out.tfevents.1706451963.node040.hpc.strath.ac.uk.3227737.4.v2 \n",
      "?rwxr-xr-x qdb16186/users          0 2024-01-28 14:26:04 tensorboard_logs/0001/execution0/validation/ \n",
      "?rw-r--r-- qdb16186/users     355093 2024-01-28 14:26:27 tensorboard_logs/0001/execution0/validation/events.out.tfevents.1706451964.node040.hpc.strath.ac.uk.3227737.5.v2 \n",
      "?rwxr-xr-x qdb16186/users          0 2024-01-28 14:26:27 tensorboard_logs/0002/ \n",
      "?rwxr-xr-x qdb16186/users          0 2024-01-28 14:26:29 tensorboard_logs/0002/execution0/ \n",
      "?rw-r--r-- qdb16186/users        393 2024-01-28 14:26:53 tensorboard_logs/0002/execution0/events.out.tfevents.1706451987.node040.hpc.strath.ac.uk.3227737.6.v2 \n",
      "?rwxr-xr-x qdb16186/users          0 2024-01-28 14:26:28 tensorboard_logs/0002/execution0/train/ \n",
      "?rw-r--r-- qdb16186/users     970149 2024-01-28 14:26:53 tensorboard_logs/0002/execution0/train/events.out.tfevents.1706451988.node040.hpc.strath.ac.uk.3227737.7.v2 \n",
      "?rwxr-xr-x qdb16186/users          0 2024-01-28 14:26:29 tensorboard_logs/0002/execution0/validation/ \n",
      "?rw-r--r-- qdb16186/users     355093 2024-01-28 14:26:53 tensorboard_logs/0002/execution0/validation/events.out.tfevents.1706451989.node040.hpc.strath.ac.uk.3227737.8.v2 \n",
      "?rwxr-xr-x qdb16186/users          0 2024-01-28 14:27:10 tensorboard_logs/0003/ \n",
      "?rwxr-xr-x qdb16186/users          0 2024-01-28 14:27:12 tensorboard_logs/0003/execution0/ \n",
      "?rw-r--r-- qdb16186/users        393 2024-01-28 14:27:37 tensorboard_logs/0003/execution0/events.out.tfevents.1706452030.node040.hpc.strath.ac.uk.3227737.9.v2 \n",
      "?rwxr-xr-x qdb16186/users          0 2024-01-28 14:27:10 tensorboard_logs/0003/execution0/train/ \n",
      "?rw-r--r-- qdb16186/users     970149 2024-01-28 14:27:37 tensorboard_logs/0003/execution0/train/events.out.tfevents.1706452030.node040.hpc.strath.ac.uk.3227737.10.v2 \n",
      "?rwxr-xr-x qdb16186/users          0 2024-01-28 14:27:12 tensorboard_logs/0003/execution0/validation/ \n",
      "?rw-r--r-- qdb16186/users     355093 2024-01-28 14:27:37 tensorboard_logs/0003/execution0/validation/events.out.tfevents.1706452032.node040.hpc.strath.ac.uk.3227737.11.v2 \n",
      "?rwxr-xr-x qdb16186/users          0 2024-01-28 14:27:53 tensorboard_logs/0004/ \n",
      "?rwxr-xr-x qdb16186/users          0 2024-01-28 14:27:55 tensorboard_logs/0004/execution0/ \n",
      "?rw-r--r-- qdb16186/users        393 2024-01-28 14:28:19 tensorboard_logs/0004/execution0/events.out.tfevents.1706452073.node040.hpc.strath.ac.uk.3227737.12.v2 \n",
      "?rwxr-xr-x qdb16186/users          0 2024-01-28 14:27:54 tensorboard_logs/0004/execution0/train/ \n",
      "?rw-r--r-- qdb16186/users     970149 2024-01-28 14:28:19 tensorboard_logs/0004/execution0/train/events.out.tfevents.1706452074.node040.hpc.strath.ac.uk.3227737.13.v2 \n",
      "?rwxr-xr-x qdb16186/users          0 2024-01-28 14:27:55 tensorboard_logs/0004/execution0/validation/ \n",
      "?rw-r--r-- qdb16186/users     355093 2024-01-28 14:28:19 tensorboard_logs/0004/execution0/validation/events.out.tfevents.1706452075.node040.hpc.strath.ac.uk.3227737.14.v2 \n",
      "?rwxr-xr-x qdb16186/users          0 2024-01-28 14:28:36 tensorboard_logs/0005/ \n",
      "?rwxr-xr-x qdb16186/users          0 2024-01-28 14:28:39 tensorboard_logs/0005/execution0/ \n",
      "?rw-r--r-- qdb16186/users        393 2024-01-28 14:29:06 tensorboard_logs/0005/execution0/events.out.tfevents.1706452116.node040.hpc.strath.ac.uk.3227737.15.v2 \n",
      "?rwxr-xr-x qdb16186/users          0 2024-01-28 14:28:37 tensorboard_logs/0005/execution0/train/ \n",
      "?rw-r--r-- qdb16186/users     970149 2024-01-28 14:29:06 tensorboard_logs/0005/execution0/train/events.out.tfevents.1706452117.node040.hpc.strath.ac.uk.3227737.16.v2 \n",
      "?rwxr-xr-x qdb16186/users          0 2024-01-28 14:28:39 tensorboard_logs/0005/execution0/validation/ \n",
      "?rw-r--r-- qdb16186/users     355093 2024-01-28 14:29:06 tensorboard_logs/0005/execution0/validation/events.out.tfevents.1706452119.node040.hpc.strath.ac.uk.3227737.17.v2 \n",
      "?rwxr-xr-x qdb16186/users          0 2024-01-28 14:29:20 tensorboard_logs/0006/ \n",
      "?rwxr-xr-x qdb16186/users          0 2024-01-28 14:29:22 tensorboard_logs/0006/execution0/ \n",
      "?rw-r--r-- qdb16186/users        393 2024-01-28 14:29:48 tensorboard_logs/0006/execution0/events.out.tfevents.1706452160.node040.hpc.strath.ac.uk.3227737.18.v2 \n",
      "?rwxr-xr-x qdb16186/users          0 2024-01-28 14:29:20 tensorboard_logs/0006/execution0/train/ \n",
      "?rw-r--r-- qdb16186/users     970149 2024-01-28 14:29:48 tensorboard_logs/0006/execution0/train/events.out.tfevents.1706452160.node040.hpc.strath.ac.uk.3227737.19.v2 \n",
      "?rwxr-xr-x qdb16186/users          0 2024-01-28 14:29:22 tensorboard_logs/0006/execution0/validation/ \n",
      "?rw-r--r-- qdb16186/users     355093 2024-01-28 14:29:48 tensorboard_logs/0006/execution0/validation/events.out.tfevents.1706452162.node040.hpc.strath.ac.uk.3227737.20.v2 \n",
      "?rwxr-xr-x qdb16186/users          0 2024-01-28 14:30:03 tensorboard_logs/0007/ \n",
      "?rwxr-xr-x qdb16186/users          0 2024-01-28 14:30:05 tensorboard_logs/0007/execution0/ \n",
      "?rw-r--r-- qdb16186/users        393 2024-01-28 14:30:32 tensorboard_logs/0007/execution0/events.out.tfevents.1706452203.node040.hpc.strath.ac.uk.3227737.21.v2 \n",
      "?rwxr-xr-x qdb16186/users          0 2024-01-28 14:30:03 tensorboard_logs/0007/execution0/train/ \n",
      "?rw-r--r-- qdb16186/users     970149 2024-01-28 14:30:32 tensorboard_logs/0007/execution0/train/events.out.tfevents.1706452203.node040.hpc.strath.ac.uk.3227737.22.v2 \n",
      "?rwxr-xr-x qdb16186/users          0 2024-01-28 14:30:05 tensorboard_logs/0007/execution0/validation/ \n",
      "?rw-r--r-- qdb16186/users     355093 2024-01-28 14:30:32 tensorboard_logs/0007/execution0/validation/events.out.tfevents.1706452205.node040.hpc.strath.ac.uk.3227737.23.v2 \n",
      "?rwxr-xr-x qdb16186/users          0 2024-01-28 14:30:46 tensorboard_logs/0008/ \n",
      "?rwxr-xr-x qdb16186/users          0 2024-01-28 14:30:49 tensorboard_logs/0008/execution0/ \n",
      "?rw-r--r-- qdb16186/users        393 2024-01-28 14:31:17 tensorboard_logs/0008/execution0/events.out.tfevents.1706452246.node040.hpc.strath.ac.uk.3227737.24.v2 \n",
      "?rwxr-xr-x qdb16186/users          0 2024-01-28 14:30:47 tensorboard_logs/0008/execution0/train/ \n",
      "?rw-r--r-- qdb16186/users     970149 2024-01-28 14:31:17 tensorboard_logs/0008/execution0/train/events.out.tfevents.1706452247.node040.hpc.strath.ac.uk.3227737.25.v2 \n",
      "?rwxr-xr-x qdb16186/users          0 2024-01-28 14:30:49 tensorboard_logs/0008/execution0/validation/ \n",
      "?rw-r--r-- qdb16186/users     355093 2024-01-28 14:31:17 tensorboard_logs/0008/execution0/validation/events.out.tfevents.1706452249.node040.hpc.strath.ac.uk.3227737.26.v2 \n",
      "?rwxr-xr-x qdb16186/users          0 2024-01-28 14:31:30 tensorboard_logs/0009/ \n",
      "?rwxr-xr-x qdb16186/users          0 2024-01-28 14:31:33 tensorboard_logs/0009/execution0/ \n",
      "?rw-r--r-- qdb16186/users        393 2024-01-28 14:32:00 tensorboard_logs/0009/execution0/events.out.tfevents.1706452290.node040.hpc.strath.ac.uk.3227737.27.v2 \n",
      "?rwxr-xr-x qdb16186/users          0 2024-01-28 14:31:31 tensorboard_logs/0009/execution0/train/ \n",
      "?rw-r--r-- qdb16186/users     970149 2024-01-28 14:32:00 tensorboard_logs/0009/execution0/train/events.out.tfevents.1706452291.node040.hpc.strath.ac.uk.3227737.28.v2 \n",
      "?rwxr-xr-x qdb16186/users          0 2024-01-28 14:31:33 tensorboard_logs/0009/execution0/validation/ \n",
      "?rw-r--r-- qdb16186/users     355093 2024-01-28 14:32:00 tensorboard_logs/0009/execution0/validation/events.out.tfevents.1706452293.node040.hpc.strath.ac.uk.3227737.29.v2 \n",
      "?rwxr-xr-x qdb16186/users          0 2024-01-28 14:32:14 tensorboard_logs/0010/ \n",
      "?rwxr-xr-x qdb16186/users          0 2024-01-28 14:32:16 tensorboard_logs/0010/execution0/ \n",
      "?rw-r--r-- qdb16186/users        393 2024-01-28 14:32:41 tensorboard_logs/0010/execution0/events.out.tfevents.1706452334.node040.hpc.strath.ac.uk.3227737.30.v2 \n",
      "?rwxr-xr-x qdb16186/users          0 2024-01-28 14:32:14 tensorboard_logs/0010/execution0/train/ \n",
      "?rw-r--r-- qdb16186/users     970149 2024-01-28 14:32:41 tensorboard_logs/0010/execution0/train/events.out.tfevents.1706452334.node040.hpc.strath.ac.uk.3227737.31.v2 \n",
      "?rwxr-xr-x qdb16186/users          0 2024-01-28 14:32:16 tensorboard_logs/0010/execution0/validation/ \n",
      "?rw-r--r-- qdb16186/users     355093 2024-01-28 14:32:41 tensorboard_logs/0010/execution0/validation/events.out.tfevents.1706452336.node040.hpc.strath.ac.uk.3227737.32.v2 \n",
      "?rwxr-xr-x qdb16186/users          0 2024-01-28 14:32:57 tensorboard_logs/0011/ \n",
      "?rwxr-xr-x qdb16186/users          0 2024-01-28 14:32:59 tensorboard_logs/0011/execution0/ \n",
      "?rw-r--r-- qdb16186/users        393 2024-01-28 14:33:24 tensorboard_logs/0011/execution0/events.out.tfevents.1706452377.node040.hpc.strath.ac.uk.3227737.33.v2 \n",
      "?rwxr-xr-x qdb16186/users          0 2024-01-28 14:32:57 tensorboard_logs/0011/execution0/train/ \n",
      "?rw-r--r-- qdb16186/users     970149 2024-01-28 14:33:24 tensorboard_logs/0011/execution0/train/events.out.tfevents.1706452377.node040.hpc.strath.ac.uk.3227737.34.v2 \n",
      "?rwxr-xr-x qdb16186/users          0 2024-01-28 14:32:59 tensorboard_logs/0011/execution0/validation/ \n",
      "?rw-r--r-- qdb16186/users     355093 2024-01-28 14:33:24 tensorboard_logs/0011/execution0/validation/events.out.tfevents.1706452379.node040.hpc.strath.ac.uk.3227737.35.v2 \n",
      "?rwxr-xr-x qdb16186/users          0 2024-01-28 14:33:24 tensorboard_logs/0012/ \n",
      "?rwxr-xr-x qdb16186/users          0 2024-01-28 14:33:26 tensorboard_logs/0012/execution0/ \n",
      "?rw-r--r-- qdb16186/users        393 2024-01-28 14:33:49 tensorboard_logs/0012/execution0/events.out.tfevents.1706452404.node040.hpc.strath.ac.uk.3227737.36.v2 \n",
      "?rwxr-xr-x qdb16186/users          0 2024-01-28 14:33:24 tensorboard_logs/0012/execution0/train/ \n",
      "?rw-r--r-- qdb16186/users     970149 2024-01-28 14:33:49 tensorboard_logs/0012/execution0/train/events.out.tfevents.1706452404.node040.hpc.strath.ac.uk.3227737.37.v2 \n",
      "?rwxr-xr-x qdb16186/users          0 2024-01-28 14:33:26 tensorboard_logs/0012/execution0/validation/ \n",
      "?rw-r--r-- qdb16186/users     355093 2024-01-28 14:33:49 tensorboard_logs/0012/execution0/validation/events.out.tfevents.1706452406.node040.hpc.strath.ac.uk.3227737.38.v2 \n",
      "?rwxr-xr-x qdb16186/users          0 2024-01-28 14:33:49 tensorboard_logs/0013/ \n",
      "?rwxr-xr-x qdb16186/users          0 2024-01-28 14:33:51 tensorboard_logs/0013/execution0/ \n",
      "?rw-r--r-- qdb16186/users        300 2024-01-28 14:33:49 tensorboard_logs/0013/execution0/events.out.tfevents.1706452429.node040.hpc.strath.ac.uk.3227737.39.v2 \n",
      "?rwxr-xr-x qdb16186/users          0 2024-01-28 14:33:49 tensorboard_logs/0013/execution0/train/ \n",
      "?rw-r--r-- qdb16186/users     510069 2024-01-28 14:34:07 tensorboard_logs/0013/execution0/train/events.out.tfevents.1706452429.node040.hpc.strath.ac.uk.3227737.40.v2 \n",
      "?rwxr-xr-x qdb16186/users          0 2024-01-28 14:33:51 tensorboard_logs/0013/execution0/validation/ \n",
      "?rw-r--r-- qdb16186/users     186539 2024-01-28 14:34:07 tensorboard_logs/0013/execution0/validation/events.out.tfevents.1706452431.node040.hpc.strath.ac.uk.3227737.41.v2 \n",
      "?rwxr-xr-x qdb16186/users          0 2024-01-28 14:25:19 model_checkpoint/ \n"
     ]
    }
   ],
   "source": [
    "display_tar_contents(f'/users/qdb16186/CNN_stk/CV/0/0/DNA-Groups/1DConv_st_Tm/tuner_results.tar.gz')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6453526e-abe6-40c3-896a-c740a848a789",
   "metadata": {},
   "source": [
    "## Combine all grids and Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "9cd8fa23-1e54-495e-b06d-d5c2d21ac1d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45\n",
      "31\n"
     ]
    }
   ],
   "source": [
    "test_df1=pd.read_csv('Tm_4.csv')\n",
    "test_df2=pd.read_csv('Tm_3.csv')\n",
    "test_df3=pd.read_csv('Tm_2.csv')\n",
    "test_df=pd.concat([test_df1,test_df2,test_df3],\n",
    "                 axis=1)\n",
    "print(len(test_df.columns))\n",
    "df_cleaned = test_df.T.drop_duplicates().T\n",
    "print(len(df_cleaned.columns))\n",
    "df_cleaned.columns\n",
    "stats_list=['r2','rmsd','bias','SDEP','gradient','b','mse','mae']\n",
    "GSHT_list=['dH','dS','dG','Tm']\n",
    "\n",
    "# for prop in GSHT_List:\n",
    "#     for stats in stats_list:\n",
    "#         temp_list=[]\n",
    "#         for fold in range(5):\n",
    "#             temp_list.append(\n",
    "# df_cleaned\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c457c810-e43b-4582-95e1-8b68dc22dd76",
   "metadata": {},
   "source": [
    "## Single Task access grid search results  from each fold and select best paramters for Train val Test evaluation of Model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "id": "00d34003-78d6-4302-bb7b-52e2d5a3b050",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dH\n"
     ]
    }
   ],
   "source": [
    "df_combine = pd.DataFrame()\n",
    "df_summary = pd.DataFrame()\n",
    "df_combine_all = pd.DataFrame()\n",
    "\n",
    "# for resample in range(1):\n",
    "df_combine_all = pd.DataFrame()\n",
    "df_summary = pd.DataFrame()\n",
    "for prop in GSHT_list[0:1]:\n",
    "    print(prop)\n",
    "for fold in range(5):\n",
    "    dir = path_fold(home, resample, fold)\n",
    "    model_name = f\"1DConv_st_{prop}\"\n",
    "    try:\n",
    "        df_read=pd.read_csv(f'{dir}/{desc}/{model_name}/{prop}_{fold}.csv')\n",
    "        # Combine\n",
    "        df_combine=pd.concat([df_combine,df_read],\n",
    "                            axis=1)\n",
    "    except:\n",
    "        pass\n",
    "        \n",
    "    # count=0\n",
    "df_combine = df_combine.T.drop_duplicates().T\n",
    "for stat in stats_list:\n",
    "    columns_to_compute = df_combine.filter(regex=f'^{stat}_{prop}')\n",
    "    # print(columns_to_compute)\n",
    "    # Compute mean and std for the specified columns\n",
    "    mean_values = df_combine.filter(regex=f'^{stat}_{prop}').mean(axis=1)\n",
    "    std_values = df_combine.filter(regex=f'^{stat}_{prop}').std(axis=1)\n",
    "    df_combine_all[f'{stat}_{prop}_mean'] = mean_values\n",
    "    df_combine_all[f'{stat}_{prop}_std']  = std_values\n",
    "    if stat == 'r2' or stat =='rmsd':\n",
    "        df_summary[f'{stat}_{prop}_mean'] = mean_values\n",
    "        df_summary[f'{stat}_{prop}_std']  = std_values\n",
    "\n",
    "df_summary['trial_id']=df_combine['Unnamed: 0']\n",
    "#  Find the trial number with the best hyper paramteres\n",
    "trial_number_fin_model = df_summary.loc[df_summary[f'r2_{prop}_mean'].idxmax()]['trial_id']\n",
    "\n",
    "# Load best hyper parameters into a dataframe\n",
    "best_hps=df_combine.loc[df_combine['Unnamed: 0']==trial_number_fin_model][df_combine.columns[2:7]]\n",
    "\n",
    "# Load Hyper parameters for final model\n",
    "hp = kt.HyperParameters()\n",
    "\n",
    "model_type1 = hp.Choice(\"model_type1\", [best_hps.values[0, 0]])\n",
    "model_type = hp.Choice(\"model_type\", [best_hps.values[0, 1]])\n",
    "hp_layer_1= hp.Choice(f'layer_1', values=[best_hps.values[0, 4]])\n",
    "hp_layer_2_2= hp.Choice(f'layer_2_2', values=[best_hps.values[0, 3]])\n",
    "hp_layer_3_3= hp.Choice(f'layer_3_3',  values=[best_hps.values[0, 2]])\n",
    "\n",
    "# Build final model\n",
    "test_model=build_model(hp)\n",
    "\n",
    "# Inputs for training final Model\n",
    "epochs = 300\n",
    "batch  = 16\n",
    "# TODO: Use path lib to create path\n",
    "resample_path = path_resample(home,resample)\n",
    "\n",
    "# model_name = architecture of - Single task/RF/KNN + dH/dG/dS/Tm or - Multitask  \n",
    "prop = 'dH' \n",
    "model_name = f\"1DConv_st_{prop}\" \n",
    "\n",
    "\n",
    "# Define the directory path\n",
    "directory_path = Path(f\"{os.getcwd()}/CV/{resample}/{desc}/{model_name}/\")\n",
    "\n",
    "# Define Paths for call backs\n",
    "csv_logger_path  = Path(f'{directory_path}/csv_logger/')\n",
    "cp_callback_path = Path(f'{directory_path}/model_checkpoint/')\n",
    "tensorboard_path = Path(f'{directory_path}/tensorboard_logs/')\n",
    "\n",
    "# Ensure the directory exists, create it if necessary\n",
    "csv_logger_path.mkdir(parents=True, exist_ok=True)\n",
    "cp_callback_path.mkdir(parents=True, exist_ok=True)\n",
    "tensorboard_path.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "\n",
    "#### CALL BACKS!\n",
    "es = EarlyStopping(monitor      = 'val_loss', \n",
    "                        mode     = 'min', \n",
    "                        verbose  = 1, \n",
    "                        patience = 2000, \n",
    "                    restore_best_weights = True)\n",
    "# CSV Logger\n",
    "csv_logger = CSVLogger(f'{csv_logger_path}/model_history.csv' , append=True)\n",
    "\n",
    "# CP_callbacks      not required when using a tunner       \n",
    "# cp_callback = tf.keras.callbacks.ModelCheckpoint(filepath=f'{cp_callback_path}/cp.ckpt',\n",
    "#                                                  save_weights_only=True,\n",
    "#                                                  verbose=1)\n",
    "\n",
    "# TensorBoard\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=tensorboard_path, \n",
    "                                                       #/{batch}', # _ADAPTIVELEARNIGNRATE_01_10_Dense3_64_3CNN_lr_3_es\n",
    "                                                      update_freq = 1,\n",
    "                                                      # histogram_freq=1, \n",
    "                                                      write_graph=False, \n",
    "                                                      write_images=False)\n",
    "# https://www.tensorflow.org/api_docs/python/tf/keras/callbacks/TensorBoard\n",
    "\n",
    "# Covert to list and provide to Keras Regressor\n",
    "keras_callbacks = [es, csv_logger, tensorboard_callback]\n",
    "\n",
    "# Load resample data\n",
    "y_1_train, y_2_train, y_3_train, y_4_train, Y_train, X_padded_train, X_train = load_xy(train,desc)\n",
    "y_1_val,   y_2_val,   y_3_val,   y_4_val,   Y_val,   X_padded_val,   X_val   = load_xy(val,desc)\n",
    "y_1_test,  y_2_test,  y_3_test,  y_4_test,  Y_test,  X_padded_test,  X_test  = load_xy(test,desc)\n",
    "\n",
    "# Train model on resample data\n",
    "history=test_model.fit(X_padded_train, y_1_train,\n",
    "            epochs = epochs,\n",
    "            batch_size=batch,\n",
    "            verbose = 2,\n",
    "            validation_data =(X_padded_val, y_1_val),\n",
    "             # validation_split = 0.2,\n",
    "            callbacks=keras_callbacks)\n",
    "# Make predictions\n",
    "\n",
    "\n",
    "# Store stats\n",
    "\n",
    "\n",
    "# Store csv files (predictions vs true)\n",
    "\n",
    "\n",
    "def stats_csv(y_test_pred, Y_test, prop, csv_name, set_type,resample):\n",
    "    y_test_np = Y_test[f'{prop}'].to_numpy()\n",
    "    y_pred_test_np = y_test_pred\n",
    "\n",
    "    r2_test = r2_score(y_test_np, y_pred_test_np)\n",
    "    rmsd_test = (mean_squared_error(y_test_np, y_pred_test_np))**0.5\n",
    "    bias_test = np.mean(y_pred_test_np - y_test_np)\n",
    "    sdep_test = (np.mean((y_pred_test_np - y_test_np - bias_test)**2))**0.5\n",
    "    r2 = '{:.3f}'.format(r2_test)\n",
    "    rmsd = '{:.3f}'.format(rmsd_test)\n",
    "    bias = '{:.3f}'.format(bias_test)\n",
    "    sdep = '{:.3f}'.format(sdep_test)\n",
    "    \n",
    "    \n",
    "    mse=mean_squared_error(y_test_np, y_pred_test_np)\n",
    "    mse='{:.3f}'.format(mse)\n",
    "    mae=mean_absolute_error(y_test_np, y_pred_test_np)\n",
    "    mae='{:.3f}'.format(mae)\n",
    "    try:\n",
    "        a, b = np.polyfit(y_test_np, y_pred_test_np, 1)\n",
    "        plot_a = '{:.3f}'.format(a[0])\n",
    "        plot_b = '{:.3f}'.format(b[0])\n",
    "    except np.linalg.LinAlgError:\n",
    "        pass\n",
    "        # 'index':np.array(Y_test.index),'ID':np.array(Y_test.index +1),\n",
    "    y_pred_test_np = y_test_pred.squeeze()\n",
    "    csv_df=pd.DataFrame({'index':np.array(Y_test.index),'ID':np.array(Y_test.index +1),'y_true': y_test_np, 'y_pred': y_pred_test_np})\n",
    "    csv_df.to_csv(csv_name,index=None)\n",
    "\n",
    "    csv_df_stats=pd.DataFrame(data=np.array([[resample, r2, rmsd, bias, sdep, plot_a, plot_b, mse, mae]]),\n",
    "                              # index=None, \n",
    "                              columns=['resample','r2','rmsd', 'bias', 'sdep', 'plot_a', 'plot_b', 'mse', 'mae'])\n",
    "    csv_df_stats.to_csv(f'{csv_name[:-4]}_stats.csv',mode='a',index='resample')\n",
    "    \n",
    "    return csv_df\n",
    "\n",
    "\n",
    "\n",
    "set_types = ['train','val','test']\n",
    "# set_type = 'test'\n",
    "# csv_name=f'{directory_path}/{set_type}.csv'\n",
    "# csv_name=f'{set_type}.csv'\n",
    "\n",
    "list_indexes = [train, val, test]\n",
    "index_counter=-1\n",
    "for indexes in list_indexes:\n",
    "    index_counter+=1\n",
    "    csv_name=f'{directory_path}/{set_types[index_counter]}.csv'\n",
    "    y_1,  y_2,  y_3,  y_4,  Y,  X_padded,  X  = load_xy(indexes,desc)\n",
    "    predictions = test_model.predict(X_padded)\n",
    "    csv_df = stats_csv(predictions, Y, prop, csv_name, set_types[index_counter],resample)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29257a01-0b0e-4fa8-84dd-7ed07b3395ba",
   "metadata": {},
   "source": [
    "# Dev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "id": "784ccad1-3367-4cec-a58d-1c4ec09c105c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "r2_dH_0    0.949\n",
       "r2_dH_1    0.941\n",
       "r2_dH_2    0.941\n",
       "r2_dH_3    0.925\n",
       "r2_dH_4    0.932\n",
       "dtype: object"
      ]
     },
     "execution_count": 262,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_combine = pd.DataFrame()\n",
    "df_summary = pd.DataFrame()\n",
    "df_combine_all = pd.DataFrame()\n",
    "\n",
    "for resample in range(1):\n",
    "    for prop in GSHT_list[0:1]:\n",
    "        print(prop)\n",
    "        for fold in range(5):\n",
    "            dir = path_fold(home, resample, fold)\n",
    "            model_name = f\"1DConv_st_{prop}\"\n",
    "            try:\n",
    "                df_read=pd.read_csv(f'{dir}/{desc}/{model_name}/{prop}_{fold}.csv')\n",
    "                # Combine\n",
    "                df_combine=pd.concat([df_combine,df_read],\n",
    "                                    axis=1)\n",
    "            except:\n",
    "                pass\n",
    "                \n",
    "            count=0\n",
    "    df_combine = df_combine.T.drop_duplicates().T\n",
    "        # Append to summary\n",
    "             \n",
    "        # append Combine all_all\n",
    "# df_read=pd.read_csv(f'{dir}/{desc}/{model_name}/{prop}_{fold}.csv')\n",
    "# df_combine.to_csv('test.csv')\n",
    "df_combine.filter(regex=f'^r2_').max()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6aaf6bc8-7e7a-49fe-a109-32dc21dcece9",
   "metadata": {},
   "source": [
    "## Quality check r2 is near 1 for Tm, dS, dG,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "id": "54068c86-2e11-4290-8ebe-52816b37118f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reloading Tuner from /users/qdb16186/CNN_stk/CV/0/4/Granulated/1DConv_st_Tm/tunner/16/tuner0.json\n",
      "WARNING:tensorflow:Detecting that an object or model or tf.train.Checkpoint is being deleted with unrestored values. See the following logs for the specific values in question. To silence these warnings, use `status.expect_partial()`. See https://www.tensorflow.org/api_docs/python/tf/train/Checkpoint#restorefor details about the status object returned by the restore function.\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.1\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.2\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.3\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.4\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.5\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.6\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.7\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.8\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.9\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.10\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.11\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.12\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.13\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.14\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.15\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.16\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.17\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.18\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.19\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.20\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.21\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.22\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.23\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.24\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.25\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.26\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.27\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.28\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.29\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.30\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.31\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.32\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.33\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.34\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.35\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.36\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.37\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.38\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.39\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.40\n",
      "2/2 [==============================] - 0s 4ms/step\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>trial</th>\n",
       "      <th>model_type1</th>\n",
       "      <th>model_type</th>\n",
       "      <th>layer_3_3</th>\n",
       "      <th>layer_2_2</th>\n",
       "      <th>layer_1</th>\n",
       "      <th>r2_Tm_4</th>\n",
       "      <th>rmsd_Tm_4</th>\n",
       "      <th>bias_Tm_4</th>\n",
       "      <th>SDEP_Tm_4</th>\n",
       "      <th>gradient_Tm_4</th>\n",
       "      <th>b_Tm_4</th>\n",
       "      <th>mse_Tm_4</th>\n",
       "      <th>mae_Tm_4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>a</th>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0000</th>\n",
       "      <td>0000</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>-77.216</td>\n",
       "      <td>119.505</td>\n",
       "      <td>-114.436</td>\n",
       "      <td>25.577</td>\n",
       "      <td>-1.456</td>\n",
       "      <td>-9.267</td>\n",
       "      <td>14281.389</td>\n",
       "      <td>114.436</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     trial model_type1 model_type layer_3_3 layer_2_2 layer_1  r2_Tm_4  \\\n",
       "a     None        None       None      None      None    None     None   \n",
       "0000  0000        None       None      None      None    None  -77.216   \n",
       "\n",
       "     rmsd_Tm_4 bias_Tm_4 SDEP_Tm_4 gradient_Tm_4  b_Tm_4   mse_Tm_4 mae_Tm_4  \n",
       "a         None      None      None          None    None       None     None  \n",
       "0000   119.505  -114.436    25.577        -1.456  -9.267  14281.389  114.436  "
      ]
     },
     "execution_count": 303,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# trial_number=str(dir_.replace(\"trial_\",\"\"))\n",
    "\n",
    "keyList = ['trial',\n",
    "               'model_type1', 'model_type',\n",
    "               'layer_3_3', 'layer_2_2', 'layer_1',\n",
    "               f'r2_{prop}_{fold}',\n",
    "               f'rmsd_{prop}_{fold}',\n",
    "               f'bias_{prop}_{fold}',\n",
    "               f'SDEP_{prop}_{fold}',\n",
    "               f'gradient_{prop}_{fold}',\n",
    "               f'b_{prop}_{fold}',\n",
    "               f'mse_{prop}_{fold}',\n",
    "               f'mae_{prop}_{fold}']\n",
    "n = dict(zip(keyList, [None]*len(keyList)))\n",
    "    \n",
    "df_grid=pd.DataFrame(n,index=['a'])\n",
    "tunner_path =f\"{dir}/{desc}/{model_name}/tunner\"\n",
    "tuner = kt.GridSearch(build_model,\n",
    "                       objective=kt.Objective('val_loss', 'min'),\n",
    "                        # loss = 'val_loss',\n",
    "                       # objective = ['val_mse','epoch_entropy_pred_mse','val_free_energy_pred_mse'],\n",
    "                      directory=tunner_path,\n",
    "                      overwrite=False,\n",
    "                      project_name=f'{batch}')\n",
    "trial_number= \"0000\"\n",
    "trial=tuner.oracle.get_trial(trial_number)\n",
    "model=tuner.load_model(trial)\n",
    "\n",
    "# train, val, test = access_resample_csv(df,home,resample)\n",
    "train_fold, val_fold, test_fold = access_fold_csv(df,home,resample,fold)\n",
    "\n",
    "y_1_train, y_2_train, y_3_train, y_4_train, Y_train, X_padded_train, X_train = load_xy(train_fold,desc)\n",
    "y_1_val,   y_2_val,   y_3_val,   y_4_val,   Y_val,   X_padded_val,   X_val   = load_xy(val_fold,desc)\n",
    "y_1_test,  y_2_test,  y_3_test,  y_4_test,  Y_test,  X_padded_test,  X_test  = load_xy(test_fold,desc)\n",
    "\n",
    "y_test_pred = model.predict(X_padded_test)\n",
    "\n",
    "r2, rmsd, bias, sdep, plot_a, plot_b, mse, mae = stats_hp(y_test_pred, Y_test, prop)\n",
    "if trial_number in df_grid.index:\n",
    "    n = df_grid.loc[trial_number].to_dict()\n",
    "n.update({\"trial\":trial_number,})\n",
    "n.update({f'r2_{prop}_{fold}':r2,f'rmsd_{prop}_{fold}': rmsd, \n",
    "          f'bias_{prop}_{fold}': bias, f'SDEP_{prop}_{fold}': sdep,\n",
    "          f'gradient_{prop}_{fold}': plot_a, f'b_{prop}_{fold}': plot_b, \n",
    "          f'mse_{prop}_{fold}':mse, f'mae_{prop}_{fold}':mae,})\n",
    "\n",
    "df_grid.loc[f'{trial_number}']=n\n",
    "df_grid\n",
    "# df_grid.to_csv(f'{dir}/{desc}/{model_name}/{prop}_{fold}.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "id": "dd2eb14b-aed2-4c78-9a8f-6edad69b4c29",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ -70.89455 ],\n",
       "       [ -61.303577],\n",
       "       [ -48.985935],\n",
       "       [ -58.889317],\n",
       "       [ -60.54698 ],\n",
       "       [ -64.19579 ],\n",
       "       [ -62.51336 ],\n",
       "       [ -60.31459 ],\n",
       "       [ -62.39605 ],\n",
       "       [ -88.56169 ],\n",
       "       [ -70.2349  ],\n",
       "       [ -54.926983],\n",
       "       [ -69.96466 ],\n",
       "       [ -71.48666 ],\n",
       "       [ -67.105774],\n",
       "       [ -93.73913 ],\n",
       "       [ -74.96023 ],\n",
       "       [-114.72769 ],\n",
       "       [ -82.142876],\n",
       "       [ -28.205814],\n",
       "       [ -57.142204],\n",
       "       [ -60.29847 ],\n",
       "       [-113.06404 ],\n",
       "       [ -50.81727 ],\n",
       "       [ -63.179466],\n",
       "       [ -46.530346],\n",
       "       [-115.39568 ],\n",
       "       [-115.31091 ],\n",
       "       [ -60.80287 ],\n",
       "       [ -63.58795 ],\n",
       "       [ -88.15382 ],\n",
       "       [ -59.3305  ],\n",
       "       [-117.883316],\n",
       "       [-118.450226],\n",
       "       [-111.86006 ],\n",
       "       [ -60.717278],\n",
       "       [ -62.408756],\n",
       "       [ -59.25267 ],\n",
       "       [ -63.498764],\n",
       "       [ -61.32525 ],\n",
       "       [ -57.973038],\n",
       "       [ -61.160408],\n",
       "       [ -48.69654 ],\n",
       "       [ -76.624626],\n",
       "       [ -63.049324]], dtype=float32)"
      ]
     },
     "execution_count": 304,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "id": "999b778b-5a76-4a79-8b1f-7d5e0f39ac49",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dH</th>\n",
       "      <th>dS</th>\n",
       "      <th>dG</th>\n",
       "      <th>Tm</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-78.3</td>\n",
       "      <td>-231.0</td>\n",
       "      <td>-6.7</td>\n",
       "      <td>32.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>-54.6</td>\n",
       "      <td>-151.0</td>\n",
       "      <td>-7.9</td>\n",
       "      <td>36.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>-45.4</td>\n",
       "      <td>-128.0</td>\n",
       "      <td>-5.7</td>\n",
       "      <td>22.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>-65.6</td>\n",
       "      <td>-191.0</td>\n",
       "      <td>-6.4</td>\n",
       "      <td>29.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>-58.6</td>\n",
       "      <td>-164.0</td>\n",
       "      <td>-7.6</td>\n",
       "      <td>35.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>-60.0</td>\n",
       "      <td>-166.0</td>\n",
       "      <td>-8.4</td>\n",
       "      <td>40.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>-62.0</td>\n",
       "      <td>-170.0</td>\n",
       "      <td>-9.4</td>\n",
       "      <td>46.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>-47.9</td>\n",
       "      <td>-129.0</td>\n",
       "      <td>-7.8</td>\n",
       "      <td>36.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>-57.9</td>\n",
       "      <td>-162.0</td>\n",
       "      <td>-7.8</td>\n",
       "      <td>35.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>-76.2</td>\n",
       "      <td>-213.0</td>\n",
       "      <td>-10.1</td>\n",
       "      <td>46.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>-76.3</td>\n",
       "      <td>-220.0</td>\n",
       "      <td>-8.2</td>\n",
       "      <td>37.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>-59.0</td>\n",
       "      <td>-172.0</td>\n",
       "      <td>-5.7</td>\n",
       "      <td>25.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>-71.3</td>\n",
       "      <td>-206.0</td>\n",
       "      <td>-7.5</td>\n",
       "      <td>34.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>-75.1</td>\n",
       "      <td>-213.0</td>\n",
       "      <td>-9.0</td>\n",
       "      <td>41.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>-74.9</td>\n",
       "      <td>-216.0</td>\n",
       "      <td>-7.9</td>\n",
       "      <td>36.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>-104.0</td>\n",
       "      <td>-291.0</td>\n",
       "      <td>-13.8</td>\n",
       "      <td>55.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>-56.8</td>\n",
       "      <td>-157.0</td>\n",
       "      <td>-8.1</td>\n",
       "      <td>37.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>-123.4</td>\n",
       "      <td>-337.0</td>\n",
       "      <td>-18.8</td>\n",
       "      <td>67.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>-82.5</td>\n",
       "      <td>-227.0</td>\n",
       "      <td>-12.2</td>\n",
       "      <td>53.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>-30.6</td>\n",
       "      <td>-86.0</td>\n",
       "      <td>-4.0</td>\n",
       "      <td>4.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>-58.2</td>\n",
       "      <td>-164.0</td>\n",
       "      <td>-7.5</td>\n",
       "      <td>36.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110</th>\n",
       "      <td>-58.8</td>\n",
       "      <td>-163.0</td>\n",
       "      <td>-8.3</td>\n",
       "      <td>38.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111</th>\n",
       "      <td>-116.3</td>\n",
       "      <td>-317.0</td>\n",
       "      <td>-18.0</td>\n",
       "      <td>66.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120</th>\n",
       "      <td>-38.7</td>\n",
       "      <td>-97.0</td>\n",
       "      <td>-8.7</td>\n",
       "      <td>46.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125</th>\n",
       "      <td>-60.9</td>\n",
       "      <td>-165.0</td>\n",
       "      <td>-9.7</td>\n",
       "      <td>46.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128</th>\n",
       "      <td>-40.4</td>\n",
       "      <td>-110.0</td>\n",
       "      <td>-6.2</td>\n",
       "      <td>24.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131</th>\n",
       "      <td>-118.2</td>\n",
       "      <td>-324.0</td>\n",
       "      <td>-17.8</td>\n",
       "      <td>64.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>136</th>\n",
       "      <td>-120.8</td>\n",
       "      <td>-330.0</td>\n",
       "      <td>-18.3</td>\n",
       "      <td>66.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140</th>\n",
       "      <td>-60.3</td>\n",
       "      <td>-169.0</td>\n",
       "      <td>-7.9</td>\n",
       "      <td>36.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141</th>\n",
       "      <td>-64.7</td>\n",
       "      <td>-182.0</td>\n",
       "      <td>-8.3</td>\n",
       "      <td>38.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142</th>\n",
       "      <td>-89.5</td>\n",
       "      <td>-246.0</td>\n",
       "      <td>-13.2</td>\n",
       "      <td>56.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>-59.6</td>\n",
       "      <td>-168.0</td>\n",
       "      <td>-7.5</td>\n",
       "      <td>34.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>150</th>\n",
       "      <td>-119.6</td>\n",
       "      <td>-325.0</td>\n",
       "      <td>-18.7</td>\n",
       "      <td>67.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>155</th>\n",
       "      <td>-119.5</td>\n",
       "      <td>-326.0</td>\n",
       "      <td>-18.2</td>\n",
       "      <td>66.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156</th>\n",
       "      <td>-93.3</td>\n",
       "      <td>-251.0</td>\n",
       "      <td>-15.6</td>\n",
       "      <td>64.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>164</th>\n",
       "      <td>-66.2</td>\n",
       "      <td>-183.0</td>\n",
       "      <td>-9.3</td>\n",
       "      <td>44.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>-71.0</td>\n",
       "      <td>-196.0</td>\n",
       "      <td>-10.2</td>\n",
       "      <td>47.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>171</th>\n",
       "      <td>-56.3</td>\n",
       "      <td>-155.0</td>\n",
       "      <td>-8.3</td>\n",
       "      <td>38.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>173</th>\n",
       "      <td>-67.9</td>\n",
       "      <td>-189.0</td>\n",
       "      <td>-9.4</td>\n",
       "      <td>43.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>178</th>\n",
       "      <td>-61.3</td>\n",
       "      <td>-168.0</td>\n",
       "      <td>-9.2</td>\n",
       "      <td>43.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>182</th>\n",
       "      <td>-58.3</td>\n",
       "      <td>-162.0</td>\n",
       "      <td>-8.1</td>\n",
       "      <td>37.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>183</th>\n",
       "      <td>-56.3</td>\n",
       "      <td>-155.0</td>\n",
       "      <td>-8.3</td>\n",
       "      <td>38.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200</th>\n",
       "      <td>-37.5</td>\n",
       "      <td>-100.0</td>\n",
       "      <td>-6.5</td>\n",
       "      <td>25.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>203</th>\n",
       "      <td>-74.1</td>\n",
       "      <td>-201.0</td>\n",
       "      <td>-11.8</td>\n",
       "      <td>53.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>210</th>\n",
       "      <td>-64.2</td>\n",
       "      <td>-175.0</td>\n",
       "      <td>-9.9</td>\n",
       "      <td>46.8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        dH     dS    dG    Tm\n",
       "2    -78.3 -231.0  -6.7  32.0\n",
       "5    -54.6 -151.0  -7.9  36.0\n",
       "6    -45.4 -128.0  -5.7  22.4\n",
       "13   -65.6 -191.0  -6.4  29.7\n",
       "23   -58.6 -164.0  -7.6  35.9\n",
       "32   -60.0 -166.0  -8.4  40.0\n",
       "42   -62.0 -170.0  -9.4  46.0\n",
       "43   -47.9 -129.0  -7.8  36.6\n",
       "45   -57.9 -162.0  -7.8  35.4\n",
       "46   -76.2 -213.0 -10.1  46.2\n",
       "48   -76.3 -220.0  -8.2  37.5\n",
       "50   -59.0 -172.0  -5.7  25.4\n",
       "65   -71.3 -206.0  -7.5  34.7\n",
       "68   -75.1 -213.0  -9.0  41.6\n",
       "70   -74.9 -216.0  -7.9  36.8\n",
       "71  -104.0 -291.0 -13.8  55.3\n",
       "72   -56.8 -157.0  -8.1  37.9\n",
       "81  -123.4 -337.0 -18.8  67.1\n",
       "95   -82.5 -227.0 -12.2  53.4\n",
       "98   -30.6  -86.0  -4.0   4.4\n",
       "102  -58.2 -164.0  -7.5  36.0\n",
       "110  -58.8 -163.0  -8.3  38.6\n",
       "111 -116.3 -317.0 -18.0  66.3\n",
       "120  -38.7  -97.0  -8.7  46.0\n",
       "125  -60.9 -165.0  -9.7  46.3\n",
       "128  -40.4 -110.0  -6.2  24.7\n",
       "131 -118.2 -324.0 -17.8  64.9\n",
       "136 -120.8 -330.0 -18.3  66.5\n",
       "140  -60.3 -169.0  -7.9  36.7\n",
       "141  -64.7 -182.0  -8.3  38.5\n",
       "142  -89.5 -246.0 -13.2  56.3\n",
       "145  -59.6 -168.0  -7.5  34.7\n",
       "150 -119.6 -325.0 -18.7  67.9\n",
       "155 -119.5 -326.0 -18.2  66.7\n",
       "156  -93.3 -251.0 -15.6  64.1\n",
       "164  -66.2 -183.0  -9.3  44.2\n",
       "168  -71.0 -196.0 -10.2  47.2\n",
       "171  -56.3 -155.0  -8.3  38.5\n",
       "173  -67.9 -189.0  -9.4  43.2\n",
       "178  -61.3 -168.0  -9.2  43.4\n",
       "182  -58.3 -162.0  -8.1  37.6\n",
       "183  -56.3 -155.0  -8.3  38.5\n",
       "200  -37.5 -100.0  -6.5  25.3\n",
       "203  -74.1 -201.0 -11.8  53.8\n",
       "210  -64.2 -175.0  -9.9  46.8"
      ]
     },
     "execution_count": 305,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29fc76b4-a18c-47c0-85f1-d7b5ba40e35b",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Analysis to extract, select based on Test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "id": "e7ea689c-633a-4d81-bce2-dd17acef9498",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>trial</th>\n",
       "      <th>model_type1</th>\n",
       "      <th>model_type</th>\n",
       "      <th>layer_3_3</th>\n",
       "      <th>layer_2_2</th>\n",
       "      <th>layer_1</th>\n",
       "      <th>r2_dH_0</th>\n",
       "      <th>rmsd_dH_0</th>\n",
       "      <th>bias_dH_0</th>\n",
       "      <th>...</th>\n",
       "      <th>mse_dH_3</th>\n",
       "      <th>mae_dH_3</th>\n",
       "      <th>r2_dH_4</th>\n",
       "      <th>rmsd_dH_4</th>\n",
       "      <th>bias_dH_4</th>\n",
       "      <th>SDEP_dH_4</th>\n",
       "      <th>gradient_dH_4</th>\n",
       "      <th>b_dH_4</th>\n",
       "      <th>mse_dH_4</th>\n",
       "      <th>mae_dH_4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>a</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0049</td>\n",
       "      <td>49.0</td>\n",
       "      <td>CNN2</td>\n",
       "      <td>Dense3</td>\n",
       "      <td>32.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>0.928</td>\n",
       "      <td>5.906</td>\n",
       "      <td>-2.318</td>\n",
       "      <td>...</td>\n",
       "      <td>26.489</td>\n",
       "      <td>4.033</td>\n",
       "      <td>0.912</td>\n",
       "      <td>6.993</td>\n",
       "      <td>0.393</td>\n",
       "      <td>31.911</td>\n",
       "      <td>0.873</td>\n",
       "      <td>-8.621</td>\n",
       "      <td>48.906</td>\n",
       "      <td>5.393</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0041</td>\n",
       "      <td>41.0</td>\n",
       "      <td>CNN3</td>\n",
       "      <td>Dense3</td>\n",
       "      <td>64.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>128.0</td>\n",
       "      <td>0.926</td>\n",
       "      <td>6.004</td>\n",
       "      <td>-1.363</td>\n",
       "      <td>...</td>\n",
       "      <td>26.305</td>\n",
       "      <td>4.023</td>\n",
       "      <td>0.913</td>\n",
       "      <td>6.953</td>\n",
       "      <td>1.605</td>\n",
       "      <td>33.192</td>\n",
       "      <td>0.951</td>\n",
       "      <td>-1.89</td>\n",
       "      <td>48.348</td>\n",
       "      <td>5.406</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0092</td>\n",
       "      <td>92.0</td>\n",
       "      <td>CNN2</td>\n",
       "      <td>Dense3</td>\n",
       "      <td>64.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>128.0</td>\n",
       "      <td>0.926</td>\n",
       "      <td>5.992</td>\n",
       "      <td>-0.463</td>\n",
       "      <td>...</td>\n",
       "      <td>64.941</td>\n",
       "      <td>5.324</td>\n",
       "      <td>0.904</td>\n",
       "      <td>7.298</td>\n",
       "      <td>1.723</td>\n",
       "      <td>32.734</td>\n",
       "      <td>0.919</td>\n",
       "      <td>-3.99</td>\n",
       "      <td>53.266</td>\n",
       "      <td>5.74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>CNN3</td>\n",
       "      <td>Dense3</td>\n",
       "      <td>16.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>0.94</td>\n",
       "      <td>5.421</td>\n",
       "      <td>-0.981</td>\n",
       "      <td>...</td>\n",
       "      <td>23.64</td>\n",
       "      <td>3.64</td>\n",
       "      <td>0.907</td>\n",
       "      <td>7.19</td>\n",
       "      <td>2.528</td>\n",
       "      <td>32.216</td>\n",
       "      <td>0.894</td>\n",
       "      <td>-5.017</td>\n",
       "      <td>51.699</td>\n",
       "      <td>5.955</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140</th>\n",
       "      <td>0134</td>\n",
       "      <td>134.0</td>\n",
       "      <td>CNN1</td>\n",
       "      <td>Dense3</td>\n",
       "      <td>64.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>128.0</td>\n",
       "      <td>0.929</td>\n",
       "      <td>5.896</td>\n",
       "      <td>-0.705</td>\n",
       "      <td>...</td>\n",
       "      <td>23.955</td>\n",
       "      <td>3.979</td>\n",
       "      <td>0.917</td>\n",
       "      <td>6.786</td>\n",
       "      <td>1.333</td>\n",
       "      <td>33.167</td>\n",
       "      <td>0.951</td>\n",
       "      <td>-2.173</td>\n",
       "      <td>46.054</td>\n",
       "      <td>5.248</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141</th>\n",
       "      <td>0096</td>\n",
       "      <td>96.0</td>\n",
       "      <td>CNN1</td>\n",
       "      <td>Dense3</td>\n",
       "      <td>16.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>0.925</td>\n",
       "      <td>6.025</td>\n",
       "      <td>-0.463</td>\n",
       "      <td>...</td>\n",
       "      <td>22.892</td>\n",
       "      <td>3.748</td>\n",
       "      <td>0.929</td>\n",
       "      <td>6.284</td>\n",
       "      <td>1.086</td>\n",
       "      <td>32.755</td>\n",
       "      <td>0.931</td>\n",
       "      <td>-3.774</td>\n",
       "      <td>39.495</td>\n",
       "      <td>4.824</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142</th>\n",
       "      <td>0129</td>\n",
       "      <td>129.0</td>\n",
       "      <td>CNN1</td>\n",
       "      <td>Dense3</td>\n",
       "      <td>16.0</td>\n",
       "      <td>128.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>0.932</td>\n",
       "      <td>5.743</td>\n",
       "      <td>-0.642</td>\n",
       "      <td>...</td>\n",
       "      <td>22.894</td>\n",
       "      <td>3.778</td>\n",
       "      <td>0.912</td>\n",
       "      <td>6.974</td>\n",
       "      <td>1.2</td>\n",
       "      <td>33.339</td>\n",
       "      <td>0.958</td>\n",
       "      <td>-1.764</td>\n",
       "      <td>48.64</td>\n",
       "      <td>5.222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>143</th>\n",
       "      <td>0139</td>\n",
       "      <td>139.0</td>\n",
       "      <td>CNN1</td>\n",
       "      <td>Dense3</td>\n",
       "      <td>32.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>128.0</td>\n",
       "      <td>0.932</td>\n",
       "      <td>5.774</td>\n",
       "      <td>-0.016</td>\n",
       "      <td>...</td>\n",
       "      <td>29.685</td>\n",
       "      <td>4.112</td>\n",
       "      <td>0.918</td>\n",
       "      <td>6.742</td>\n",
       "      <td>1.448</td>\n",
       "      <td>33.453</td>\n",
       "      <td>0.969</td>\n",
       "      <td>-0.783</td>\n",
       "      <td>45.451</td>\n",
       "      <td>5.245</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>144</th>\n",
       "      <td>0024</td>\n",
       "      <td>24.0</td>\n",
       "      <td>CNN3</td>\n",
       "      <td>Dense3</td>\n",
       "      <td>16.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>0.945</td>\n",
       "      <td>5.163</td>\n",
       "      <td>-1.184</td>\n",
       "      <td>...</td>\n",
       "      <td>26.559</td>\n",
       "      <td>3.984</td>\n",
       "      <td>0.908</td>\n",
       "      <td>7.132</td>\n",
       "      <td>2.534</td>\n",
       "      <td>32.54</td>\n",
       "      <td>0.913</td>\n",
       "      <td>-3.616</td>\n",
       "      <td>50.867</td>\n",
       "      <td>5.707</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>145 rows × 47 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Unnamed: 0  trial model_type1 model_type layer_3_3 layer_2_2 layer_1  \\\n",
       "0            a    NaN         NaN        NaN       NaN       NaN     NaN   \n",
       "1         0049   49.0        CNN2     Dense3      32.0      16.0    16.0   \n",
       "2         0041   41.0        CNN3     Dense3      64.0      32.0   128.0   \n",
       "3         0092   92.0        CNN2     Dense3      64.0      64.0   128.0   \n",
       "4         0000    0.0        CNN3     Dense3      16.0      16.0    16.0   \n",
       "..         ...    ...         ...        ...       ...       ...     ...   \n",
       "140       0134  134.0        CNN1     Dense3      64.0      16.0   128.0   \n",
       "141       0096   96.0        CNN1     Dense3      16.0      16.0    16.0   \n",
       "142       0129  129.0        CNN1     Dense3      16.0     128.0    64.0   \n",
       "143       0139  139.0        CNN1     Dense3      32.0      64.0   128.0   \n",
       "144       0024   24.0        CNN3     Dense3      16.0      16.0    64.0   \n",
       "\n",
       "    r2_dH_0 rmsd_dH_0 bias_dH_0  ... mse_dH_3 mae_dH_3 r2_dH_4 rmsd_dH_4  \\\n",
       "0       NaN       NaN       NaN  ...      NaN      NaN     NaN       NaN   \n",
       "1     0.928     5.906    -2.318  ...   26.489    4.033   0.912     6.993   \n",
       "2     0.926     6.004    -1.363  ...   26.305    4.023   0.913     6.953   \n",
       "3     0.926     5.992    -0.463  ...   64.941    5.324   0.904     7.298   \n",
       "4      0.94     5.421    -0.981  ...    23.64     3.64   0.907      7.19   \n",
       "..      ...       ...       ...  ...      ...      ...     ...       ...   \n",
       "140   0.929     5.896    -0.705  ...   23.955    3.979   0.917     6.786   \n",
       "141   0.925     6.025    -0.463  ...   22.892    3.748   0.929     6.284   \n",
       "142   0.932     5.743    -0.642  ...   22.894    3.778   0.912     6.974   \n",
       "143   0.932     5.774    -0.016  ...   29.685    4.112   0.918     6.742   \n",
       "144   0.945     5.163    -1.184  ...   26.559    3.984   0.908     7.132   \n",
       "\n",
       "    bias_dH_4 SDEP_dH_4 gradient_dH_4 b_dH_4 mse_dH_4 mae_dH_4  \n",
       "0         NaN       NaN           NaN    NaN      NaN      NaN  \n",
       "1       0.393    31.911         0.873 -8.621   48.906    5.393  \n",
       "2       1.605    33.192         0.951  -1.89   48.348    5.406  \n",
       "3       1.723    32.734         0.919  -3.99   53.266     5.74  \n",
       "4       2.528    32.216         0.894 -5.017   51.699    5.955  \n",
       "..        ...       ...           ...    ...      ...      ...  \n",
       "140     1.333    33.167         0.951 -2.173   46.054    5.248  \n",
       "141     1.086    32.755         0.931 -3.774   39.495    4.824  \n",
       "142       1.2    33.339         0.958 -1.764    48.64    5.222  \n",
       "143     1.448    33.453         0.969 -0.783   45.451    5.245  \n",
       "144     2.534     32.54         0.913 -3.616   50.867    5.707  \n",
       "\n",
       "[145 rows x 47 columns]"
      ]
     },
     "execution_count": 263,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# df_combine=df_combine.dropna()\n",
    "# df_combine.loc[df_combine['r2_dH_mean'].idxmax()]\n",
    "df_combine.columns\n",
    "df_combine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "7f5b3035-3efb-4404-b77a-5ffb00a2fc85",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_combine_all = pd.DataFrame()\n",
    "df_summary = pd.DataFrame()\n",
    "for prop in GSHT_list:\n",
    "    try:\n",
    "        for stat in stats_list:\n",
    "            columns_to_compute = df_combine.filter(regex=f'^{stat}_{prop}')\n",
    "            # print(columns_to_compute)\n",
    "            # Compute mean and std for the specified columns\n",
    "            mean_values = df_combine.filter(regex=f'^{stat}_{prop}').mean(axis=1)\n",
    "            std_values = df_combine.filter(regex=f'^{stat}_{prop}').std(axis=1)\n",
    "            df_combine_all[f'{stat}_{prop}_mean'] = mean_values\n",
    "            df_combine_all[f'{stat}_{prop}_std']  = std_values\n",
    "            if stat == 'r2' or stat =='rmsd':\n",
    "                df_summary[f'{stat}_{prop}_mean'] = mean_values\n",
    "                df_summary[f'{stat}_{prop}_std']  = std_values\n",
    "    except:\n",
    "        pass\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "ab92b9cb-d552-4cc5-92e3-c17f815b4692",
   "metadata": {},
   "outputs": [],
   "source": [
    "prop='dH'\n",
    "for stat in stats_list:\n",
    "    columns_to_compute = df_combine.filter(regex=f'^{stat}_{prop}')\n",
    "    # print(columns_to_compute)\n",
    "    # Compute mean and std for the specified columns\n",
    "    mean_values = df_combine.filter(regex=f'^{stat}_{prop}').mean(axis=1)\n",
    "    std_values = df_combine.filter(regex=f'^{stat}_{prop}').std(axis=1)\n",
    "    df_combine_all[f'{stat}_{prop}_mean'] = mean_values\n",
    "    df_combine_all[f'{stat}_{prop}_std']  = std_values\n",
    "    if stat == 'r2' or stat =='rmsd':\n",
    "        df_summary[f'{stat}_{prop}_mean'] = mean_values\n",
    "        df_summary[f'{stat}_{prop}_std']  = std_values\n",
    "df_summary['trial_id']=df_combine['Unnamed: 0']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "1f766cb1-83bf-43fc-a10a-a85a3c658229",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>trial</th>\n",
       "      <th>model_type1</th>\n",
       "      <th>model_type</th>\n",
       "      <th>layer_3_3</th>\n",
       "      <th>layer_2_2</th>\n",
       "      <th>layer_1</th>\n",
       "      <th>r2_dH_0</th>\n",
       "      <th>rmsd_dH_0</th>\n",
       "      <th>bias_dH_0</th>\n",
       "      <th>...</th>\n",
       "      <th>mse_dH_3</th>\n",
       "      <th>mae_dH_3</th>\n",
       "      <th>r2_dH_4</th>\n",
       "      <th>rmsd_dH_4</th>\n",
       "      <th>bias_dH_4</th>\n",
       "      <th>SDEP_dH_4</th>\n",
       "      <th>gradient_dH_4</th>\n",
       "      <th>b_dH_4</th>\n",
       "      <th>mse_dH_4</th>\n",
       "      <th>mae_dH_4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>a</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0049</td>\n",
       "      <td>49.0</td>\n",
       "      <td>CNN2</td>\n",
       "      <td>Dense3</td>\n",
       "      <td>32.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>0.928</td>\n",
       "      <td>5.906</td>\n",
       "      <td>-2.318</td>\n",
       "      <td>...</td>\n",
       "      <td>26.489</td>\n",
       "      <td>4.033</td>\n",
       "      <td>0.912</td>\n",
       "      <td>6.993</td>\n",
       "      <td>0.393</td>\n",
       "      <td>31.911</td>\n",
       "      <td>0.873</td>\n",
       "      <td>-8.621</td>\n",
       "      <td>48.906</td>\n",
       "      <td>5.393</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0041</td>\n",
       "      <td>41.0</td>\n",
       "      <td>CNN3</td>\n",
       "      <td>Dense3</td>\n",
       "      <td>64.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>128.0</td>\n",
       "      <td>0.926</td>\n",
       "      <td>6.004</td>\n",
       "      <td>-1.363</td>\n",
       "      <td>...</td>\n",
       "      <td>26.305</td>\n",
       "      <td>4.023</td>\n",
       "      <td>0.913</td>\n",
       "      <td>6.953</td>\n",
       "      <td>1.605</td>\n",
       "      <td>33.192</td>\n",
       "      <td>0.951</td>\n",
       "      <td>-1.89</td>\n",
       "      <td>48.348</td>\n",
       "      <td>5.406</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0092</td>\n",
       "      <td>92.0</td>\n",
       "      <td>CNN2</td>\n",
       "      <td>Dense3</td>\n",
       "      <td>64.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>128.0</td>\n",
       "      <td>0.926</td>\n",
       "      <td>5.992</td>\n",
       "      <td>-0.463</td>\n",
       "      <td>...</td>\n",
       "      <td>64.941</td>\n",
       "      <td>5.324</td>\n",
       "      <td>0.904</td>\n",
       "      <td>7.298</td>\n",
       "      <td>1.723</td>\n",
       "      <td>32.734</td>\n",
       "      <td>0.919</td>\n",
       "      <td>-3.99</td>\n",
       "      <td>53.266</td>\n",
       "      <td>5.74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>CNN3</td>\n",
       "      <td>Dense3</td>\n",
       "      <td>16.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>0.94</td>\n",
       "      <td>5.421</td>\n",
       "      <td>-0.981</td>\n",
       "      <td>...</td>\n",
       "      <td>23.64</td>\n",
       "      <td>3.64</td>\n",
       "      <td>0.907</td>\n",
       "      <td>7.19</td>\n",
       "      <td>2.528</td>\n",
       "      <td>32.216</td>\n",
       "      <td>0.894</td>\n",
       "      <td>-5.017</td>\n",
       "      <td>51.699</td>\n",
       "      <td>5.955</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140</th>\n",
       "      <td>0134</td>\n",
       "      <td>134.0</td>\n",
       "      <td>CNN1</td>\n",
       "      <td>Dense3</td>\n",
       "      <td>64.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>128.0</td>\n",
       "      <td>0.929</td>\n",
       "      <td>5.896</td>\n",
       "      <td>-0.705</td>\n",
       "      <td>...</td>\n",
       "      <td>23.955</td>\n",
       "      <td>3.979</td>\n",
       "      <td>0.917</td>\n",
       "      <td>6.786</td>\n",
       "      <td>1.333</td>\n",
       "      <td>33.167</td>\n",
       "      <td>0.951</td>\n",
       "      <td>-2.173</td>\n",
       "      <td>46.054</td>\n",
       "      <td>5.248</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141</th>\n",
       "      <td>0096</td>\n",
       "      <td>96.0</td>\n",
       "      <td>CNN1</td>\n",
       "      <td>Dense3</td>\n",
       "      <td>16.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>0.925</td>\n",
       "      <td>6.025</td>\n",
       "      <td>-0.463</td>\n",
       "      <td>...</td>\n",
       "      <td>22.892</td>\n",
       "      <td>3.748</td>\n",
       "      <td>0.929</td>\n",
       "      <td>6.284</td>\n",
       "      <td>1.086</td>\n",
       "      <td>32.755</td>\n",
       "      <td>0.931</td>\n",
       "      <td>-3.774</td>\n",
       "      <td>39.495</td>\n",
       "      <td>4.824</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142</th>\n",
       "      <td>0129</td>\n",
       "      <td>129.0</td>\n",
       "      <td>CNN1</td>\n",
       "      <td>Dense3</td>\n",
       "      <td>16.0</td>\n",
       "      <td>128.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>0.932</td>\n",
       "      <td>5.743</td>\n",
       "      <td>-0.642</td>\n",
       "      <td>...</td>\n",
       "      <td>22.894</td>\n",
       "      <td>3.778</td>\n",
       "      <td>0.912</td>\n",
       "      <td>6.974</td>\n",
       "      <td>1.2</td>\n",
       "      <td>33.339</td>\n",
       "      <td>0.958</td>\n",
       "      <td>-1.764</td>\n",
       "      <td>48.64</td>\n",
       "      <td>5.222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>143</th>\n",
       "      <td>0139</td>\n",
       "      <td>139.0</td>\n",
       "      <td>CNN1</td>\n",
       "      <td>Dense3</td>\n",
       "      <td>32.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>128.0</td>\n",
       "      <td>0.932</td>\n",
       "      <td>5.774</td>\n",
       "      <td>-0.016</td>\n",
       "      <td>...</td>\n",
       "      <td>29.685</td>\n",
       "      <td>4.112</td>\n",
       "      <td>0.918</td>\n",
       "      <td>6.742</td>\n",
       "      <td>1.448</td>\n",
       "      <td>33.453</td>\n",
       "      <td>0.969</td>\n",
       "      <td>-0.783</td>\n",
       "      <td>45.451</td>\n",
       "      <td>5.245</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>144</th>\n",
       "      <td>0024</td>\n",
       "      <td>24.0</td>\n",
       "      <td>CNN3</td>\n",
       "      <td>Dense3</td>\n",
       "      <td>16.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>0.945</td>\n",
       "      <td>5.163</td>\n",
       "      <td>-1.184</td>\n",
       "      <td>...</td>\n",
       "      <td>26.559</td>\n",
       "      <td>3.984</td>\n",
       "      <td>0.908</td>\n",
       "      <td>7.132</td>\n",
       "      <td>2.534</td>\n",
       "      <td>32.54</td>\n",
       "      <td>0.913</td>\n",
       "      <td>-3.616</td>\n",
       "      <td>50.867</td>\n",
       "      <td>5.707</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>145 rows × 47 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Unnamed: 0  trial model_type1 model_type layer_3_3 layer_2_2 layer_1  \\\n",
       "0            a    NaN         NaN        NaN       NaN       NaN     NaN   \n",
       "1         0049   49.0        CNN2     Dense3      32.0      16.0    16.0   \n",
       "2         0041   41.0        CNN3     Dense3      64.0      32.0   128.0   \n",
       "3         0092   92.0        CNN2     Dense3      64.0      64.0   128.0   \n",
       "4         0000    0.0        CNN3     Dense3      16.0      16.0    16.0   \n",
       "..         ...    ...         ...        ...       ...       ...     ...   \n",
       "140       0134  134.0        CNN1     Dense3      64.0      16.0   128.0   \n",
       "141       0096   96.0        CNN1     Dense3      16.0      16.0    16.0   \n",
       "142       0129  129.0        CNN1     Dense3      16.0     128.0    64.0   \n",
       "143       0139  139.0        CNN1     Dense3      32.0      64.0   128.0   \n",
       "144       0024   24.0        CNN3     Dense3      16.0      16.0    64.0   \n",
       "\n",
       "    r2_dH_0 rmsd_dH_0 bias_dH_0  ... mse_dH_3 mae_dH_3 r2_dH_4 rmsd_dH_4  \\\n",
       "0       NaN       NaN       NaN  ...      NaN      NaN     NaN       NaN   \n",
       "1     0.928     5.906    -2.318  ...   26.489    4.033   0.912     6.993   \n",
       "2     0.926     6.004    -1.363  ...   26.305    4.023   0.913     6.953   \n",
       "3     0.926     5.992    -0.463  ...   64.941    5.324   0.904     7.298   \n",
       "4      0.94     5.421    -0.981  ...    23.64     3.64   0.907      7.19   \n",
       "..      ...       ...       ...  ...      ...      ...     ...       ...   \n",
       "140   0.929     5.896    -0.705  ...   23.955    3.979   0.917     6.786   \n",
       "141   0.925     6.025    -0.463  ...   22.892    3.748   0.929     6.284   \n",
       "142   0.932     5.743    -0.642  ...   22.894    3.778   0.912     6.974   \n",
       "143   0.932     5.774    -0.016  ...   29.685    4.112   0.918     6.742   \n",
       "144   0.945     5.163    -1.184  ...   26.559    3.984   0.908     7.132   \n",
       "\n",
       "    bias_dH_4 SDEP_dH_4 gradient_dH_4 b_dH_4 mse_dH_4 mae_dH_4  \n",
       "0         NaN       NaN           NaN    NaN      NaN      NaN  \n",
       "1       0.393    31.911         0.873 -8.621   48.906    5.393  \n",
       "2       1.605    33.192         0.951  -1.89   48.348    5.406  \n",
       "3       1.723    32.734         0.919  -3.99   53.266     5.74  \n",
       "4       2.528    32.216         0.894 -5.017   51.699    5.955  \n",
       "..        ...       ...           ...    ...      ...      ...  \n",
       "140     1.333    33.167         0.951 -2.173   46.054    5.248  \n",
       "141     1.086    32.755         0.931 -3.774   39.495    4.824  \n",
       "142       1.2    33.339         0.958 -1.764    48.64    5.222  \n",
       "143     1.448    33.453         0.969 -0.783   45.451    5.245  \n",
       "144     2.534     32.54         0.913 -3.616   50.867    5.707  \n",
       "\n",
       "[145 rows x 47 columns]"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_combine"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad8d0831-39cc-41ef-bc31-f38c51f7bf33",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Select Trial Id with best parameters\n",
    "based on mean max r2 or mean min absolut rmsd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6d6ccd8-e6c3-4461-85cc-b6eec1c909a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Find the trial number with the best hyper paramteres\n",
    "trial_number_fin_model = df_summary.loc[df_summary['r2_dH_mean'].idxmax()]['trial_id']\n",
    "\n",
    "# Load best hyper parameters into a dataframe\n",
    "best_hps=df_combine.loc[df_combine['Unnamed: 0']==trial_number_fin_model][df_combine.columns[2:7]]\n",
    "\n",
    "# Load Hyper parameters for final model\n",
    "hp = kt.HyperParameters()\n",
    "\n",
    "model_type1 = hp.Choice(\"model_type1\", [best_hps.values[0, 0]])\n",
    "model_type = hp.Choice(\"model_type\", [best_hps.values[0, 1]])\n",
    "hp_layer_1= hp.Choice(f'layer_1', values=[best_hps.values[0, 4]])\n",
    "hp_layer_2_2= hp.Choice(f'layer_2_2', values=[best_hps.values[0, 3]])\n",
    "hp_layer_3_3= hp.Choice(f'layer_3_3',  values=[best_hps.values[0, 2]])\n",
    "\n",
    "# Build final model\n",
    "test_model=build_model(hp)\n",
    "\n",
    "# Inputs for training final Model\n",
    "epochs = 300\n",
    "batch  = 16\n",
    "# TODO: Use path lib to create path\n",
    "resample_path = path_resample(home,resample)\n",
    "\n",
    "# model_name = architecture of - Single task/RF/KNN + dH/dG/dS/Tm or - Multitask  \n",
    "prop = 'dH' \n",
    "model_name = f\"1DConv_st_{prop}\" \n",
    "\n",
    "\n",
    "# Define the directory path\n",
    "directory_path = Path(f\"{os.getcwd()}/CV/0/{desc}/{model_name}/\")\n",
    "\n",
    "# Define Paths for call backs\n",
    "csv_logger_path  = Path(f'{directory_path}/csv_logger/')\n",
    "cp_callback_path = Path(f'{directory_path}/model_checkpoint/')\n",
    "tensorboard_path = Path(f'{directory_path}/tensorboard_logs/')\n",
    "\n",
    "# Ensure the directory exists, create it if necessary\n",
    "csv_logger_path.mkdir(parents=True, exist_ok=True)\n",
    "cp_callback_path.mkdir(parents=True, exist_ok=True)\n",
    "tensorboard_path.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "\n",
    "#### CALL BACKS!\n",
    "es = EarlyStopping(monitor      = 'val_loss', \n",
    "                        mode     = 'min', \n",
    "                        verbose  = 1, \n",
    "                        patience = 2000, \n",
    "                    restore_best_weights = True)\n",
    "# CSV Logger\n",
    "csv_logger = CSVLogger(f'{csv_logger_path}/model_history.csv' , append=True)\n",
    "\n",
    "# CP_callbacks      not required when using a tunner       \n",
    "# cp_callback = tf.keras.callbacks.ModelCheckpoint(filepath=f'{cp_callback_path}/cp.ckpt',\n",
    "#                                                  save_weights_only=True,\n",
    "#                                                  verbose=1)\n",
    "\n",
    "# TensorBoard\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=tensorboard_path, \n",
    "                                                       #/{batch}', # _ADAPTIVELEARNIGNRATE_01_10_Dense3_64_3CNN_lr_3_es\n",
    "                                                      update_freq = 1,\n",
    "                                                      # histogram_freq=1, \n",
    "                                                      write_graph=False, \n",
    "                                                      write_images=False)\n",
    "# https://www.tensorflow.org/api_docs/python/tf/keras/callbacks/TensorBoard\n",
    "\n",
    "# Covert to list and provide to Keras Regressor\n",
    "keras_callbacks = [es, csv_logger, tensorboard_callback]\n",
    "\n",
    "# Load resample data\n",
    "y_1_train, y_2_train, y_3_train, y_4_train, Y_train, X_padded_train, X_train = load_xy(train,desc)\n",
    "y_1_val,   y_2_val,   y_3_val,   y_4_val,   Y_val,   X_padded_val,   X_val   = load_xy(val,desc)\n",
    "y_1_test,  y_2_test,  y_3_test,  y_4_test,  Y_test,  X_padded_test,  X_test  = load_xy(test,desc)\n",
    "\n",
    "# Train model on resample data\n",
    "history=test_model.fit(X_padded_train, y_1_train,\n",
    "            epochs = epochs,\n",
    "            batch_size=batch,\n",
    "            verbose = 2,\n",
    "            validation_data =(X_padded_val, y_1_val),\n",
    "             # validation_split = 0.2,\n",
    "            callbacks=keras_callbacks)\n",
    "# Make predictions\n",
    "predictions_test = test_model.predict(X_padded_test)\n",
    "predictions_val = test_model.predict(X_padded_val)\n",
    "predictions_train = test_model.predict(X_padded_train)\n",
    "\n",
    "# Store stats\n",
    "r2, rmsd, bias, sdep, plot_a, plot_b, mse, mae = stats_hp(predictions_test, Y_test, prop)\n",
    "print(f'test: r2 = {r2}] | rmsd = {rmsd}')\n",
    "\n",
    "r2, rmsd, bias, sdep, plot_a, plot_b, mse, mae = stats_hp(predictions_test, Y_val, prop)\n",
    "print(f'val: r2 = {r2}] | rmsd = {rmsd}')\n",
    "\n",
    "r2, rmsd, bias, sdep, plot_a, plot_b, mse, mae = stats_hp(predictions_test, Y_train, prop)\n",
    "print(f'train: r2 = {r2}] | rmsd = {rmsd}')\n",
    "\n",
    "# Store csv files (predictions vs true)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2c1217a-8e49-40e6-9ee4-809a6d1ea3aa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "a9de02c0-70f8-4944-a050-a3422de2e3a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0131\n",
      "1DConv_st_dH\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Index(['model_type1', 'model_type', 'layer_3_3', 'layer_2_2', 'layer_1'], dtype='object')"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trial_number_fin_model = df_summary.loc[df_summary['r2_dH_mean'].idxmax()]['trial_id']\n",
    "print(trial_number_fin_model)\n",
    "print(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "859c1eb6-f493-48cc-9445-edb7d51d46b2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model_type1</th>\n",
       "      <th>model_type</th>\n",
       "      <th>layer_3_3</th>\n",
       "      <th>layer_2_2</th>\n",
       "      <th>layer_1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>CNN1</td>\n",
       "      <td>Dense3</td>\n",
       "      <td>64.0</td>\n",
       "      <td>128.0</td>\n",
       "      <td>64.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   model_type1 model_type layer_3_3 layer_2_2 layer_1\n",
       "33        CNN1     Dense3      64.0     128.0    64.0"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_hps=df_combine.loc[df_combine['Unnamed: 0']==trial_number_fin_model][df_combine.columns[2:7]]\n",
    "best_hps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "id": "e47f1ee6-b689-4efe-b1d5-0dc23b959880",
   "metadata": {},
   "outputs": [],
   "source": [
    "hp = kt.HyperParameters()\n",
    "\n",
    "model_type1 = hp.Choice(\"model_type1\", [best_hps.values[0, 0]])\n",
    "model_type = hp.Choice(\"model_type\", [best_hps.values[0, 1]])\n",
    "hp_layer_1= hp.Choice(f'layer_1', values=[best_hps.values[0, 4]])\n",
    "hp_layer_2_2= hp.Choice(f'layer_2_2', values=[best_hps.values[0, 3]])\n",
    "hp_layer_3_3= hp.Choice(f'layer_3_3',  values=[best_hps.values[0, 2]])\n",
    "\n",
    "test_model=build_model(hp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "id": "8c3c8e3b-4536-45b0-b7d8-2f84d9b9576d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'model_type1': 'CNN1',\n",
       " 'model_type': 'Dense3',\n",
       " 'layer_1': 64.0,\n",
       " 'layer_2_2': 128.0,\n",
       " 'layer_3_3': 64.0}"
      ]
     },
     "execution_count": 197,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "id": "14a60225-d37d-4c97-b99b-8f15280fd23c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/users/qdb16186/CNN_stk'"
      ]
     },
     "execution_count": 204,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "id": "d7f7a3c1-6e72-46c7-b622-fd1fb01dedb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 300\n",
    "batch  = 16\n",
    "# TODO: Use path lib to create path\n",
    "# fold_path = path_fold(home,resample,fold)\n",
    "resample_path = path_resample(home,resample)\n",
    "\n",
    "# model_name = architecture of - Single task/RF/KNN + dH/dG/dS/Tm or - Multitask  \n",
    "prop = 'dH' \n",
    "model_name = f\"1DConv_st_{prop}\" \n",
    "\n",
    "\n",
    "# Define the directory path\n",
    "directory_path = Path(f\"{os.getcwd()}/CV/0/{desc}/{model_name}/\")\n",
    "\n",
    "# tunner_path      = Path(f'{directory_path}/tunner')\n",
    "csv_logger_path  = Path(f'{directory_path}/csv_logger/')\n",
    "cp_callback_path = Path(f'{directory_path}/model_checkpoint/')\n",
    "tensorboard_path = Path(f'{directory_path}/tensorboard_logs/')\n",
    "\n",
    "# Ensure the directory exists, create it if necessary\n",
    "# tunner_path.mkdir(parents=True, exist_ok=True)\n",
    "csv_logger_path.mkdir(parents=True, exist_ok=True)\n",
    "cp_callback_path.mkdir(parents=True, exist_ok=True)\n",
    "tensorboard_path.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "\n",
    "# tuner = kt.GridSearch(build_model,\n",
    "#                    objective=kt.Objective('val_loss', 'min'),\n",
    "#                     # loss = 'val_loss',\n",
    "#                    # objective = ['val_mse','val_free_energy_pred_mse'],\n",
    "#                   directory=tunner_path,\n",
    "#                   overwrite=False,\n",
    "#                   project_name=f'{batch}')\n",
    "\n",
    "# with open(f'{tunner_path}/tuner_path.txt', 'w') as f:\n",
    "#     f.write(tuner.project_dir)\n",
    "# f.close\n",
    "\n",
    "#### CALL BACKS!\n",
    "es = EarlyStopping(monitor      = 'val_loss', \n",
    "                        mode     = 'min', \n",
    "                        verbose  = 1, \n",
    "                        patience = 2000, \n",
    "                    restore_best_weights = True)\n",
    "# CSV Logger\n",
    "csv_logger = CSVLogger(f'{csv_logger_path}/model_history.csv' , append=True)\n",
    "\n",
    "# CP_callbacks      not required when using a tunner       \n",
    "# cp_callback = tf.keras.callbacks.ModelCheckpoint(filepath=f'{cp_callback_path}/cp.ckpt',\n",
    "#                                                  save_weights_only=True,\n",
    "#                                                  verbose=1)\n",
    "\n",
    "# TensorBoard\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=tensorboard_path, \n",
    "                                                       #/{batch}', # _ADAPTIVELEARNIGNRATE_01_10_Dense3_64_3CNN_lr_3_es\n",
    "                                                      update_freq = 1,\n",
    "                                                      # histogram_freq=1, \n",
    "                                                      write_graph=False, \n",
    "                                                      write_images=False)\n",
    "# https://www.tensorflow.org/api_docs/python/tf/keras/callbacks/TensorBoard\n",
    "\n",
    "# Covert to list and provide to Keras Regressor\n",
    "keras_callbacks = [es, csv_logger, tensorboard_callback]\n",
    "\n",
    "\n",
    "# history=tuner.search(x_hp_train, y_hp_train[:],\n",
    "#             epochs = epochs,\n",
    "#             batch_size=batch,\n",
    "#             verbose = 2,\n",
    "#             validation_data =(x_hp_val, y_hp_val[:]),\n",
    "#              # validation_split = 0.2,\n",
    "#             callbacks=keras_callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "id": "10ce6f76-f88a-44f8-b0ca-e34044bdd227",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "y_1_train, y_2_train, y_3_train, y_4_train, Y_train, X_padded_train, X_train = load_xy(train,desc)\n",
    "y_1_val,   y_2_val,   y_3_val,   y_4_val,   Y_val,   X_padded_val,   X_val   = load_xy(val,desc)\n",
    "y_1_test,  y_2_test,  y_3_test,  y_4_test,  Y_test,  X_padded_test,  X_test  = load_xy(test,desc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "id": "0e59f5c5-3f6f-4a85-a417-003a8d3dd816",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n",
      "10/10 - 0s - loss: 138.3230 - mse: 138.3230 - mean_absolute_error: 8.7295 - r2_func_tf: 0.7631 - rmse_func_tf: 9.6737 - bias_func_tf: -6.6587e+00 - sdep_func_tf: 6.0318 - val_loss: 14642.6963 - val_mse: 14642.6963 - val_mean_absolute_error: 111.1787 - val_r2_func_tf: -3.5805e+01 - val_rmse_func_tf: 120.5054 - val_bias_func_tf: 111.1787 - val_sdep_func_tf: 45.6262 - 130ms/epoch - 13ms/step\n",
      "Epoch 2/300\n",
      "10/10 - 0s - loss: 104.1648 - mse: 104.1648 - mean_absolute_error: 8.0470 - r2_func_tf: 0.6905 - rmse_func_tf: 9.3716 - bias_func_tf: 6.1515 - sdep_func_tf: 5.4708 - val_loss: 3840.9956 - val_mse: 3840.9956 - val_mean_absolute_error: 56.2184 - val_r2_func_tf: -8.8258e+00 - val_rmse_func_tf: 61.6983 - val_bias_func_tf: 56.2184 - val_sdep_func_tf: 24.9233 - 91ms/epoch - 9ms/step\n",
      "Epoch 3/300\n",
      "10/10 - 0s - loss: 196.1502 - mse: 196.1502 - mean_absolute_error: 11.1765 - r2_func_tf: 0.5723 - rmse_func_tf: 12.9333 - bias_func_tf: -9.2349e+00 - sdep_func_tf: 6.3817 - val_loss: 5951.8306 - val_mse: 5951.8306 - val_mean_absolute_error: 70.9696 - val_r2_func_tf: -1.4186e+01 - val_rmse_func_tf: 76.8537 - val_bias_func_tf: 70.9696 - val_sdep_func_tf: 28.9038 - 94ms/epoch - 9ms/step\n",
      "Epoch 4/300\n",
      "10/10 - 0s - loss: 156.6572 - mse: 156.6572 - mean_absolute_error: 10.3119 - r2_func_tf: 0.3946 - rmse_func_tf: 11.8765 - bias_func_tf: 7.7787 - sdep_func_tf: 6.1885 - val_loss: 1778.4478 - val_mse: 1778.4478 - val_mean_absolute_error: 38.1737 - val_r2_func_tf: -3.6525e+00 - val_rmse_func_tf: 41.9892 - val_bias_func_tf: 38.1737 - val_sdep_func_tf: 17.0900 - 89ms/epoch - 9ms/step\n",
      "Epoch 5/300\n",
      "10/10 - 0s - loss: 150.2429 - mse: 150.2429 - mean_absolute_error: 10.1901 - r2_func_tf: 0.7006 - rmse_func_tf: 11.1153 - bias_func_tf: -8.9801e+00 - sdep_func_tf: 5.6906 - val_loss: 2026.8770 - val_mse: 2026.8770 - val_mean_absolute_error: 41.1643 - val_r2_func_tf: -4.3095e+00 - val_rmse_func_tf: 44.8476 - val_bias_func_tf: 41.1643 - val_sdep_func_tf: 17.3957 - 88ms/epoch - 9ms/step\n",
      "Epoch 6/300\n",
      "10/10 - 0s - loss: 89.3614 - mse: 89.3614 - mean_absolute_error: 7.6610 - r2_func_tf: 0.5152 - rmse_func_tf: 8.7668 - bias_func_tf: 2.6685 - sdep_func_tf: 5.5400 - val_loss: 1745.8114 - val_mse: 1745.8114 - val_mean_absolute_error: 38.2770 - val_r2_func_tf: -3.6062e+00 - val_rmse_func_tf: 41.6274 - val_bias_func_tf: 38.2770 - val_sdep_func_tf: 15.9827 - 93ms/epoch - 9ms/step\n",
      "Epoch 7/300\n",
      "10/10 - 0s - loss: 67.2946 - mse: 67.2946 - mean_absolute_error: 6.4114 - r2_func_tf: 0.3314 - rmse_func_tf: 7.8230 - bias_func_tf: 1.7591 - sdep_func_tf: 5.4305 - val_loss: 751.9478 - val_mse: 751.9478 - val_mean_absolute_error: 24.6695 - val_r2_func_tf: -1.0445e+00 - val_rmse_func_tf: 27.2922 - val_bias_func_tf: 24.6537 - val_sdep_func_tf: 11.3839 - 96ms/epoch - 10ms/step\n",
      "Epoch 8/300\n",
      "10/10 - 0s - loss: 163.9004 - mse: 163.9004 - mean_absolute_error: 9.8112 - r2_func_tf: 0.2476 - rmse_func_tf: 11.1184 - bias_func_tf: -1.4370e+00 - sdep_func_tf: 5.9210 - val_loss: 630.0557 - val_mse: 630.0557 - val_mean_absolute_error: 22.5296 - val_r2_func_tf: -7.2825e-01 - val_rmse_func_tf: 24.9792 - val_bias_func_tf: 22.4885 - val_sdep_func_tf: 10.5617 - 95ms/epoch - 10ms/step\n",
      "Epoch 9/300\n",
      "10/10 - 0s - loss: 52.1611 - mse: 52.1611 - mean_absolute_error: 5.7673 - r2_func_tf: 0.6451 - rmse_func_tf: 6.9606 - bias_func_tf: -6.2225e-01 - sdep_func_tf: 5.3542 - val_loss: 389.6589 - val_mse: 389.6589 - val_mean_absolute_error: 17.4391 - val_r2_func_tf: -8.9567e-02 - val_rmse_func_tf: 19.6195 - val_bias_func_tf: 17.2611 - val_sdep_func_tf: 9.0199 - 94ms/epoch - 9ms/step\n",
      "Epoch 10/300\n",
      "10/10 - 0s - loss: 88.1461 - mse: 88.1461 - mean_absolute_error: 7.0678 - r2_func_tf: 0.7493 - rmse_func_tf: 8.0359 - bias_func_tf: -1.0098e+00 - sdep_func_tf: 5.2163 - val_loss: 256.6380 - val_mse: 256.6380 - val_mean_absolute_error: 13.8672 - val_r2_func_tf: 0.2688 - val_rmse_func_tf: 15.8973 - val_bias_func_tf: 13.5684 - val_sdep_func_tf: 7.9719 - 91ms/epoch - 9ms/step\n",
      "Epoch 11/300\n",
      "10/10 - 0s - loss: 87.9722 - mse: 87.9722 - mean_absolute_error: 7.3444 - r2_func_tf: 0.7128 - rmse_func_tf: 8.5473 - bias_func_tf: 1.3914 - sdep_func_tf: 5.5698 - val_loss: 274.5332 - val_mse: 274.5332 - val_mean_absolute_error: 14.4789 - val_r2_func_tf: 0.2190 - val_rmse_func_tf: 16.4494 - val_bias_func_tf: 14.2099 - val_sdep_func_tf: 7.9792 - 87ms/epoch - 9ms/step\n",
      "Epoch 12/300\n",
      "10/10 - 0s - loss: 85.4071 - mse: 85.4071 - mean_absolute_error: 7.7909 - r2_func_tf: 0.6905 - rmse_func_tf: 8.8397 - bias_func_tf: -7.9128e-01 - sdep_func_tf: 5.1326 - val_loss: 93.3682 - val_mse: 93.3682 - val_mean_absolute_error: 7.8695 - val_r2_func_tf: 0.7193 - val_rmse_func_tf: 9.5305 - val_bias_func_tf: 6.8913 - val_sdep_func_tf: 6.2125 - 94ms/epoch - 9ms/step\n",
      "Epoch 13/300\n",
      "10/10 - 0s - loss: 55.3277 - mse: 55.3277 - mean_absolute_error: 5.8429 - r2_func_tf: 0.7961 - rmse_func_tf: 7.1515 - bias_func_tf: -9.4779e-01 - sdep_func_tf: 5.0119 - val_loss: 153.3322 - val_mse: 153.3322 - val_mean_absolute_error: 10.4438 - val_r2_func_tf: 0.5492 - val_rmse_func_tf: 12.2529 - val_bias_func_tf: 9.9938 - val_sdep_func_tf: 6.7662 - 93ms/epoch - 9ms/step\n",
      "Epoch 14/300\n",
      "10/10 - 0s - loss: 54.6635 - mse: 54.6635 - mean_absolute_error: 5.7584 - r2_func_tf: 0.8538 - rmse_func_tf: 7.2513 - bias_func_tf: 1.1213 - sdep_func_tf: 5.5711 - val_loss: 68.8666 - val_mse: 68.8666 - val_mean_absolute_error: 6.6587 - val_r2_func_tf: 0.7900 - val_rmse_func_tf: 8.1691 - val_bias_func_tf: 5.3994 - val_sdep_func_tf: 5.7358 - 86ms/epoch - 9ms/step\n",
      "Epoch 15/300\n",
      "10/10 - 0s - loss: 90.4020 - mse: 90.4020 - mean_absolute_error: 7.8388 - r2_func_tf: 0.3014 - rmse_func_tf: 9.0755 - bias_func_tf: -5.8371e-01 - sdep_func_tf: 5.0003 - val_loss: 47.9186 - val_mse: 47.9186 - val_mean_absolute_error: 5.2836 - val_r2_func_tf: 0.8553 - val_rmse_func_tf: 6.8206 - val_bias_func_tf: 3.4715 - val_sdep_func_tf: 5.4176 - 84ms/epoch - 8ms/step\n",
      "Epoch 16/300\n",
      "10/10 - 0s - loss: 100.6141 - mse: 100.6141 - mean_absolute_error: 7.5583 - r2_func_tf: 0.6719 - rmse_func_tf: 8.7562 - bias_func_tf: -7.2128e-01 - sdep_func_tf: 5.4726 - val_loss: 36.9592 - val_mse: 36.9592 - val_mean_absolute_error: 4.4913 - val_r2_func_tf: 0.8922 - val_rmse_func_tf: 6.0041 - val_bias_func_tf: 1.9385 - val_sdep_func_tf: 5.1904 - 89ms/epoch - 9ms/step\n",
      "Epoch 17/300\n",
      "10/10 - 0s - loss: 79.6990 - mse: 79.6990 - mean_absolute_error: 7.3696 - r2_func_tf: 0.3769 - rmse_func_tf: 8.6614 - bias_func_tf: 0.3704 - sdep_func_tf: 5.5982 - val_loss: 36.2897 - val_mse: 36.2897 - val_mean_absolute_error: 4.4435 - val_r2_func_tf: 0.8944 - val_rmse_func_tf: 5.9478 - val_bias_func_tf: 1.8543 - val_sdep_func_tf: 5.1644 - 91ms/epoch - 9ms/step\n",
      "Epoch 18/300\n",
      "10/10 - 0s - loss: 70.0273 - mse: 70.0273 - mean_absolute_error: 6.9781 - r2_func_tf: 0.7061 - rmse_func_tf: 7.9139 - bias_func_tf: 0.8684 - sdep_func_tf: 4.8970 - val_loss: 30.5265 - val_mse: 30.5265 - val_mean_absolute_error: 4.0927 - val_r2_func_tf: 0.9191 - val_rmse_func_tf: 5.4497 - val_bias_func_tf: 0.2320 - val_sdep_func_tf: 4.9555 - 82ms/epoch - 8ms/step\n",
      "Epoch 19/300\n",
      "10/10 - 0s - loss: 102.2725 - mse: 102.2725 - mean_absolute_error: 8.1305 - r2_func_tf: 0.5118 - rmse_func_tf: 9.1521 - bias_func_tf: -8.0874e-01 - sdep_func_tf: 5.3668 - val_loss: 32.5997 - val_mse: 32.5997 - val_mean_absolute_error: 4.5356 - val_r2_func_tf: 0.9269 - val_rmse_func_tf: 5.5833 - val_bias_func_tf: -2.0361e+00 - val_sdep_func_tf: 4.7634 - 87ms/epoch - 9ms/step\n",
      "Epoch 20/300\n",
      "10/10 - 0s - loss: 68.0105 - mse: 68.0105 - mean_absolute_error: 6.4831 - r2_func_tf: 0.7605 - rmse_func_tf: 7.6591 - bias_func_tf: -5.9790e-02 - sdep_func_tf: 5.2844 - val_loss: 30.0633 - val_mse: 30.0633 - val_mean_absolute_error: 4.0279 - val_r2_func_tf: 0.9183 - val_rmse_func_tf: 5.4051 - val_bias_func_tf: 0.6428 - val_sdep_func_tf: 4.8941 - 87ms/epoch - 9ms/step\n",
      "Epoch 21/300\n",
      "10/10 - 0s - loss: 43.5682 - mse: 43.5682 - mean_absolute_error: 5.1420 - r2_func_tf: 0.8830 - rmse_func_tf: 6.6339 - bias_func_tf: -3.5990e-02 - sdep_func_tf: 5.0215 - val_loss: 29.2601 - val_mse: 29.2601 - val_mean_absolute_error: 4.1709 - val_r2_func_tf: 0.9303 - val_rmse_func_tf: 5.3167 - val_bias_func_tf: -1.0923e+00 - val_sdep_func_tf: 4.7311 - 85ms/epoch - 8ms/step\n",
      "Epoch 22/300\n",
      "10/10 - 0s - loss: 44.4288 - mse: 44.4288 - mean_absolute_error: 5.0940 - r2_func_tf: 0.8898 - rmse_func_tf: 6.5613 - bias_func_tf: -7.4049e-01 - sdep_func_tf: 5.4935 - val_loss: 28.5699 - val_mse: 28.5699 - val_mean_absolute_error: 4.0667 - val_r2_func_tf: 0.9300 - val_rmse_func_tf: 5.2646 - val_bias_func_tf: -7.5416e-01 - val_sdep_func_tf: 4.7270 - 84ms/epoch - 8ms/step\n",
      "Epoch 23/300\n",
      "10/10 - 0s - loss: 55.1329 - mse: 55.1329 - mean_absolute_error: 6.0626 - r2_func_tf: 0.8423 - rmse_func_tf: 7.6269 - bias_func_tf: -1.1417e+00 - sdep_func_tf: 5.3402 - val_loss: 28.8461 - val_mse: 28.8461 - val_mean_absolute_error: 4.1290 - val_r2_func_tf: 0.9317 - val_rmse_func_tf: 5.2831 - val_bias_func_tf: -1.1256e+00 - val_sdep_func_tf: 4.6930 - 81ms/epoch - 8ms/step\n",
      "Epoch 24/300\n",
      "10/10 - 0s - loss: 51.4843 - mse: 51.4843 - mean_absolute_error: 5.6363 - r2_func_tf: 0.8747 - rmse_func_tf: 6.8902 - bias_func_tf: 1.2598 - sdep_func_tf: 5.3048 - val_loss: 27.7258 - val_mse: 27.7258 - val_mean_absolute_error: 3.9635 - val_r2_func_tf: 0.9300 - val_rmse_func_tf: 5.1867 - val_bias_func_tf: -3.8909e-01 - val_sdep_func_tf: 4.7006 - 84ms/epoch - 8ms/step\n",
      "Epoch 25/300\n",
      "10/10 - 0s - loss: 43.9244 - mse: 43.9244 - mean_absolute_error: 4.9516 - r2_func_tf: 0.5201 - rmse_func_tf: 6.9793 - bias_func_tf: 2.8051 - sdep_func_tf: 5.0130 - val_loss: 32.9138 - val_mse: 32.9138 - val_mean_absolute_error: 4.5819 - val_r2_func_tf: 0.9291 - val_rmse_func_tf: 5.6100 - val_bias_func_tf: -2.3839e+00 - val_sdep_func_tf: 4.6622 - 81ms/epoch - 8ms/step\n",
      "Epoch 26/300\n",
      "10/10 - 0s - loss: 75.6399 - mse: 75.6399 - mean_absolute_error: 6.4606 - r2_func_tf: 0.8367 - rmse_func_tf: 7.8342 - bias_func_tf: -2.6602e+00 - sdep_func_tf: 5.4621 - val_loss: 50.3264 - val_mse: 50.3264 - val_mean_absolute_error: 5.8707 - val_r2_func_tf: 0.8993 - val_rmse_func_tf: 6.8966 - val_bias_func_tf: -4.7432e+00 - val_sdep_func_tf: 4.7150 - 78ms/epoch - 8ms/step\n",
      "Epoch 27/300\n",
      "10/10 - 0s - loss: 57.1404 - mse: 57.1404 - mean_absolute_error: 5.9409 - r2_func_tf: 0.7251 - rmse_func_tf: 7.4255 - bias_func_tf: 0.2920 - sdep_func_tf: 4.9644 - val_loss: 27.7932 - val_mse: 27.7932 - val_mean_absolute_error: 4.0060 - val_r2_func_tf: 0.9323 - val_rmse_func_tf: 5.1859 - val_bias_func_tf: -7.4348e-01 - val_sdep_func_tf: 4.6818 - 83ms/epoch - 8ms/step\n",
      "Epoch 28/300\n",
      "10/10 - 0s - loss: 57.4780 - mse: 57.4780 - mean_absolute_error: 5.6725 - r2_func_tf: 0.8419 - rmse_func_tf: 7.8099 - bias_func_tf: -2.1613e-01 - sdep_func_tf: 5.4823 - val_loss: 35.9585 - val_mse: 35.9585 - val_mean_absolute_error: 4.8236 - val_r2_func_tf: 0.9252 - val_rmse_func_tf: 5.8460 - val_bias_func_tf: -3.0054e+00 - val_sdep_func_tf: 4.6447 - 81ms/epoch - 8ms/step\n",
      "Epoch 29/300\n",
      "10/10 - 0s - loss: 69.7642 - mse: 69.7642 - mean_absolute_error: 6.1789 - r2_func_tf: 0.6834 - rmse_func_tf: 7.1756 - bias_func_tf: 0.0589 - sdep_func_tf: 5.3528 - val_loss: 28.2803 - val_mse: 28.2803 - val_mean_absolute_error: 4.1022 - val_r2_func_tf: 0.9342 - val_rmse_func_tf: 5.2205 - val_bias_func_tf: -1.2031e+00 - val_sdep_func_tf: 4.6458 - 80ms/epoch - 8ms/step\n",
      "Epoch 30/300\n",
      "10/10 - 0s - loss: 62.1068 - mse: 62.1068 - mean_absolute_error: 6.0709 - r2_func_tf: 0.6534 - rmse_func_tf: 7.9900 - bias_func_tf: 1.6778 - sdep_func_tf: 5.3861 - val_loss: 33.9717 - val_mse: 33.9717 - val_mean_absolute_error: 4.6600 - val_r2_func_tf: 0.9287 - val_rmse_func_tf: 5.6894 - val_bias_func_tf: -2.6915e+00 - val_sdep_func_tf: 4.6314 - 79ms/epoch - 8ms/step\n",
      "Epoch 31/300\n",
      "10/10 - 0s - loss: 101.8271 - mse: 101.8271 - mean_absolute_error: 7.7152 - r2_func_tf: 0.5513 - rmse_func_tf: 9.3677 - bias_func_tf: -4.5012e-01 - sdep_func_tf: 5.7024 - val_loss: 54.3260 - val_mse: 54.3260 - val_mean_absolute_error: 6.0823 - val_r2_func_tf: 0.8920 - val_rmse_func_tf: 7.1689 - val_bias_func_tf: -5.1545e+00 - val_sdep_func_tf: 4.7282 - 79ms/epoch - 8ms/step\n",
      "Epoch 32/300\n",
      "10/10 - 0s - loss: 59.3193 - mse: 59.3192 - mean_absolute_error: 6.1779 - r2_func_tf: 0.6896 - rmse_func_tf: 8.0512 - bias_func_tf: -3.6587e+00 - sdep_func_tf: 4.9051 - val_loss: 41.0663 - val_mse: 41.0663 - val_mean_absolute_error: 5.2469 - val_r2_func_tf: 0.9170 - val_rmse_func_tf: 6.2373 - val_bias_func_tf: -3.7799e+00 - val_sdep_func_tf: 4.6468 - 82ms/epoch - 8ms/step\n",
      "Epoch 33/300\n",
      "10/10 - 0s - loss: 52.5944 - mse: 52.5944 - mean_absolute_error: 5.6715 - r2_func_tf: 0.8818 - rmse_func_tf: 6.8727 - bias_func_tf: 0.3979 - sdep_func_tf: 5.2754 - val_loss: 26.6836 - val_mse: 26.6836 - val_mean_absolute_error: 3.8885 - val_r2_func_tf: 0.9321 - val_rmse_func_tf: 5.0840 - val_bias_func_tf: -1.1313e-01 - val_sdep_func_tf: 4.6536 - 98ms/epoch - 10ms/step\n",
      "Epoch 34/300\n",
      "10/10 - 0s - loss: 71.2469 - mse: 71.2469 - mean_absolute_error: 6.6681 - r2_func_tf: 0.4838 - rmse_func_tf: 7.9107 - bias_func_tf: 3.6323 - sdep_func_tf: 5.1992 - val_loss: 28.8888 - val_mse: 28.8888 - val_mean_absolute_error: 4.2027 - val_r2_func_tf: 0.9354 - val_rmse_func_tf: 5.2736 - val_bias_func_tf: -1.6237e+00 - val_sdep_func_tf: 4.6148 - 89ms/epoch - 9ms/step\n",
      "Epoch 35/300\n",
      "10/10 - 0s - loss: 90.6869 - mse: 90.6869 - mean_absolute_error: 6.8583 - r2_func_tf: 0.6444 - rmse_func_tf: 9.5534 - bias_func_tf: -3.9254e+00 - sdep_func_tf: 5.5229 - val_loss: 67.0844 - val_mse: 67.0844 - val_mean_absolute_error: 6.8239 - val_r2_func_tf: 0.8659 - val_rmse_func_tf: 7.9849 - val_bias_func_tf: -6.1968e+00 - val_sdep_func_tf: 4.8328 - 84ms/epoch - 8ms/step\n",
      "Epoch 36/300\n",
      "10/10 - 0s - loss: 56.7115 - mse: 56.7115 - mean_absolute_error: 6.0301 - r2_func_tf: 0.6606 - rmse_func_tf: 7.5773 - bias_func_tf: 1.1179 - sdep_func_tf: 4.9517 - val_loss: 26.3071 - val_mse: 26.3071 - val_mean_absolute_error: 3.8952 - val_r2_func_tf: 0.9322 - val_rmse_func_tf: 5.0472 - val_bias_func_tf: 0.0961 - val_sdep_func_tf: 4.6368 - 86ms/epoch - 9ms/step\n",
      "Epoch 37/300\n",
      "10/10 - 0s - loss: 107.6840 - mse: 107.6840 - mean_absolute_error: 8.7346 - r2_func_tf: -1.5153e-01 - rmse_func_tf: 9.7905 - bias_func_tf: 1.5164 - sdep_func_tf: 5.3099 - val_loss: 46.8014 - val_mse: 46.8014 - val_mean_absolute_error: 5.6308 - val_r2_func_tf: 0.9063 - val_rmse_func_tf: 6.6628 - val_bias_func_tf: -4.4620e+00 - val_sdep_func_tf: 4.6852 - 84ms/epoch - 8ms/step\n",
      "Epoch 38/300\n",
      "10/10 - 0s - loss: 55.6105 - mse: 55.6105 - mean_absolute_error: 5.7003 - r2_func_tf: 0.8418 - rmse_func_tf: 7.7191 - bias_func_tf: -3.0515e+00 - sdep_func_tf: 5.1237 - val_loss: 44.1842 - val_mse: 44.1842 - val_mean_absolute_error: 5.4647 - val_r2_func_tf: 0.9113 - val_rmse_func_tf: 6.4745 - val_bias_func_tf: -4.1841e+00 - val_sdep_func_tf: 4.6681 - 82ms/epoch - 8ms/step\n",
      "Epoch 39/300\n",
      "10/10 - 0s - loss: 63.7440 - mse: 63.7440 - mean_absolute_error: 6.4717 - r2_func_tf: 0.8191 - rmse_func_tf: 8.0214 - bias_func_tf: -3.2577e-01 - sdep_func_tf: 5.1445 - val_loss: 26.6186 - val_mse: 26.6186 - val_mean_absolute_error: 3.9332 - val_r2_func_tf: 0.9367 - val_rmse_func_tf: 5.0701 - val_bias_func_tf: -6.9813e-01 - val_sdep_func_tf: 4.6351 - 85ms/epoch - 8ms/step\n",
      "Epoch 40/300\n",
      "10/10 - 0s - loss: 72.6429 - mse: 72.6429 - mean_absolute_error: 6.8354 - r2_func_tf: 0.5181 - rmse_func_tf: 8.5419 - bias_func_tf: 3.1696 - sdep_func_tf: 4.9515 - val_loss: 27.2989 - val_mse: 27.2989 - val_mean_absolute_error: 4.0487 - val_r2_func_tf: 0.9375 - val_rmse_func_tf: 5.1314 - val_bias_func_tf: -1.1301e+00 - val_sdep_func_tf: 4.6279 - 85ms/epoch - 8ms/step\n",
      "Epoch 41/300\n",
      "10/10 - 0s - loss: 55.5973 - mse: 55.5973 - mean_absolute_error: 5.9614 - r2_func_tf: 0.3457 - rmse_func_tf: 7.3644 - bias_func_tf: -8.3842e-02 - sdep_func_tf: 4.9835 - val_loss: 44.3651 - val_mse: 44.3651 - val_mean_absolute_error: 5.4488 - val_r2_func_tf: 0.9110 - val_rmse_func_tf: 6.4913 - val_bias_func_tf: -4.2056e+00 - val_sdep_func_tf: 4.6857 - 83ms/epoch - 8ms/step\n",
      "Epoch 42/300\n",
      "10/10 - 0s - loss: 45.0914 - mse: 45.0914 - mean_absolute_error: 5.2440 - r2_func_tf: 0.8519 - rmse_func_tf: 6.2230 - bias_func_tf: -1.3994e+00 - sdep_func_tf: 4.8991 - val_loss: 36.5182 - val_mse: 36.5182 - val_mean_absolute_error: 4.8413 - val_r2_func_tf: 0.9254 - val_rmse_func_tf: 5.8980 - val_bias_func_tf: -3.2139e+00 - val_sdep_func_tf: 4.6529 - 86ms/epoch - 9ms/step\n",
      "Epoch 43/300\n",
      "10/10 - 0s - loss: 54.0244 - mse: 54.0244 - mean_absolute_error: 5.9731 - r2_func_tf: -1.9049e+00 - rmse_func_tf: 7.4345 - bias_func_tf: -3.2334e-01 - sdep_func_tf: 4.7126 - val_loss: 32.1290 - val_mse: 32.1290 - val_mean_absolute_error: 4.4593 - val_r2_func_tf: 0.9326 - val_rmse_func_tf: 5.5441 - val_bias_func_tf: -2.4689e+00 - val_sdep_func_tf: 4.6434 - 82ms/epoch - 8ms/step\n",
      "Epoch 44/300\n",
      "10/10 - 0s - loss: 60.4376 - mse: 60.4376 - mean_absolute_error: 5.9868 - r2_func_tf: 0.5657 - rmse_func_tf: 7.2215 - bias_func_tf: -1.5585e+00 - sdep_func_tf: 4.7268 - val_loss: 32.3308 - val_mse: 32.3308 - val_mean_absolute_error: 4.4655 - val_r2_func_tf: 0.9324 - val_rmse_func_tf: 5.5606 - val_bias_func_tf: -2.4942e+00 - val_sdep_func_tf: 4.6544 - 81ms/epoch - 8ms/step\n",
      "Epoch 45/300\n",
      "10/10 - 0s - loss: 68.5075 - mse: 68.5075 - mean_absolute_error: 6.5579 - r2_func_tf: 0.7798 - rmse_func_tf: 8.1089 - bias_func_tf: 0.7491 - sdep_func_tf: 5.2760 - val_loss: 26.0964 - val_mse: 26.0964 - val_mean_absolute_error: 3.8934 - val_r2_func_tf: 0.9350 - val_rmse_func_tf: 5.0236 - val_bias_func_tf: 0.0358 - val_sdep_func_tf: 4.6676 - 86ms/epoch - 9ms/step\n",
      "Epoch 46/300\n",
      "10/10 - 0s - loss: 67.6849 - mse: 67.6849 - mean_absolute_error: 6.1905 - r2_func_tf: 0.6532 - rmse_func_tf: 7.8086 - bias_func_tf: 2.5554 - sdep_func_tf: 5.0908 - val_loss: 29.2213 - val_mse: 29.2213 - val_mean_absolute_error: 4.2215 - val_r2_func_tf: 0.9366 - val_rmse_func_tf: 5.2982 - val_bias_func_tf: -1.7873e+00 - val_sdep_func_tf: 4.6568 - 81ms/epoch - 8ms/step\n",
      "Epoch 47/300\n",
      "10/10 - 0s - loss: 57.7522 - mse: 57.7522 - mean_absolute_error: 5.5770 - r2_func_tf: 0.8172 - rmse_func_tf: 6.6144 - bias_func_tf: -1.2249e+00 - sdep_func_tf: 5.1327 - val_loss: 42.9966 - val_mse: 42.9966 - val_mean_absolute_error: 5.2880 - val_r2_func_tf: 0.9133 - val_rmse_func_tf: 6.3989 - val_bias_func_tf: -4.0096e+00 - val_sdep_func_tf: 4.7404 - 84ms/epoch - 8ms/step\n",
      "Epoch 48/300\n",
      "10/10 - 0s - loss: 75.8783 - mse: 75.8783 - mean_absolute_error: 6.4923 - r2_func_tf: 0.8251 - rmse_func_tf: 7.7171 - bias_func_tf: -1.9392e+00 - sdep_func_tf: 5.2279 - val_loss: 28.5394 - val_mse: 28.5394 - val_mean_absolute_error: 4.1474 - val_r2_func_tf: 0.9372 - val_rmse_func_tf: 5.2374 - val_bias_func_tf: -1.5610e+00 - val_sdep_func_tf: 4.6699 - 90ms/epoch - 9ms/step\n",
      "Epoch 49/300\n",
      "10/10 - 0s - loss: 58.0053 - mse: 58.0053 - mean_absolute_error: 5.7402 - r2_func_tf: 0.8352 - rmse_func_tf: 7.0071 - bias_func_tf: 1.4614 - sdep_func_tf: 5.0494 - val_loss: 26.2535 - val_mse: 26.2535 - val_mean_absolute_error: 3.9162 - val_r2_func_tf: 0.9355 - val_rmse_func_tf: 5.0378 - val_bias_func_tf: -1.0613e-01 - val_sdep_func_tf: 4.6885 - 87ms/epoch - 9ms/step\n",
      "Epoch 50/300\n",
      "10/10 - 0s - loss: 83.5825 - mse: 83.5825 - mean_absolute_error: 7.2997 - r2_func_tf: 0.5101 - rmse_func_tf: 8.4372 - bias_func_tf: 0.6233 - sdep_func_tf: 5.1190 - val_loss: 31.1783 - val_mse: 31.1783 - val_mean_absolute_error: 4.3529 - val_r2_func_tf: 0.9338 - val_rmse_func_tf: 5.4683 - val_bias_func_tf: -2.1934e+00 - val_sdep_func_tf: 4.7032 - 83ms/epoch - 8ms/step\n",
      "Epoch 51/300\n",
      "10/10 - 0s - loss: 60.8935 - mse: 60.8935 - mean_absolute_error: 6.3172 - r2_func_tf: 0.8483 - rmse_func_tf: 7.9264 - bias_func_tf: -2.4881e+00 - sdep_func_tf: 4.8684 - val_loss: 31.8438 - val_mse: 31.8438 - val_mean_absolute_error: 4.3972 - val_r2_func_tf: 0.9329 - val_rmse_func_tf: 5.5233 - val_bias_func_tf: -2.3433e+00 - val_sdep_func_tf: 4.7041 - 82ms/epoch - 8ms/step\n",
      "Epoch 52/300\n",
      "10/10 - 0s - loss: 77.3760 - mse: 77.3760 - mean_absolute_error: 7.0157 - r2_func_tf: -1.4051e+01 - rmse_func_tf: 8.5991 - bias_func_tf: 1.3600 - sdep_func_tf: 5.0200 - val_loss: 27.1151 - val_mse: 27.1151 - val_mean_absolute_error: 3.9957 - val_r2_func_tf: 0.9380 - val_rmse_func_tf: 5.1133 - val_bias_func_tf: -1.0179e+00 - val_sdep_func_tf: 4.6811 - 83ms/epoch - 8ms/step\n",
      "Epoch 53/300\n",
      "10/10 - 0s - loss: 56.3051 - mse: 56.3051 - mean_absolute_error: 5.8607 - r2_func_tf: 0.4696 - rmse_func_tf: 7.6088 - bias_func_tf: 1.0893 - sdep_func_tf: 5.1231 - val_loss: 30.5343 - val_mse: 30.5343 - val_mean_absolute_error: 4.3012 - val_r2_func_tf: 0.9347 - val_rmse_func_tf: 5.4151 - val_bias_func_tf: -2.0516e+00 - val_sdep_func_tf: 4.7068 - 83ms/epoch - 8ms/step\n",
      "Epoch 54/300\n",
      "10/10 - 0s - loss: 60.4656 - mse: 60.4656 - mean_absolute_error: 6.0469 - r2_func_tf: 0.7688 - rmse_func_tf: 7.1767 - bias_func_tf: -8.2232e-01 - sdep_func_tf: 5.2090 - val_loss: 36.8197 - val_mse: 36.8197 - val_mean_absolute_error: 4.7548 - val_r2_func_tf: 0.9246 - val_rmse_func_tf: 5.9320 - val_bias_func_tf: -3.1626e+00 - val_sdep_func_tf: 4.7560 - 90ms/epoch - 9ms/step\n",
      "Epoch 55/300\n",
      "10/10 - 0s - loss: 59.6969 - mse: 59.6969 - mean_absolute_error: 6.0442 - r2_func_tf: 0.8202 - rmse_func_tf: 7.1754 - bias_func_tf: -1.2528e+00 - sdep_func_tf: 5.3096 - val_loss: 29.5850 - val_mse: 29.5850 - val_mean_absolute_error: 4.2211 - val_r2_func_tf: 0.9361 - val_rmse_func_tf: 5.3330 - val_bias_func_tf: -1.8140e+00 - val_sdep_func_tf: 4.7109 - 86ms/epoch - 9ms/step\n",
      "Epoch 56/300\n",
      "10/10 - 0s - loss: 55.1686 - mse: 55.1686 - mean_absolute_error: 5.5129 - r2_func_tf: 0.8258 - rmse_func_tf: 7.7460 - bias_func_tf: -1.1203e+00 - sdep_func_tf: 5.3168 - val_loss: 27.2775 - val_mse: 27.2775 - val_mean_absolute_error: 4.0017 - val_r2_func_tf: 0.9381 - val_rmse_func_tf: 5.1284 - val_bias_func_tf: -1.0689e+00 - val_sdep_func_tf: 4.7007 - 80ms/epoch - 8ms/step\n",
      "Epoch 57/300\n",
      "10/10 - 0s - loss: 53.2332 - mse: 53.2332 - mean_absolute_error: 5.7321 - r2_func_tf: 0.6105 - rmse_func_tf: 6.8128 - bias_func_tf: 1.2784 - sdep_func_tf: 4.7408 - val_loss: 26.1706 - val_mse: 26.1706 - val_mean_absolute_error: 3.9192 - val_r2_func_tf: 0.9374 - val_rmse_func_tf: 5.0206 - val_bias_func_tf: -3.1025e-01 - val_sdep_func_tf: 4.7005 - 80ms/epoch - 8ms/step\n",
      "Epoch 58/300\n",
      "10/10 - 0s - loss: 51.8524 - mse: 51.8524 - mean_absolute_error: 5.2764 - r2_func_tf: 0.5951 - rmse_func_tf: 7.3315 - bias_func_tf: 2.5604 - sdep_func_tf: 5.0918 - val_loss: 27.0100 - val_mse: 27.0100 - val_mean_absolute_error: 3.9878 - val_r2_func_tf: 0.9384 - val_rmse_func_tf: 5.0988 - val_bias_func_tf: -9.5795e-01 - val_sdep_func_tf: 4.7063 - 82ms/epoch - 8ms/step\n",
      "Epoch 59/300\n",
      "10/10 - 0s - loss: 42.2651 - mse: 42.2651 - mean_absolute_error: 5.0693 - r2_func_tf: 0.6676 - rmse_func_tf: 6.2196 - bias_func_tf: -5.6786e-01 - sdep_func_tf: 4.9346 - val_loss: 38.9325 - val_mse: 38.9325 - val_mean_absolute_error: 4.9309 - val_r2_func_tf: 0.9203 - val_rmse_func_tf: 6.1019 - val_bias_func_tf: -3.4660e+00 - val_sdep_func_tf: 4.7838 - 84ms/epoch - 8ms/step\n",
      "Epoch 60/300\n",
      "10/10 - 0s - loss: 81.5681 - mse: 81.5681 - mean_absolute_error: 7.2702 - r2_func_tf: 0.5501 - rmse_func_tf: 8.4454 - bias_func_tf: -5.8716e-01 - sdep_func_tf: 5.2903 - val_loss: 33.3094 - val_mse: 33.3094 - val_mean_absolute_error: 4.4731 - val_r2_func_tf: 0.9304 - val_rmse_func_tf: 5.6485 - val_bias_func_tf: -2.6038e+00 - val_sdep_func_tf: 4.7530 - 83ms/epoch - 8ms/step\n",
      "Epoch 61/300\n",
      "10/10 - 0s - loss: 50.0584 - mse: 50.0584 - mean_absolute_error: 5.3757 - r2_func_tf: 0.8943 - rmse_func_tf: 6.5793 - bias_func_tf: -1.4954e+00 - sdep_func_tf: 5.0924 - val_loss: 30.8009 - val_mse: 30.8009 - val_mean_absolute_error: 4.3012 - val_r2_func_tf: 0.9345 - val_rmse_func_tf: 5.4336 - val_bias_func_tf: -2.1094e+00 - val_sdep_func_tf: 4.7409 - 84ms/epoch - 8ms/step\n",
      "Epoch 62/300\n",
      "10/10 - 0s - loss: 50.2097 - mse: 50.2097 - mean_absolute_error: 5.5665 - r2_func_tf: 0.0696 - rmse_func_tf: 7.2556 - bias_func_tf: 0.7421 - sdep_func_tf: 5.2152 - val_loss: 26.2392 - val_mse: 26.2392 - val_mean_absolute_error: 3.9262 - val_r2_func_tf: 0.9377 - val_rmse_func_tf: 5.0231 - val_bias_func_tf: -3.1193e-01 - val_sdep_func_tf: 4.7223 - 84ms/epoch - 8ms/step\n",
      "Epoch 63/300\n",
      "10/10 - 0s - loss: 80.6602 - mse: 80.6602 - mean_absolute_error: 6.9536 - r2_func_tf: 0.5791 - rmse_func_tf: 8.6677 - bias_func_tf: 2.1910 - sdep_func_tf: 4.6269 - val_loss: 27.1262 - val_mse: 27.1262 - val_mean_absolute_error: 3.9925 - val_r2_func_tf: 0.9384 - val_rmse_func_tf: 5.1065 - val_bias_func_tf: -9.4475e-01 - val_sdep_func_tf: 4.7320 - 86ms/epoch - 9ms/step\n",
      "Epoch 64/300\n",
      "10/10 - 0s - loss: 44.8777 - mse: 44.8777 - mean_absolute_error: 5.2555 - r2_func_tf: 0.7622 - rmse_func_tf: 6.5179 - bias_func_tf: -6.3225e-01 - sdep_func_tf: 4.6796 - val_loss: 32.0852 - val_mse: 32.0852 - val_mean_absolute_error: 4.3681 - val_r2_func_tf: 0.9324 - val_rmse_func_tf: 5.5442 - val_bias_func_tf: -2.3363e+00 - val_sdep_func_tf: 4.7747 - 89ms/epoch - 9ms/step\n",
      "Epoch 65/300\n",
      "10/10 - 0s - loss: 77.9619 - mse: 77.9619 - mean_absolute_error: 6.8700 - r2_func_tf: 0.7881 - rmse_func_tf: 7.6953 - bias_func_tf: -1.3274e+00 - sdep_func_tf: 4.8174 - val_loss: 31.0887 - val_mse: 31.0887 - val_mean_absolute_error: 4.3038 - val_r2_func_tf: 0.9337 - val_rmse_func_tf: 5.4577 - val_bias_func_tf: -2.1394e+00 - val_sdep_func_tf: 4.7625 - 87ms/epoch - 9ms/step\n",
      "Epoch 66/300\n",
      "10/10 - 0s - loss: 67.3767 - mse: 67.3767 - mean_absolute_error: 6.2437 - r2_func_tf: 0.4025 - rmse_func_tf: 8.2281 - bias_func_tf: 0.2128 - sdep_func_tf: 4.9245 - val_loss: 29.0105 - val_mse: 29.0105 - val_mean_absolute_error: 4.1370 - val_r2_func_tf: 0.9364 - val_rmse_func_tf: 5.2780 - val_bias_func_tf: -1.5917e+00 - val_sdep_func_tf: 4.7639 - 81ms/epoch - 8ms/step\n",
      "Epoch 67/300\n",
      "10/10 - 0s - loss: 76.5097 - mse: 76.5097 - mean_absolute_error: 6.4681 - r2_func_tf: 0.7166 - rmse_func_tf: 7.4285 - bias_func_tf: -3.4152e-01 - sdep_func_tf: 5.0511 - val_loss: 29.8184 - val_mse: 29.8184 - val_mean_absolute_error: 4.2000 - val_r2_func_tf: 0.9350 - val_rmse_func_tf: 5.3531 - val_bias_func_tf: -1.7815e+00 - val_sdep_func_tf: 4.7828 - 86ms/epoch - 9ms/step\n",
      "Epoch 68/300\n",
      "10/10 - 0s - loss: 81.1889 - mse: 81.1889 - mean_absolute_error: 7.1680 - r2_func_tf: 0.6302 - rmse_func_tf: 8.4022 - bias_func_tf: -1.2267e+00 - sdep_func_tf: 5.1716 - val_loss: 32.3601 - val_mse: 32.3601 - val_mean_absolute_error: 4.3654 - val_r2_func_tf: 0.9311 - val_rmse_func_tf: 5.5759 - val_bias_func_tf: -2.3313e+00 - val_sdep_func_tf: 4.8182 - 80ms/epoch - 8ms/step\n",
      "Epoch 69/300\n",
      "10/10 - 0s - loss: 44.8367 - mse: 44.8367 - mean_absolute_error: 5.4277 - r2_func_tf: 0.7570 - rmse_func_tf: 6.7580 - bias_func_tf: 0.3601 - sdep_func_tf: 4.7637 - val_loss: 26.9008 - val_mse: 26.9008 - val_mean_absolute_error: 3.9735 - val_r2_func_tf: 0.9329 - val_rmse_func_tf: 5.0913 - val_bias_func_tf: 0.4280 - val_sdep_func_tf: 4.8037 - 87ms/epoch - 9ms/step\n",
      "Epoch 70/300\n",
      "10/10 - 0s - loss: 51.9950 - mse: 51.9950 - mean_absolute_error: 5.6832 - r2_func_tf: 0.8124 - rmse_func_tf: 7.2510 - bias_func_tf: 1.4416 - sdep_func_tf: 4.7255 - val_loss: 26.7264 - val_mse: 26.7264 - val_mean_absolute_error: 3.9484 - val_r2_func_tf: 0.9346 - val_rmse_func_tf: 5.0740 - val_bias_func_tf: 0.2016 - val_sdep_func_tf: 4.8069 - 86ms/epoch - 9ms/step\n",
      "Epoch 71/300\n",
      "10/10 - 0s - loss: 75.5201 - mse: 75.5201 - mean_absolute_error: 7.0747 - r2_func_tf: 0.6721 - rmse_func_tf: 8.2470 - bias_func_tf: -3.8237e-01 - sdep_func_tf: 5.1461 - val_loss: 28.9059 - val_mse: 28.9059 - val_mean_absolute_error: 4.0904 - val_r2_func_tf: 0.9364 - val_rmse_func_tf: 5.2714 - val_bias_func_tf: -1.4397e+00 - val_sdep_func_tf: 4.8258 - 95ms/epoch - 10ms/step\n",
      "Epoch 72/300\n",
      "10/10 - 0s - loss: 55.1474 - mse: 55.1474 - mean_absolute_error: 5.5232 - r2_func_tf: 0.8150 - rmse_func_tf: 6.8306 - bias_func_tf: -7.5094e-01 - sdep_func_tf: 5.1353 - val_loss: 27.3058 - val_mse: 27.3058 - val_mean_absolute_error: 3.9684 - val_r2_func_tf: 0.9375 - val_rmse_func_tf: 5.1265 - val_bias_func_tf: -7.5471e-01 - val_sdep_func_tf: 4.8159 - 86ms/epoch - 9ms/step\n",
      "Epoch 73/300\n",
      "10/10 - 0s - loss: 104.6544 - mse: 104.6544 - mean_absolute_error: 7.3009 - r2_func_tf: -2.2469e-01 - rmse_func_tf: 9.0699 - bias_func_tf: 0.1969 - sdep_func_tf: 4.9637 - val_loss: 30.6042 - val_mse: 30.6042 - val_mean_absolute_error: 4.2100 - val_r2_func_tf: 0.9340 - val_rmse_func_tf: 5.4251 - val_bias_func_tf: -1.8794e+00 - val_sdep_func_tf: 4.8496 - 85ms/epoch - 8ms/step\n",
      "Epoch 74/300\n",
      "10/10 - 0s - loss: 44.3310 - mse: 44.3310 - mean_absolute_error: 4.9286 - r2_func_tf: 0.8889 - rmse_func_tf: 6.8719 - bias_func_tf: -2.6256e+00 - sdep_func_tf: 5.0350 - val_loss: 28.4902 - val_mse: 28.4902 - val_mean_absolute_error: 4.0595 - val_r2_func_tf: 0.9363 - val_rmse_func_tf: 5.2413 - val_bias_func_tf: -1.2381e+00 - val_sdep_func_tf: 4.8427 - 80ms/epoch - 8ms/step\n",
      "Epoch 75/300\n",
      "10/10 - 0s - loss: 65.1269 - mse: 65.1269 - mean_absolute_error: 5.9803 - r2_func_tf: 0.5493 - rmse_func_tf: 8.3097 - bias_func_tf: 2.1698 - sdep_func_tf: 5.0039 - val_loss: 28.3380 - val_mse: 28.3380 - val_mean_absolute_error: 4.1363 - val_r2_func_tf: 0.9259 - val_rmse_func_tf: 5.2287 - val_bias_func_tf: 1.1947 - val_sdep_func_tf: 4.8313 - 82ms/epoch - 8ms/step\n",
      "Epoch 76/300\n",
      "10/10 - 0s - loss: 30.5272 - mse: 30.5272 - mean_absolute_error: 4.1986 - r2_func_tf: 0.9153 - rmse_func_tf: 5.4143 - bias_func_tf: 0.4250 - sdep_func_tf: 4.9895 - val_loss: 28.1674 - val_mse: 28.1674 - val_mean_absolute_error: 4.0438 - val_r2_func_tf: 0.9365 - val_rmse_func_tf: 5.2114 - val_bias_func_tf: -1.1369e+00 - val_sdep_func_tf: 4.8329 - 85ms/epoch - 9ms/step\n",
      "Epoch 77/300\n",
      "10/10 - 0s - loss: 51.3208 - mse: 51.3208 - mean_absolute_error: 5.6879 - r2_func_tf: 0.3783 - rmse_func_tf: 7.2168 - bias_func_tf: 0.4069 - sdep_func_tf: 4.8449 - val_loss: 27.6418 - val_mse: 27.6418 - val_mean_absolute_error: 3.9970 - val_r2_func_tf: 0.9368 - val_rmse_func_tf: 5.1620 - val_bias_func_tf: -8.8899e-01 - val_sdep_func_tf: 4.8335 - 83ms/epoch - 8ms/step\n",
      "Epoch 78/300\n",
      "10/10 - 0s - loss: 48.7808 - mse: 48.7808 - mean_absolute_error: 5.3146 - r2_func_tf: 0.6197 - rmse_func_tf: 7.2579 - bias_func_tf: -4.7224e-02 - sdep_func_tf: 4.8725 - val_loss: 29.8971 - val_mse: 29.8971 - val_mean_absolute_error: 4.1640 - val_r2_func_tf: 0.9347 - val_rmse_func_tf: 5.3648 - val_bias_func_tf: -1.6685e+00 - val_sdep_func_tf: 4.8638 - 85ms/epoch - 9ms/step\n",
      "Epoch 79/300\n",
      "10/10 - 0s - loss: 56.7508 - mse: 56.7508 - mean_absolute_error: 5.9619 - r2_func_tf: 0.5754 - rmse_func_tf: 7.7713 - bias_func_tf: -5.5123e-01 - sdep_func_tf: 5.0843 - val_loss: 31.0213 - val_mse: 31.0213 - val_mean_absolute_error: 4.2356 - val_r2_func_tf: 0.9330 - val_rmse_func_tf: 5.4622 - val_bias_func_tf: -1.9613e+00 - val_sdep_func_tf: 4.8713 - 87ms/epoch - 9ms/step\n",
      "Epoch 80/300\n",
      "10/10 - 0s - loss: 57.6360 - mse: 57.6360 - mean_absolute_error: 5.7792 - r2_func_tf: 0.7874 - rmse_func_tf: 7.2433 - bias_func_tf: -6.3131e-01 - sdep_func_tf: 5.0888 - val_loss: 27.6993 - val_mse: 27.6993 - val_mean_absolute_error: 3.9912 - val_r2_func_tf: 0.9370 - val_rmse_func_tf: 5.1613 - val_bias_func_tf: -9.0371e-01 - val_sdep_func_tf: 4.8388 - 96ms/epoch - 10ms/step\n",
      "Epoch 81/300\n",
      "10/10 - 0s - loss: 80.8818 - mse: 80.8818 - mean_absolute_error: 6.8413 - r2_func_tf: 0.4828 - rmse_func_tf: 8.4275 - bias_func_tf: -1.2042e-01 - sdep_func_tf: 5.0144 - val_loss: 28.1944 - val_mse: 28.1944 - val_mean_absolute_error: 4.0348 - val_r2_func_tf: 0.9369 - val_rmse_func_tf: 5.2050 - val_bias_func_tf: -1.1496e+00 - val_sdep_func_tf: 4.8371 - 87ms/epoch - 9ms/step\n",
      "Epoch 82/300\n",
      "10/10 - 0s - loss: 52.5550 - mse: 52.5550 - mean_absolute_error: 5.5378 - r2_func_tf: 0.6344 - rmse_func_tf: 6.3695 - bias_func_tf: -8.5082e-01 - sdep_func_tf: 4.6163 - val_loss: 27.1380 - val_mse: 27.1380 - val_mean_absolute_error: 3.9586 - val_r2_func_tf: 0.9372 - val_rmse_func_tf: 5.1057 - val_bias_func_tf: -6.0241e-01 - val_sdep_func_tf: 4.8256 - 88ms/epoch - 9ms/step\n",
      "Epoch 83/300\n",
      "10/10 - 0s - loss: 48.1633 - mse: 48.1633 - mean_absolute_error: 5.4068 - r2_func_tf: 0.7132 - rmse_func_tf: 6.8724 - bias_func_tf: 0.6581 - sdep_func_tf: 4.8280 - val_loss: 26.8314 - val_mse: 26.8314 - val_mean_absolute_error: 3.9529 - val_r2_func_tf: 0.9348 - val_rmse_func_tf: 5.0782 - val_bias_func_tf: 0.1591 - val_sdep_func_tf: 4.8273 - 89ms/epoch - 9ms/step\n",
      "Epoch 84/300\n",
      "10/10 - 0s - loss: 46.1290 - mse: 46.1290 - mean_absolute_error: 5.5716 - r2_func_tf: 0.7905 - rmse_func_tf: 6.7786 - bias_func_tf: 0.6629 - sdep_func_tf: 5.1306 - val_loss: 26.7950 - val_mse: 26.7950 - val_mean_absolute_error: 3.9440 - val_r2_func_tf: 0.9358 - val_rmse_func_tf: 5.0759 - val_bias_func_tf: -8.5562e-02 - val_sdep_func_tf: 4.8265 - 86ms/epoch - 9ms/step\n",
      "Epoch 85/300\n",
      "10/10 - 0s - loss: 49.6996 - mse: 49.6996 - mean_absolute_error: 5.2037 - r2_func_tf: 0.8315 - rmse_func_tf: 6.3696 - bias_func_tf: -9.4952e-01 - sdep_func_tf: 4.9041 - val_loss: 28.8142 - val_mse: 28.8142 - val_mean_absolute_error: 4.0916 - val_r2_func_tf: 0.9362 - val_rmse_func_tf: 5.2627 - val_bias_func_tf: -1.3759e+00 - val_sdep_func_tf: 4.8437 - 87ms/epoch - 9ms/step\n",
      "Epoch 86/300\n",
      "10/10 - 0s - loss: 56.5725 - mse: 56.5725 - mean_absolute_error: 5.8849 - r2_func_tf: 0.0025 - rmse_func_tf: 7.3550 - bias_func_tf: 0.1499 - sdep_func_tf: 5.0309 - val_loss: 26.8614 - val_mse: 26.8614 - val_mean_absolute_error: 3.9463 - val_r2_func_tf: 0.9358 - val_rmse_func_tf: 5.0845 - val_bias_func_tf: -1.1981e-01 - val_sdep_func_tf: 4.8375 - 84ms/epoch - 8ms/step\n",
      "Epoch 87/300\n",
      "10/10 - 0s - loss: 51.2911 - mse: 51.2911 - mean_absolute_error: 5.5423 - r2_func_tf: 0.8169 - rmse_func_tf: 6.9840 - bias_func_tf: 0.7861 - sdep_func_tf: 4.6517 - val_loss: 26.8397 - val_mse: 26.8397 - val_mean_absolute_error: 3.9438 - val_r2_func_tf: 0.9355 - val_rmse_func_tf: 5.0833 - val_bias_func_tf: -9.7823e-03 - val_sdep_func_tf: 4.8402 - 86ms/epoch - 9ms/step\n",
      "Epoch 88/300\n",
      "10/10 - 0s - loss: 42.6349 - mse: 42.6349 - mean_absolute_error: 5.2019 - r2_func_tf: 0.8596 - rmse_func_tf: 6.5933 - bias_func_tf: -5.6720e-02 - sdep_func_tf: 4.9361 - val_loss: 27.5754 - val_mse: 27.5754 - val_mean_absolute_error: 3.9773 - val_r2_func_tf: 0.9371 - val_rmse_func_tf: 5.1526 - val_bias_func_tf: -8.2787e-01 - val_sdep_func_tf: 4.8485 - 82ms/epoch - 8ms/step\n",
      "Epoch 89/300\n",
      "10/10 - 0s - loss: 53.9228 - mse: 53.9228 - mean_absolute_error: 5.9850 - r2_func_tf: 0.8098 - rmse_func_tf: 6.8831 - bias_func_tf: -1.1922e+00 - sdep_func_tf: 4.8816 - val_loss: 27.4101 - val_mse: 27.4101 - val_mean_absolute_error: 3.9633 - val_r2_func_tf: 0.9372 - val_rmse_func_tf: 5.1351 - val_bias_func_tf: -7.1373e-01 - val_sdep_func_tf: 4.8510 - 86ms/epoch - 9ms/step\n",
      "Epoch 90/300\n",
      "10/10 - 0s - loss: 79.5841 - mse: 79.5841 - mean_absolute_error: 7.0121 - r2_func_tf: 0.5442 - rmse_func_tf: 8.9896 - bias_func_tf: -1.7835e+00 - sdep_func_tf: 5.5018 - val_loss: 26.8107 - val_mse: 26.8107 - val_mean_absolute_error: 3.9431 - val_r2_func_tf: 0.9357 - val_rmse_func_tf: 5.0777 - val_bias_func_tf: 0.0072 - val_sdep_func_tf: 4.8408 - 81ms/epoch - 8ms/step\n",
      "Epoch 91/300\n",
      "10/10 - 0s - loss: 62.6090 - mse: 62.6090 - mean_absolute_error: 6.2585 - r2_func_tf: 0.8092 - rmse_func_tf: 7.7934 - bias_func_tf: 0.7219 - sdep_func_tf: 5.0809 - val_loss: 32.8192 - val_mse: 32.8192 - val_mean_absolute_error: 4.5267 - val_r2_func_tf: 0.9111 - val_rmse_func_tf: 5.6294 - val_bias_func_tf: 2.3170 - val_sdep_func_tf: 4.8894 - 84ms/epoch - 8ms/step\n",
      "Epoch 92/300\n",
      "10/10 - 0s - loss: 62.7148 - mse: 62.7148 - mean_absolute_error: 6.2367 - r2_func_tf: 0.8035 - rmse_func_tf: 7.0863 - bias_func_tf: 1.1173 - sdep_func_tf: 4.4327 - val_loss: 26.7868 - val_mse: 26.7868 - val_mean_absolute_error: 3.9433 - val_r2_func_tf: 0.9360 - val_rmse_func_tf: 5.0752 - val_bias_func_tf: -4.5892e-02 - val_sdep_func_tf: 4.8389 - 81ms/epoch - 8ms/step\n",
      "Epoch 93/300\n",
      "10/10 - 0s - loss: 44.9442 - mse: 44.9442 - mean_absolute_error: 5.1957 - r2_func_tf: 0.8934 - rmse_func_tf: 6.4360 - bias_func_tf: -2.5906e-01 - sdep_func_tf: 5.0839 - val_loss: 27.0708 - val_mse: 27.0708 - val_mean_absolute_error: 3.9476 - val_r2_func_tf: 0.9371 - val_rmse_func_tf: 5.1040 - val_bias_func_tf: -5.2532e-01 - val_sdep_func_tf: 4.8405 - 84ms/epoch - 8ms/step\n",
      "Epoch 94/300\n",
      "10/10 - 0s - loss: 41.5548 - mse: 41.5548 - mean_absolute_error: 5.0350 - r2_func_tf: 0.8988 - rmse_func_tf: 5.9104 - bias_func_tf: 0.4224 - sdep_func_tf: 4.5641 - val_loss: 27.3542 - val_mse: 27.3542 - val_mean_absolute_error: 4.0338 - val_r2_func_tf: 0.9319 - val_rmse_func_tf: 5.1308 - val_bias_func_tf: 0.6273 - val_sdep_func_tf: 4.8544 - 87ms/epoch - 9ms/step\n",
      "Epoch 95/300\n",
      "10/10 - 0s - loss: 56.0273 - mse: 56.0273 - mean_absolute_error: 5.7779 - r2_func_tf: 0.7789 - rmse_func_tf: 6.8256 - bias_func_tf: 0.8835 - sdep_func_tf: 4.9329 - val_loss: 26.9166 - val_mse: 26.9166 - val_mean_absolute_error: 3.9409 - val_r2_func_tf: 0.9366 - val_rmse_func_tf: 5.0901 - val_bias_func_tf: -2.6474e-01 - val_sdep_func_tf: 4.8487 - 86ms/epoch - 9ms/step\n",
      "Epoch 96/300\n",
      "10/10 - 0s - loss: 48.5229 - mse: 48.5229 - mean_absolute_error: 5.3450 - r2_func_tf: 0.0097 - rmse_func_tf: 7.0938 - bias_func_tf: 0.3710 - sdep_func_tf: 4.6197 - val_loss: 27.7755 - val_mse: 27.7755 - val_mean_absolute_error: 3.9819 - val_r2_func_tf: 0.9372 - val_rmse_func_tf: 5.1689 - val_bias_func_tf: -9.2081e-01 - val_sdep_func_tf: 4.8605 - 86ms/epoch - 9ms/step\n",
      "Epoch 97/300\n",
      "10/10 - 0s - loss: 65.8897 - mse: 65.8897 - mean_absolute_error: 6.3908 - r2_func_tf: 0.7637 - rmse_func_tf: 8.3203 - bias_func_tf: -1.7464e+00 - sdep_func_tf: 5.0841 - val_loss: 27.6629 - val_mse: 27.6629 - val_mean_absolute_error: 3.9709 - val_r2_func_tf: 0.9371 - val_rmse_func_tf: 5.1589 - val_bias_func_tf: -8.3386e-01 - val_sdep_func_tf: 4.8662 - 90ms/epoch - 9ms/step\n",
      "Epoch 98/300\n",
      "10/10 - 0s - loss: 44.3399 - mse: 44.3399 - mean_absolute_error: 5.3370 - r2_func_tf: 0.8683 - rmse_func_tf: 6.7403 - bias_func_tf: -1.3040e-01 - sdep_func_tf: 5.2635 - val_loss: 27.1849 - val_mse: 27.1849 - val_mean_absolute_error: 4.0090 - val_r2_func_tf: 0.9332 - val_rmse_func_tf: 5.1135 - val_bias_func_tf: 0.4245 - val_sdep_func_tf: 4.8664 - 86ms/epoch - 9ms/step\n",
      "Epoch 99/300\n",
      "10/10 - 0s - loss: 65.8400 - mse: 65.8400 - mean_absolute_error: 6.0655 - r2_func_tf: 0.6185 - rmse_func_tf: 6.7330 - bias_func_tf: 0.4034 - sdep_func_tf: 4.7880 - val_loss: 27.0268 - val_mse: 27.0268 - val_mean_absolute_error: 3.9416 - val_r2_func_tf: 0.9361 - val_rmse_func_tf: 5.1013 - val_bias_func_tf: -2.0685e-01 - val_sdep_func_tf: 4.8714 - 88ms/epoch - 9ms/step\n",
      "Epoch 100/300\n",
      "10/10 - 0s - loss: 46.9855 - mse: 46.9855 - mean_absolute_error: 5.1580 - r2_func_tf: 0.8964 - rmse_func_tf: 6.5101 - bias_func_tf: -2.6713e-01 - sdep_func_tf: 5.0909 - val_loss: 26.9885 - val_mse: 26.9885 - val_mean_absolute_error: 3.9413 - val_r2_func_tf: 0.9355 - val_rmse_func_tf: 5.0991 - val_bias_func_tf: -6.3702e-02 - val_sdep_func_tf: 4.8719 - 94ms/epoch - 9ms/step\n",
      "Epoch 101/300\n",
      "10/10 - 0s - loss: 45.3119 - mse: 45.3119 - mean_absolute_error: 5.1920 - r2_func_tf: 0.8997 - rmse_func_tf: 6.3687 - bias_func_tf: -2.5026e-01 - sdep_func_tf: 4.8195 - val_loss: 27.0120 - val_mse: 27.0120 - val_mean_absolute_error: 3.9423 - val_r2_func_tf: 0.9354 - val_rmse_func_tf: 5.1023 - val_bias_func_tf: -5.3436e-02 - val_sdep_func_tf: 4.8751 - 93ms/epoch - 9ms/step\n",
      "Epoch 102/300\n",
      "10/10 - 0s - loss: 67.4447 - mse: 67.4447 - mean_absolute_error: 6.4150 - r2_func_tf: 0.8337 - rmse_func_tf: 7.8009 - bias_func_tf: -6.5664e-01 - sdep_func_tf: 5.1404 - val_loss: 27.0683 - val_mse: 27.0683 - val_mean_absolute_error: 3.9420 - val_r2_func_tf: 0.9360 - val_rmse_func_tf: 5.1076 - val_bias_func_tf: -2.1501e-01 - val_sdep_func_tf: 4.8765 - 84ms/epoch - 8ms/step\n",
      "Epoch 103/300\n",
      "10/10 - 0s - loss: 51.4760 - mse: 51.4760 - mean_absolute_error: 5.6269 - r2_func_tf: 0.8253 - rmse_func_tf: 7.0570 - bias_func_tf: -1.6039e-01 - sdep_func_tf: 5.1010 - val_loss: 27.7278 - val_mse: 27.7278 - val_mean_absolute_error: 4.1067 - val_r2_func_tf: 0.9299 - val_rmse_func_tf: 5.1708 - val_bias_func_tf: 0.8271 - val_sdep_func_tf: 4.8763 - 85ms/epoch - 8ms/step\n",
      "Epoch 104/300\n",
      "10/10 - 0s - loss: 60.4145 - mse: 60.4145 - mean_absolute_error: 6.2271 - r2_func_tf: 0.2666 - rmse_func_tf: 7.6631 - bias_func_tf: 1.5248 - sdep_func_tf: 4.8378 - val_loss: 27.1147 - val_mse: 27.1147 - val_mean_absolute_error: 3.9978 - val_r2_func_tf: 0.9336 - val_rmse_func_tf: 5.1129 - val_bias_func_tf: 0.3352 - val_sdep_func_tf: 4.8758 - 83ms/epoch - 8ms/step\n",
      "Epoch 105/300\n",
      "10/10 - 0s - loss: 30.1405 - mse: 30.1405 - mean_absolute_error: 4.3816 - r2_func_tf: 0.9131 - rmse_func_tf: 5.3696 - bias_func_tf: -7.1571e-02 - sdep_func_tf: 4.7536 - val_loss: 27.0441 - val_mse: 27.0441 - val_mean_absolute_error: 3.9429 - val_r2_func_tf: 0.9363 - val_rmse_func_tf: 5.1042 - val_bias_func_tf: -2.3196e-01 - val_sdep_func_tf: 4.8774 - 84ms/epoch - 8ms/step\n",
      "Epoch 106/300\n",
      "10/10 - 0s - loss: 52.5597 - mse: 52.5597 - mean_absolute_error: 5.5480 - r2_func_tf: 0.8167 - rmse_func_tf: 6.8242 - bias_func_tf: -3.0084e-01 - sdep_func_tf: 4.9813 - val_loss: 27.0409 - val_mse: 27.0409 - val_mean_absolute_error: 3.9445 - val_r2_func_tf: 0.9364 - val_rmse_func_tf: 5.1023 - val_bias_func_tf: -2.5189e-01 - val_sdep_func_tf: 4.8768 - 85ms/epoch - 9ms/step\n",
      "Epoch 107/300\n",
      "10/10 - 0s - loss: 57.4504 - mse: 57.4504 - mean_absolute_error: 6.1833 - r2_func_tf: -1.8084e-01 - rmse_func_tf: 7.4446 - bias_func_tf: 0.8223 - sdep_func_tf: 4.8111 - val_loss: 27.0011 - val_mse: 27.0011 - val_mean_absolute_error: 3.9731 - val_r2_func_tf: 0.9349 - val_rmse_func_tf: 5.0976 - val_bias_func_tf: 0.1558 - val_sdep_func_tf: 4.8771 - 84ms/epoch - 8ms/step\n",
      "Epoch 108/300\n",
      "10/10 - 0s - loss: 42.0197 - mse: 42.0197 - mean_absolute_error: 4.9367 - r2_func_tf: 0.6877 - rmse_func_tf: 6.1235 - bias_func_tf: -3.4472e-01 - sdep_func_tf: 4.7618 - val_loss: 28.2283 - val_mse: 28.2283 - val_mean_absolute_error: 4.0116 - val_r2_func_tf: 0.9367 - val_rmse_func_tf: 5.2131 - val_bias_func_tf: -1.0687e+00 - val_sdep_func_tf: 4.8928 - 82ms/epoch - 8ms/step\n",
      "Epoch 109/300\n",
      "10/10 - 0s - loss: 39.9667 - mse: 39.9667 - mean_absolute_error: 4.9795 - r2_func_tf: 0.8801 - rmse_func_tf: 6.1940 - bias_func_tf: -1.0899e+00 - sdep_func_tf: 4.7224 - val_loss: 27.3815 - val_mse: 27.3815 - val_mean_absolute_error: 3.9587 - val_r2_func_tf: 0.9368 - val_rmse_func_tf: 5.1336 - val_bias_func_tf: -5.7487e-01 - val_sdep_func_tf: 4.8887 - 83ms/epoch - 8ms/step\n",
      "Epoch 110/300\n",
      "10/10 - 0s - loss: 46.5164 - mse: 46.5164 - mean_absolute_error: 5.3032 - r2_func_tf: 0.8631 - rmse_func_tf: 6.6549 - bias_func_tf: 0.2442 - sdep_func_tf: 4.8287 - val_loss: 27.3396 - val_mse: 27.3396 - val_mean_absolute_error: 4.0311 - val_r2_func_tf: 0.9331 - val_rmse_func_tf: 5.1282 - val_bias_func_tf: 0.4479 - val_sdep_func_tf: 4.8927 - 81ms/epoch - 8ms/step\n",
      "Epoch 111/300\n",
      "10/10 - 0s - loss: 84.4361 - mse: 84.4361 - mean_absolute_error: 7.3397 - r2_func_tf: 0.3693 - rmse_func_tf: 9.1555 - bias_func_tf: 2.1775 - sdep_func_tf: 4.9156 - val_loss: 27.2328 - val_mse: 27.2328 - val_mean_absolute_error: 3.9976 - val_r2_func_tf: 0.9342 - val_rmse_func_tf: 5.1201 - val_bias_func_tf: 0.2072 - val_sdep_func_tf: 4.8982 - 83ms/epoch - 8ms/step\n",
      "Epoch 112/300\n",
      "10/10 - 0s - loss: 45.5085 - mse: 45.5085 - mean_absolute_error: 5.1964 - r2_func_tf: 0.8538 - rmse_func_tf: 7.1297 - bias_func_tf: -2.3636e+00 - sdep_func_tf: 5.0226 - val_loss: 33.8601 - val_mse: 33.8601 - val_mean_absolute_error: 4.4318 - val_r2_func_tf: 0.9280 - val_rmse_func_tf: 5.7079 - val_bias_func_tf: -2.5293e+00 - val_sdep_func_tf: 4.9249 - 82ms/epoch - 8ms/step\n",
      "Epoch 113/300\n",
      "10/10 - 0s - loss: 43.5244 - mse: 43.5244 - mean_absolute_error: 4.9870 - r2_func_tf: 0.7073 - rmse_func_tf: 6.7679 - bias_func_tf: -6.7875e-02 - sdep_func_tf: 5.1424 - val_loss: 27.2077 - val_mse: 27.2077 - val_mean_absolute_error: 3.9648 - val_r2_func_tf: 0.9358 - val_rmse_func_tf: 5.1179 - val_bias_func_tf: -1.9537e-01 - val_sdep_func_tf: 4.9022 - 80ms/epoch - 8ms/step\n",
      "Epoch 114/300\n",
      "10/10 - 0s - loss: 38.9837 - mse: 38.9837 - mean_absolute_error: 4.9413 - r2_func_tf: 0.8705 - rmse_func_tf: 6.1356 - bias_func_tf: 0.3886 - sdep_func_tf: 4.7799 - val_loss: 27.1875 - val_mse: 27.1875 - val_mean_absolute_error: 3.9966 - val_r2_func_tf: 0.9345 - val_rmse_func_tf: 5.1133 - val_bias_func_tf: 0.1847 - val_sdep_func_tf: 4.9018 - 82ms/epoch - 8ms/step\n",
      "Epoch 115/300\n",
      "10/10 - 0s - loss: 63.2769 - mse: 63.2769 - mean_absolute_error: 6.5338 - r2_func_tf: 0.6129 - rmse_func_tf: 7.5551 - bias_func_tf: 0.0939 - sdep_func_tf: 4.5949 - val_loss: 27.1953 - val_mse: 27.1953 - val_mean_absolute_error: 3.9692 - val_r2_func_tf: 0.9358 - val_rmse_func_tf: 5.1150 - val_bias_func_tf: -1.6401e-01 - val_sdep_func_tf: 4.9064 - 85ms/epoch - 8ms/step\n",
      "Epoch 116/300\n",
      "10/10 - 0s - loss: 57.6671 - mse: 57.6671 - mean_absolute_error: 6.0796 - r2_func_tf: 0.7962 - rmse_func_tf: 7.8068 - bias_func_tf: -1.3377e+00 - sdep_func_tf: 5.1374 - val_loss: 27.5247 - val_mse: 27.5247 - val_mean_absolute_error: 3.9683 - val_r2_func_tf: 0.9366 - val_rmse_func_tf: 5.1459 - val_bias_func_tf: -5.9828e-01 - val_sdep_func_tf: 4.9111 - 82ms/epoch - 8ms/step\n",
      "Epoch 117/300\n",
      "10/10 - 0s - loss: 62.4802 - mse: 62.4802 - mean_absolute_error: 6.1615 - r2_func_tf: 0.6393 - rmse_func_tf: 7.2909 - bias_func_tf: 0.2697 - sdep_func_tf: 4.8481 - val_loss: 27.2364 - val_mse: 27.2364 - val_mean_absolute_error: 4.0024 - val_r2_func_tf: 0.9344 - val_rmse_func_tf: 5.1203 - val_bias_func_tf: 0.1752 - val_sdep_func_tf: 4.9138 - 82ms/epoch - 8ms/step\n",
      "Epoch 118/300\n",
      "10/10 - 0s - loss: 91.2372 - mse: 91.2372 - mean_absolute_error: 7.5502 - r2_func_tf: 0.3358 - rmse_func_tf: 9.0787 - bias_func_tf: 2.0312 - sdep_func_tf: 5.2113 - val_loss: 27.4507 - val_mse: 27.4507 - val_mean_absolute_error: 4.0346 - val_r2_func_tf: 0.9332 - val_rmse_func_tf: 5.1393 - val_bias_func_tf: 0.3667 - val_sdep_func_tf: 4.9229 - 83ms/epoch - 8ms/step\n",
      "Epoch 119/300\n",
      "10/10 - 0s - loss: 32.4735 - mse: 32.4735 - mean_absolute_error: 4.3418 - r2_func_tf: 0.9182 - rmse_func_tf: 5.7015 - bias_func_tf: -7.5979e-01 - sdep_func_tf: 4.9524 - val_loss: 28.6972 - val_mse: 28.6972 - val_mean_absolute_error: 4.0248 - val_r2_func_tf: 0.9357 - val_rmse_func_tf: 5.2529 - val_bias_func_tf: -1.1985e+00 - val_sdep_func_tf: 4.9208 - 82ms/epoch - 8ms/step\n",
      "Epoch 120/300\n",
      "10/10 - 0s - loss: 38.8730 - mse: 38.8730 - mean_absolute_error: 4.8249 - r2_func_tf: 0.9118 - rmse_func_tf: 5.8253 - bias_func_tf: -6.1301e-01 - sdep_func_tf: 4.7892 - val_loss: 27.3766 - val_mse: 27.3766 - val_mean_absolute_error: 3.9691 - val_r2_func_tf: 0.9361 - val_rmse_func_tf: 5.1304 - val_bias_func_tf: -3.6410e-01 - val_sdep_func_tf: 4.9175 - 82ms/epoch - 8ms/step\n",
      "Epoch 121/300\n",
      "10/10 - 0s - loss: 53.0183 - mse: 53.0183 - mean_absolute_error: 5.4840 - r2_func_tf: 0.8380 - rmse_func_tf: 7.3385 - bias_func_tf: -1.1872e+00 - sdep_func_tf: 5.3450 - val_loss: 27.3791 - val_mse: 27.3791 - val_mean_absolute_error: 3.9637 - val_r2_func_tf: 0.9360 - val_rmse_func_tf: 5.1326 - val_bias_func_tf: -3.6752e-01 - val_sdep_func_tf: 4.9190 - 97ms/epoch - 10ms/step\n",
      "Epoch 122/300\n",
      "10/10 - 0s - loss: 52.1799 - mse: 52.1799 - mean_absolute_error: 5.8519 - r2_func_tf: 0.8633 - rmse_func_tf: 7.1495 - bias_func_tf: 1.0717 - sdep_func_tf: 4.9818 - val_loss: 28.4484 - val_mse: 28.4484 - val_mean_absolute_error: 4.1842 - val_r2_func_tf: 0.9281 - val_rmse_func_tf: 5.2363 - val_bias_func_tf: 1.0105 - val_sdep_func_tf: 4.9337 - 88ms/epoch - 9ms/step\n",
      "Epoch 123/300\n",
      "10/10 - 0s - loss: 50.1135 - mse: 50.1135 - mean_absolute_error: 5.6949 - r2_func_tf: 0.8343 - rmse_func_tf: 6.8631 - bias_func_tf: 0.1812 - sdep_func_tf: 4.7052 - val_loss: 27.3297 - val_mse: 27.3297 - val_mean_absolute_error: 3.9901 - val_r2_func_tf: 0.9345 - val_rmse_func_tf: 5.1319 - val_bias_func_tf: 0.0479 - val_sdep_func_tf: 4.9307 - 85ms/epoch - 8ms/step\n",
      "Epoch 124/300\n",
      "10/10 - 0s - loss: 44.0069 - mse: 44.0069 - mean_absolute_error: 4.9373 - r2_func_tf: 0.8803 - rmse_func_tf: 6.6693 - bias_func_tf: -8.0068e-01 - sdep_func_tf: 5.3036 - val_loss: 27.3275 - val_mse: 27.3275 - val_mean_absolute_error: 3.9919 - val_r2_func_tf: 0.9345 - val_rmse_func_tf: 5.1308 - val_bias_func_tf: 0.0704 - val_sdep_func_tf: 4.9302 - 80ms/epoch - 8ms/step\n",
      "Epoch 125/300\n",
      "10/10 - 0s - loss: 47.0333 - mse: 47.0333 - mean_absolute_error: 5.1238 - r2_func_tf: 0.8799 - rmse_func_tf: 6.4108 - bias_func_tf: 0.0766 - sdep_func_tf: 5.0869 - val_loss: 27.8206 - val_mse: 27.8206 - val_mean_absolute_error: 4.1187 - val_r2_func_tf: 0.9308 - val_rmse_func_tf: 5.1796 - val_bias_func_tf: 0.7067 - val_sdep_func_tf: 4.9289 - 82ms/epoch - 8ms/step\n",
      "Epoch 126/300\n",
      "10/10 - 0s - loss: 51.9221 - mse: 51.9221 - mean_absolute_error: 5.7354 - r2_func_tf: 0.7414 - rmse_func_tf: 6.8987 - bias_func_tf: 0.8066 - sdep_func_tf: 4.9276 - val_loss: 27.4294 - val_mse: 27.4294 - val_mean_absolute_error: 4.0499 - val_r2_func_tf: 0.9328 - val_rmse_func_tf: 5.1433 - val_bias_func_tf: 0.4242 - val_sdep_func_tf: 4.9229 - 83ms/epoch - 8ms/step\n",
      "Epoch 127/300\n",
      "10/10 - 0s - loss: 60.3455 - mse: 60.3455 - mean_absolute_error: 6.1519 - r2_func_tf: 0.7805 - rmse_func_tf: 7.1569 - bias_func_tf: 0.2939 - sdep_func_tf: 4.8482 - val_loss: 27.2375 - val_mse: 27.2375 - val_mean_absolute_error: 3.9522 - val_r2_func_tf: 0.9357 - val_rmse_func_tf: 5.1243 - val_bias_func_tf: -1.8318e-01 - val_sdep_func_tf: 4.9208 - 82ms/epoch - 8ms/step\n",
      "Epoch 128/300\n",
      "10/10 - 0s - loss: 53.2345 - mse: 53.2345 - mean_absolute_error: 5.8248 - r2_func_tf: 0.8197 - rmse_func_tf: 7.2079 - bias_func_tf: -1.1698e+00 - sdep_func_tf: 4.7092 - val_loss: 27.9518 - val_mse: 27.9518 - val_mean_absolute_error: 3.9790 - val_r2_func_tf: 0.9363 - val_rmse_func_tf: 5.1932 - val_bias_func_tf: -8.0926e-01 - val_sdep_func_tf: 4.9310 - 84ms/epoch - 8ms/step\n",
      "Epoch 129/300\n",
      "10/10 - 0s - loss: 31.5267 - mse: 31.5267 - mean_absolute_error: 4.4051 - r2_func_tf: 0.9153 - rmse_func_tf: 5.5315 - bias_func_tf: -1.4401e-01 - sdep_func_tf: 4.8606 - val_loss: 27.2818 - val_mse: 27.2818 - val_mean_absolute_error: 4.0031 - val_r2_func_tf: 0.9343 - val_rmse_func_tf: 5.1303 - val_bias_func_tf: 0.1707 - val_sdep_func_tf: 4.9282 - 88ms/epoch - 9ms/step\n",
      "Epoch 130/300\n",
      "10/10 - 0s - loss: 40.3913 - mse: 40.3913 - mean_absolute_error: 4.7990 - r2_func_tf: 0.8676 - rmse_func_tf: 6.6317 - bias_func_tf: -7.6846e-01 - sdep_func_tf: 4.9625 - val_loss: 27.3777 - val_mse: 27.3777 - val_mean_absolute_error: 4.0284 - val_r2_func_tf: 0.9334 - val_rmse_func_tf: 5.1420 - val_bias_func_tf: 0.3041 - val_sdep_func_tf: 4.9307 - 89ms/epoch - 9ms/step\n",
      "Epoch 131/300\n",
      "10/10 - 0s - loss: 42.3910 - mse: 42.3910 - mean_absolute_error: 5.1744 - r2_func_tf: 0.8954 - rmse_func_tf: 6.1709 - bias_func_tf: 0.2939 - sdep_func_tf: 4.8113 - val_loss: 27.9145 - val_mse: 27.9145 - val_mean_absolute_error: 4.1413 - val_r2_func_tf: 0.9300 - val_rmse_func_tf: 5.1952 - val_bias_func_tf: 0.7798 - val_sdep_func_tf: 4.9311 - 82ms/epoch - 8ms/step\n",
      "Epoch 132/300\n",
      "10/10 - 0s - loss: 39.0011 - mse: 39.0011 - mean_absolute_error: 4.9563 - r2_func_tf: 0.7304 - rmse_func_tf: 6.1491 - bias_func_tf: 0.9497 - sdep_func_tf: 4.7901 - val_loss: 27.4742 - val_mse: 27.4742 - val_mean_absolute_error: 4.0384 - val_r2_func_tf: 0.9330 - val_rmse_func_tf: 5.1536 - val_bias_func_tf: 0.3296 - val_sdep_func_tf: 4.9389 - 83ms/epoch - 8ms/step\n",
      "Epoch 133/300\n",
      "10/10 - 0s - loss: 51.0010 - mse: 51.0010 - mean_absolute_error: 5.3420 - r2_func_tf: 0.8710 - rmse_func_tf: 7.4190 - bias_func_tf: -1.4021e+00 - sdep_func_tf: 5.3347 - val_loss: 27.5859 - val_mse: 27.5859 - val_mean_absolute_error: 3.9445 - val_r2_func_tf: 0.9355 - val_rmse_func_tf: 5.1641 - val_bias_func_tf: -3.4072e-01 - val_sdep_func_tf: 4.9497 - 88ms/epoch - 9ms/step\n",
      "Epoch 134/300\n",
      "10/10 - 0s - loss: 35.1543 - mse: 35.1543 - mean_absolute_error: 4.7101 - r2_func_tf: 0.9132 - rmse_func_tf: 5.9749 - bias_func_tf: 0.9852 - sdep_func_tf: 4.8186 - val_loss: 29.0750 - val_mse: 29.0750 - val_mean_absolute_error: 4.2836 - val_r2_func_tf: 0.9253 - val_rmse_func_tf: 5.2981 - val_bias_func_tf: 1.3060 - val_sdep_func_tf: 4.9378 - 82ms/epoch - 8ms/step\n",
      "Epoch 135/300\n",
      "10/10 - 0s - loss: 39.1251 - mse: 39.1251 - mean_absolute_error: 4.8756 - r2_func_tf: 0.8636 - rmse_func_tf: 6.1177 - bias_func_tf: 1.0181 - sdep_func_tf: 5.0175 - val_loss: 27.5980 - val_mse: 27.5980 - val_mean_absolute_error: 4.0839 - val_r2_func_tf: 0.9323 - val_rmse_func_tf: 5.1588 - val_bias_func_tf: 0.5106 - val_sdep_func_tf: 4.9364 - 83ms/epoch - 8ms/step\n",
      "Epoch 136/300\n",
      "10/10 - 0s - loss: 52.2839 - mse: 52.2839 - mean_absolute_error: 5.8868 - r2_func_tf: 0.6823 - rmse_func_tf: 7.2664 - bias_func_tf: 0.6790 - sdep_func_tf: 4.5796 - val_loss: 27.5374 - val_mse: 27.5374 - val_mean_absolute_error: 3.9504 - val_r2_func_tf: 0.9360 - val_rmse_func_tf: 5.1544 - val_bias_func_tf: -3.6183e-01 - val_sdep_func_tf: 4.9451 - 83ms/epoch - 8ms/step\n",
      "Epoch 137/300\n",
      "10/10 - 0s - loss: 64.8659 - mse: 64.8659 - mean_absolute_error: 6.1238 - r2_func_tf: 0.5295 - rmse_func_tf: 7.4026 - bias_func_tf: -1.1060e-01 - sdep_func_tf: 5.1439 - val_loss: 27.9428 - val_mse: 27.9428 - val_mean_absolute_error: 3.9690 - val_r2_func_tf: 0.9362 - val_rmse_func_tf: 5.1943 - val_bias_func_tf: -6.9918e-01 - val_sdep_func_tf: 4.9484 - 86ms/epoch - 9ms/step\n",
      "Epoch 138/300\n",
      "10/10 - 0s - loss: 90.9794 - mse: 90.9794 - mean_absolute_error: 8.0292 - r2_func_tf: 0.1206 - rmse_func_tf: 9.0375 - bias_func_tf: -7.1481e-01 - sdep_func_tf: 5.0145 - val_loss: 28.7847 - val_mse: 28.7847 - val_mean_absolute_error: 4.0383 - val_r2_func_tf: 0.9357 - val_rmse_func_tf: 5.2719 - val_bias_func_tf: -1.1432e+00 - val_sdep_func_tf: 4.9532 - 84ms/epoch - 8ms/step\n",
      "Epoch 139/300\n",
      "10/10 - 0s - loss: 55.3950 - mse: 55.3950 - mean_absolute_error: 5.8270 - r2_func_tf: -4.4093e-01 - rmse_func_tf: 7.3939 - bias_func_tf: 0.2614 - sdep_func_tf: 5.0038 - val_loss: 27.5791 - val_mse: 27.5791 - val_mean_absolute_error: 3.9562 - val_r2_func_tf: 0.9361 - val_rmse_func_tf: 5.1596 - val_bias_func_tf: -4.4212e-01 - val_sdep_func_tf: 4.9472 - 81ms/epoch - 8ms/step\n",
      "Epoch 140/300\n",
      "10/10 - 0s - loss: 70.9149 - mse: 70.9149 - mean_absolute_error: 6.4695 - r2_func_tf: 0.4445 - rmse_func_tf: 8.3677 - bias_func_tf: 1.0501 - sdep_func_tf: 4.9231 - val_loss: 27.9042 - val_mse: 27.9042 - val_mean_absolute_error: 3.9672 - val_r2_func_tf: 0.9362 - val_rmse_func_tf: 5.1891 - val_bias_func_tf: -6.8899e-01 - val_sdep_func_tf: 4.9546 - 81ms/epoch - 8ms/step\n",
      "Epoch 141/300\n",
      "10/10 - 0s - loss: 62.6388 - mse: 62.6388 - mean_absolute_error: 6.1173 - r2_func_tf: 0.3187 - rmse_func_tf: 7.9906 - bias_func_tf: 0.2650 - sdep_func_tf: 4.7689 - val_loss: 31.6397 - val_mse: 31.6397 - val_mean_absolute_error: 4.2532 - val_r2_func_tf: 0.9314 - val_rmse_func_tf: 5.5259 - val_bias_func_tf: -1.9814e+00 - val_sdep_func_tf: 4.9837 - 86ms/epoch - 9ms/step\n",
      "Epoch 142/300\n",
      "10/10 - 0s - loss: 83.3443 - mse: 83.3443 - mean_absolute_error: 6.9635 - r2_func_tf: 0.8115 - rmse_func_tf: 7.9476 - bias_func_tf: -8.8068e-01 - sdep_func_tf: 5.0734 - val_loss: 30.4476 - val_mse: 30.4476 - val_mean_absolute_error: 4.1685 - val_r2_func_tf: 0.9332 - val_rmse_func_tf: 5.4209 - val_bias_func_tf: -1.6937e+00 - val_sdep_func_tf: 4.9721 - 84ms/epoch - 8ms/step\n",
      "Epoch 143/300\n",
      "10/10 - 0s - loss: 49.2805 - mse: 49.2805 - mean_absolute_error: 5.5086 - r2_func_tf: 0.8896 - rmse_func_tf: 6.6703 - bias_func_tf: -1.7826e+00 - sdep_func_tf: 4.9728 - val_loss: 29.0770 - val_mse: 29.0770 - val_mean_absolute_error: 4.0545 - val_r2_func_tf: 0.9351 - val_rmse_func_tf: 5.2971 - val_bias_func_tf: -1.2590e+00 - val_sdep_func_tf: 4.9638 - 82ms/epoch - 8ms/step\n",
      "Epoch 144/300\n",
      "10/10 - 0s - loss: 64.6821 - mse: 64.6821 - mean_absolute_error: 6.4222 - r2_func_tf: 0.7393 - rmse_func_tf: 7.3399 - bias_func_tf: -6.8332e-01 - sdep_func_tf: 4.6581 - val_loss: 27.4718 - val_mse: 27.4718 - val_mean_absolute_error: 3.9739 - val_r2_func_tf: 0.9357 - val_rmse_func_tf: 5.1456 - val_bias_func_tf: -3.0440e-01 - val_sdep_func_tf: 4.9513 - 85ms/epoch - 9ms/step\n",
      "Epoch 145/300\n",
      "10/10 - 0s - loss: 41.9145 - mse: 41.9145 - mean_absolute_error: 5.0606 - r2_func_tf: 0.7387 - rmse_func_tf: 6.4261 - bias_func_tf: 0.1828 - sdep_func_tf: 5.1252 - val_loss: 27.6764 - val_mse: 27.6764 - val_mean_absolute_error: 4.0859 - val_r2_func_tf: 0.9322 - val_rmse_func_tf: 5.1633 - val_bias_func_tf: 0.5007 - val_sdep_func_tf: 4.9514 - 86ms/epoch - 9ms/step\n",
      "Epoch 146/300\n",
      "10/10 - 0s - loss: 74.5809 - mse: 74.5809 - mean_absolute_error: 6.8926 - r2_func_tf: 0.7243 - rmse_func_tf: 8.2476 - bias_func_tf: -3.6183e-01 - sdep_func_tf: 5.2615 - val_loss: 27.3530 - val_mse: 27.3530 - val_mean_absolute_error: 4.0116 - val_r2_func_tf: 0.9343 - val_rmse_func_tf: 5.1309 - val_bias_func_tf: 0.1538 - val_sdep_func_tf: 4.9423 - 86ms/epoch - 9ms/step\n",
      "Epoch 147/300\n",
      "10/10 - 0s - loss: 59.5583 - mse: 59.5583 - mean_absolute_error: 6.0432 - r2_func_tf: 0.5160 - rmse_func_tf: 7.8531 - bias_func_tf: 1.8909 - sdep_func_tf: 4.7362 - val_loss: 28.7100 - val_mse: 28.7100 - val_mean_absolute_error: 4.2215 - val_r2_func_tf: 0.9275 - val_rmse_func_tf: 5.2573 - val_bias_func_tf: 1.0996 - val_sdep_func_tf: 4.9526 - 91ms/epoch - 9ms/step\n",
      "Epoch 148/300\n",
      "10/10 - 0s - loss: 46.3729 - mse: 46.3729 - mean_absolute_error: 5.2731 - r2_func_tf: 0.8591 - rmse_func_tf: 6.1587 - bias_func_tf: -1.9607e-01 - sdep_func_tf: 4.7208 - val_loss: 28.0576 - val_mse: 28.0576 - val_mean_absolute_error: 3.9913 - val_r2_func_tf: 0.9360 - val_rmse_func_tf: 5.1996 - val_bias_func_tf: -8.4706e-01 - val_sdep_func_tf: 4.9422 - 85ms/epoch - 9ms/step\n",
      "Epoch 149/300\n",
      "10/10 - 0s - loss: 46.7406 - mse: 46.7406 - mean_absolute_error: 5.3853 - r2_func_tf: 0.8877 - rmse_func_tf: 6.4262 - bias_func_tf: -3.9496e-01 - sdep_func_tf: 4.8979 - val_loss: 27.6813 - val_mse: 27.6813 - val_mean_absolute_error: 3.9744 - val_r2_func_tf: 0.9360 - val_rmse_func_tf: 5.1658 - val_bias_func_tf: -5.8356e-01 - val_sdep_func_tf: 4.9430 - 85ms/epoch - 8ms/step\n",
      "Epoch 150/300\n",
      "10/10 - 0s - loss: 37.5546 - mse: 37.5546 - mean_absolute_error: 5.0574 - r2_func_tf: 0.9133 - rmse_func_tf: 6.0098 - bias_func_tf: -7.1664e-01 - sdep_func_tf: 4.7183 - val_loss: 27.4279 - val_mse: 27.4279 - val_mean_absolute_error: 3.9723 - val_r2_func_tf: 0.9353 - val_rmse_func_tf: 5.1436 - val_bias_func_tf: -2.4014e-01 - val_sdep_func_tf: 4.9492 - 82ms/epoch - 8ms/step\n",
      "Epoch 151/300\n",
      "10/10 - 0s - loss: 34.8932 - mse: 34.8932 - mean_absolute_error: 4.5375 - r2_func_tf: 0.8495 - rmse_func_tf: 5.4965 - bias_func_tf: -3.9065e-01 - sdep_func_tf: 4.3918 - val_loss: 27.5678 - val_mse: 27.5678 - val_mean_absolute_error: 4.0711 - val_r2_func_tf: 0.9326 - val_rmse_func_tf: 5.1575 - val_bias_func_tf: 0.4146 - val_sdep_func_tf: 4.9527 - 82ms/epoch - 8ms/step\n",
      "Epoch 152/300\n",
      "10/10 - 0s - loss: 61.7765 - mse: 61.7765 - mean_absolute_error: 6.1240 - r2_func_tf: 0.7477 - rmse_func_tf: 7.5399 - bias_func_tf: 0.8712 - sdep_func_tf: 5.0656 - val_loss: 27.6905 - val_mse: 27.6905 - val_mean_absolute_error: 4.1057 - val_r2_func_tf: 0.9317 - val_rmse_func_tf: 5.1678 - val_bias_func_tf: 0.5820 - val_sdep_func_tf: 4.9475 - 81ms/epoch - 8ms/step\n",
      "Epoch 153/300\n",
      "10/10 - 0s - loss: 57.2986 - mse: 57.2986 - mean_absolute_error: 6.1554 - r2_func_tf: 0.7984 - rmse_func_tf: 7.1225 - bias_func_tf: -3.2515e-01 - sdep_func_tf: 4.7778 - val_loss: 27.6413 - val_mse: 27.6413 - val_mean_absolute_error: 3.9644 - val_r2_func_tf: 0.9360 - val_rmse_func_tf: 5.1650 - val_bias_func_tf: -5.5103e-01 - val_sdep_func_tf: 4.9483 - 83ms/epoch - 8ms/step\n",
      "Epoch 154/300\n",
      "10/10 - 0s - loss: 70.0346 - mse: 70.0346 - mean_absolute_error: 6.1489 - r2_func_tf: 0.7080 - rmse_func_tf: 8.7571 - bias_func_tf: -2.0796e+00 - sdep_func_tf: 5.0228 - val_loss: 27.4300 - val_mse: 27.4300 - val_mean_absolute_error: 3.9626 - val_r2_func_tf: 0.9354 - val_rmse_func_tf: 5.1472 - val_bias_func_tf: -2.8583e-01 - val_sdep_func_tf: 4.9477 - 85ms/epoch - 8ms/step\n",
      "Epoch 155/300\n",
      "10/10 - 0s - loss: 38.1592 - mse: 38.1592 - mean_absolute_error: 4.8343 - r2_func_tf: 0.9014 - rmse_func_tf: 5.9344 - bias_func_tf: 0.7588 - sdep_func_tf: 4.8714 - val_loss: 28.5169 - val_mse: 28.5169 - val_mean_absolute_error: 4.2051 - val_r2_func_tf: 0.9275 - val_rmse_func_tf: 5.2475 - val_bias_func_tf: 1.0515 - val_sdep_func_tf: 4.9474 - 98ms/epoch - 10ms/step\n",
      "Epoch 156/300\n",
      "10/10 - 0s - loss: 44.3288 - mse: 44.3288 - mean_absolute_error: 5.2642 - r2_func_tf: 0.8945 - rmse_func_tf: 6.4270 - bias_func_tf: 0.6811 - sdep_func_tf: 4.8167 - val_loss: 27.4809 - val_mse: 27.4809 - val_mean_absolute_error: 4.0601 - val_r2_func_tf: 0.9326 - val_rmse_func_tf: 5.1515 - val_bias_func_tf: 0.3971 - val_sdep_func_tf: 4.9453 - 83ms/epoch - 8ms/step\n",
      "Epoch 157/300\n",
      "10/10 - 0s - loss: 38.4460 - mse: 38.4460 - mean_absolute_error: 4.8027 - r2_func_tf: 0.8624 - rmse_func_tf: 5.8855 - bias_func_tf: 0.1964 - sdep_func_tf: 4.6318 - val_loss: 27.5236 - val_mse: 27.5236 - val_mean_absolute_error: 4.0802 - val_r2_func_tf: 0.9323 - val_rmse_func_tf: 5.1534 - val_bias_func_tf: 0.4726 - val_sdep_func_tf: 4.9429 - 84ms/epoch - 8ms/step\n",
      "Epoch 158/300\n",
      "10/10 - 0s - loss: 45.5322 - mse: 45.5322 - mean_absolute_error: 5.4322 - r2_func_tf: 0.7060 - rmse_func_tf: 6.4699 - bias_func_tf: 0.1060 - sdep_func_tf: 4.7950 - val_loss: 27.3521 - val_mse: 27.3521 - val_mean_absolute_error: 4.0281 - val_r2_func_tf: 0.9338 - val_rmse_func_tf: 5.1369 - val_bias_func_tf: 0.2196 - val_sdep_func_tf: 4.9456 - 81ms/epoch - 8ms/step\n",
      "Epoch 159/300\n",
      "10/10 - 0s - loss: 49.4721 - mse: 49.4721 - mean_absolute_error: 5.7539 - r2_func_tf: 0.7483 - rmse_func_tf: 6.9151 - bias_func_tf: 0.3218 - sdep_func_tf: 5.1328 - val_loss: 27.3823 - val_mse: 27.3823 - val_mean_absolute_error: 4.0440 - val_r2_func_tf: 0.9335 - val_rmse_func_tf: 5.1400 - val_bias_func_tf: 0.2825 - val_sdep_func_tf: 4.9460 - 84ms/epoch - 8ms/step\n",
      "Epoch 160/300\n",
      "10/10 - 0s - loss: 54.8391 - mse: 54.8391 - mean_absolute_error: 5.7571 - r2_func_tf: 0.6399 - rmse_func_tf: 7.4571 - bias_func_tf: 1.1514 - sdep_func_tf: 4.9101 - val_loss: 27.3473 - val_mse: 27.3473 - val_mean_absolute_error: 4.0189 - val_r2_func_tf: 0.9342 - val_rmse_func_tf: 5.1361 - val_bias_func_tf: 0.1517 - val_sdep_func_tf: 4.9493 - 85ms/epoch - 8ms/step\n",
      "Epoch 161/300\n",
      "10/10 - 0s - loss: 47.0252 - mse: 47.0252 - mean_absolute_error: 5.2250 - r2_func_tf: 0.7430 - rmse_func_tf: 7.1332 - bias_func_tf: -1.6025e+00 - sdep_func_tf: 4.8933 - val_loss: 27.5748 - val_mse: 27.5748 - val_mean_absolute_error: 3.9613 - val_r2_func_tf: 0.9360 - val_rmse_func_tf: 5.1585 - val_bias_func_tf: -5.1019e-01 - val_sdep_func_tf: 4.9470 - 85ms/epoch - 8ms/step\n",
      "Epoch 162/300\n",
      "10/10 - 0s - loss: 59.2127 - mse: 59.2127 - mean_absolute_error: 6.1736 - r2_func_tf: 0.6437 - rmse_func_tf: 7.5003 - bias_func_tf: 0.4556 - sdep_func_tf: 5.0498 - val_loss: 27.2471 - val_mse: 27.2471 - val_mean_absolute_error: 4.0025 - val_r2_func_tf: 0.9343 - val_rmse_func_tf: 5.1260 - val_bias_func_tf: 0.1414 - val_sdep_func_tf: 4.9335 - 88ms/epoch - 9ms/step\n",
      "Epoch 163/300\n",
      "10/10 - 0s - loss: 36.3847 - mse: 36.3847 - mean_absolute_error: 4.6726 - r2_func_tf: 0.9169 - rmse_func_tf: 5.8169 - bias_func_tf: -5.2673e-01 - sdep_func_tf: 4.9171 - val_loss: 27.2775 - val_mse: 27.2775 - val_mean_absolute_error: 3.9754 - val_r2_func_tf: 0.9353 - val_rmse_func_tf: 5.1300 - val_bias_func_tf: -1.3465e-01 - val_sdep_func_tf: 4.9375 - 86ms/epoch - 9ms/step\n",
      "Epoch 164/300\n",
      "10/10 - 0s - loss: 39.4111 - mse: 39.4111 - mean_absolute_error: 4.7371 - r2_func_tf: 0.7934 - rmse_func_tf: 6.1309 - bias_func_tf: 0.1282 - sdep_func_tf: 4.9685 - val_loss: 27.3638 - val_mse: 27.3638 - val_mean_absolute_error: 4.0387 - val_r2_func_tf: 0.9335 - val_rmse_func_tf: 5.1387 - val_bias_func_tf: 0.2864 - val_sdep_func_tf: 4.9407 - 82ms/epoch - 8ms/step\n",
      "Epoch 165/300\n",
      "10/10 - 0s - loss: 40.5193 - mse: 40.5193 - mean_absolute_error: 5.0804 - r2_func_tf: 0.8891 - rmse_func_tf: 6.3388 - bias_func_tf: -4.5528e-01 - sdep_func_tf: 5.0399 - val_loss: 27.5818 - val_mse: 27.5818 - val_mean_absolute_error: 4.0961 - val_r2_func_tf: 0.9323 - val_rmse_func_tf: 5.1578 - val_bias_func_tf: 0.5121 - val_sdep_func_tf: 4.9454 - 84ms/epoch - 8ms/step\n",
      "Epoch 166/300\n",
      "10/10 - 0s - loss: 34.6025 - mse: 34.6025 - mean_absolute_error: 4.4763 - r2_func_tf: 0.9032 - rmse_func_tf: 6.2129 - bias_func_tf: -9.8901e-01 - sdep_func_tf: 4.6021 - val_loss: 27.8525 - val_mse: 27.8525 - val_mean_absolute_error: 4.1463 - val_r2_func_tf: 0.9307 - val_rmse_func_tf: 5.1840 - val_bias_func_tf: 0.7314 - val_sdep_func_tf: 4.9440 - 86ms/epoch - 9ms/step\n",
      "Epoch 167/300\n",
      "10/10 - 0s - loss: 42.3161 - mse: 42.3161 - mean_absolute_error: 5.0581 - r2_func_tf: -2.4499e+00 - rmse_func_tf: 6.8262 - bias_func_tf: 1.8239 - sdep_func_tf: 4.6125 - val_loss: 28.8067 - val_mse: 28.8067 - val_mean_absolute_error: 4.2622 - val_r2_func_tf: 0.9263 - val_rmse_func_tf: 5.2748 - val_bias_func_tf: 1.2089 - val_sdep_func_tf: 4.9464 - 86ms/epoch - 9ms/step\n",
      "Epoch 168/300\n",
      "10/10 - 0s - loss: 58.9587 - mse: 58.9587 - mean_absolute_error: 5.9701 - r2_func_tf: 0.8484 - rmse_func_tf: 7.3130 - bias_func_tf: -3.2277e-01 - sdep_func_tf: 5.0878 - val_loss: 27.6459 - val_mse: 27.6459 - val_mean_absolute_error: 3.9555 - val_r2_func_tf: 0.9357 - val_rmse_func_tf: 5.1695 - val_bias_func_tf: -5.1538e-01 - val_sdep_func_tf: 4.9529 - 87ms/epoch - 9ms/step\n",
      "Epoch 169/300\n",
      "10/10 - 0s - loss: 45.5285 - mse: 45.5285 - mean_absolute_error: 5.3564 - r2_func_tf: 0.8389 - rmse_func_tf: 6.4066 - bias_func_tf: 8.1066e-04 - sdep_func_tf: 4.9034 - val_loss: 27.3639 - val_mse: 27.3639 - val_mean_absolute_error: 3.9969 - val_r2_func_tf: 0.9342 - val_rmse_func_tf: 5.1437 - val_bias_func_tf: 0.0350 - val_sdep_func_tf: 4.9529 - 88ms/epoch - 9ms/step\n",
      "Epoch 170/300\n",
      "10/10 - 0s - loss: 53.3632 - mse: 53.3632 - mean_absolute_error: 5.4887 - r2_func_tf: 0.5571 - rmse_func_tf: 7.3794 - bias_func_tf: 1.5061 - sdep_func_tf: 4.7254 - val_loss: 27.3915 - val_mse: 27.3915 - val_mean_absolute_error: 3.9912 - val_r2_func_tf: 0.9345 - val_rmse_func_tf: 5.1456 - val_bias_func_tf: -4.4757e-02 - val_sdep_func_tf: 4.9563 - 86ms/epoch - 9ms/step\n",
      "Epoch 171/300\n",
      "10/10 - 0s - loss: 47.5230 - mse: 47.5230 - mean_absolute_error: 5.4670 - r2_func_tf: 0.8264 - rmse_func_tf: 6.6349 - bias_func_tf: 0.0092 - sdep_func_tf: 4.9496 - val_loss: 27.7502 - val_mse: 27.7502 - val_mean_absolute_error: 3.9619 - val_r2_func_tf: 0.9356 - val_rmse_func_tf: 5.1793 - val_bias_func_tf: -5.7258e-01 - val_sdep_func_tf: 4.9577 - 84ms/epoch - 8ms/step\n",
      "Epoch 172/300\n",
      "10/10 - 0s - loss: 44.9402 - mse: 44.9402 - mean_absolute_error: 5.3343 - r2_func_tf: 0.8195 - rmse_func_tf: 6.3504 - bias_func_tf: -5.0461e-01 - sdep_func_tf: 4.5641 - val_loss: 28.7351 - val_mse: 28.7351 - val_mean_absolute_error: 4.0395 - val_r2_func_tf: 0.9351 - val_rmse_func_tf: 5.2708 - val_bias_func_tf: -1.0891e+00 - val_sdep_func_tf: 4.9700 - 90ms/epoch - 9ms/step\n",
      "Epoch 173/300\n",
      "10/10 - 0s - loss: 44.3772 - mse: 44.3772 - mean_absolute_error: 5.3416 - r2_func_tf: 0.8621 - rmse_func_tf: 6.8317 - bias_func_tf: -1.6424e+00 - sdep_func_tf: 4.9633 - val_loss: 28.6399 - val_mse: 28.6399 - val_mean_absolute_error: 4.0302 - val_r2_func_tf: 0.9351 - val_rmse_func_tf: 5.2616 - val_bias_func_tf: -1.0439e+00 - val_sdep_func_tf: 4.9707 - 87ms/epoch - 9ms/step\n",
      "Epoch 174/300\n",
      "10/10 - 0s - loss: 44.6187 - mse: 44.6187 - mean_absolute_error: 4.9819 - r2_func_tf: 0.8688 - rmse_func_tf: 6.7821 - bias_func_tf: -1.3913e+00 - sdep_func_tf: 4.5741 - val_loss: 27.5053 - val_mse: 27.5053 - val_mean_absolute_error: 3.9925 - val_r2_func_tf: 0.9345 - val_rmse_func_tf: 5.1553 - val_bias_func_tf: -1.2290e-01 - val_sdep_func_tf: 4.9648 - 89ms/epoch - 9ms/step\n",
      "Epoch 175/300\n",
      "10/10 - 0s - loss: 47.0911 - mse: 47.0911 - mean_absolute_error: 5.1583 - r2_func_tf: 0.8673 - rmse_func_tf: 6.3849 - bias_func_tf: 0.6043 - sdep_func_tf: 5.0558 - val_loss: 29.9673 - val_mse: 29.9673 - val_mean_absolute_error: 4.3556 - val_r2_func_tf: 0.9225 - val_rmse_func_tf: 5.3819 - val_bias_func_tf: 1.5091 - val_sdep_func_tf: 4.9815 - 90ms/epoch - 9ms/step\n",
      "Epoch 176/300\n",
      "10/10 - 0s - loss: 46.3858 - mse: 46.3858 - mean_absolute_error: 5.4022 - r2_func_tf: -3.1021e-01 - rmse_func_tf: 6.8926 - bias_func_tf: 1.9836 - sdep_func_tf: 4.8076 - val_loss: 28.5627 - val_mse: 28.5627 - val_mean_absolute_error: 4.2360 - val_r2_func_tf: 0.9280 - val_rmse_func_tf: 5.2494 - val_bias_func_tf: 1.0123 - val_sdep_func_tf: 4.9703 - 94ms/epoch - 9ms/step\n",
      "Epoch 177/300\n",
      "10/10 - 0s - loss: 56.4995 - mse: 56.4995 - mean_absolute_error: 5.9000 - r2_func_tf: 0.7811 - rmse_func_tf: 7.0171 - bias_func_tf: 0.3350 - sdep_func_tf: 4.8596 - val_loss: 27.4214 - val_mse: 27.4214 - val_mean_absolute_error: 4.0239 - val_r2_func_tf: 0.9345 - val_rmse_func_tf: 5.1404 - val_bias_func_tf: 0.0691 - val_sdep_func_tf: 4.9617 - 91ms/epoch - 9ms/step\n",
      "Epoch 178/300\n",
      "10/10 - 0s - loss: 32.5620 - mse: 32.5620 - mean_absolute_error: 4.4534 - r2_func_tf: 0.9213 - rmse_func_tf: 5.5846 - bias_func_tf: -7.8300e-01 - sdep_func_tf: 4.6037 - val_loss: 27.5652 - val_mse: 27.5652 - val_mean_absolute_error: 3.9798 - val_r2_func_tf: 0.9358 - val_rmse_func_tf: 5.1545 - val_bias_func_tf: -3.9219e-01 - val_sdep_func_tf: 4.9617 - 85ms/epoch - 8ms/step\n",
      "Epoch 179/300\n",
      "10/10 - 0s - loss: 67.3718 - mse: 67.3718 - mean_absolute_error: 6.7823 - r2_func_tf: -2.3800e+00 - rmse_func_tf: 8.3351 - bias_func_tf: 0.8519 - sdep_func_tf: 4.4737 - val_loss: 27.5756 - val_mse: 27.5756 - val_mean_absolute_error: 3.9827 - val_r2_func_tf: 0.9357 - val_rmse_func_tf: 5.1565 - val_bias_func_tf: -3.8092e-01 - val_sdep_func_tf: 4.9641 - 87ms/epoch - 9ms/step\n",
      "Epoch 180/300\n",
      "10/10 - 0s - loss: 81.3716 - mse: 81.3716 - mean_absolute_error: 6.7877 - r2_func_tf: 0.4851 - rmse_func_tf: 9.0877 - bias_func_tf: -2.1021e+00 - sdep_func_tf: 5.1576 - val_loss: 28.6891 - val_mse: 28.6891 - val_mean_absolute_error: 4.0290 - val_r2_func_tf: 0.9352 - val_rmse_func_tf: 5.2619 - val_bias_func_tf: -1.0564e+00 - val_sdep_func_tf: 4.9806 - 88ms/epoch - 9ms/step\n",
      "Epoch 181/300\n",
      "10/10 - 0s - loss: 31.4563 - mse: 31.4563 - mean_absolute_error: 4.4960 - r2_func_tf: 0.9168 - rmse_func_tf: 5.7018 - bias_func_tf: -7.0808e-01 - sdep_func_tf: 4.5858 - val_loss: 27.7857 - val_mse: 27.7857 - val_mean_absolute_error: 4.1131 - val_r2_func_tf: 0.9320 - val_rmse_func_tf: 5.1775 - val_bias_func_tf: 0.4564 - val_sdep_func_tf: 4.9822 - 85ms/epoch - 9ms/step\n",
      "Epoch 182/300\n",
      "10/10 - 0s - loss: 54.5946 - mse: 54.5946 - mean_absolute_error: 5.8512 - r2_func_tf: 0.8232 - rmse_func_tf: 6.8021 - bias_func_tf: 0.9936 - sdep_func_tf: 4.9542 - val_loss: 29.2059 - val_mse: 29.2059 - val_mean_absolute_error: 4.3049 - val_r2_func_tf: 0.9256 - val_rmse_func_tf: 5.3104 - val_bias_func_tf: 1.2164 - val_sdep_func_tf: 4.9956 - 86ms/epoch - 9ms/step\n",
      "Epoch 183/300\n",
      "10/10 - 0s - loss: 43.6638 - mse: 43.6638 - mean_absolute_error: 5.1673 - r2_func_tf: 0.7133 - rmse_func_tf: 6.8781 - bias_func_tf: 2.0721 - sdep_func_tf: 4.8173 - val_loss: 28.3960 - val_mse: 28.3960 - val_mean_absolute_error: 4.2139 - val_r2_func_tf: 0.9291 - val_rmse_func_tf: 5.2340 - val_bias_func_tf: 0.8379 - val_sdep_func_tf: 4.9941 - 82ms/epoch - 8ms/step\n",
      "Epoch 184/300\n",
      "10/10 - 0s - loss: 43.2477 - mse: 43.2477 - mean_absolute_error: 5.2069 - r2_func_tf: 0.8908 - rmse_func_tf: 6.5506 - bias_func_tf: -4.7206e-01 - sdep_func_tf: 4.7772 - val_loss: 28.2448 - val_mse: 28.2448 - val_mean_absolute_error: 3.9827 - val_r2_func_tf: 0.9349 - val_rmse_func_tf: 5.2233 - val_bias_func_tf: -7.1985e-01 - val_sdep_func_tf: 5.0016 - 85ms/epoch - 9ms/step\n",
      "Epoch 185/300\n",
      "10/10 - 0s - loss: 53.2692 - mse: 53.2692 - mean_absolute_error: 5.5783 - r2_func_tf: 0.8695 - rmse_func_tf: 6.7110 - bias_func_tf: -4.2895e-01 - sdep_func_tf: 5.1045 - val_loss: 28.1015 - val_mse: 28.1015 - val_mean_absolute_error: 3.9797 - val_r2_func_tf: 0.9347 - val_rmse_func_tf: 5.2102 - val_bias_func_tf: -5.7938e-01 - val_sdep_func_tf: 5.0076 - 83ms/epoch - 8ms/step\n",
      "Epoch 186/300\n",
      "10/10 - 0s - loss: 52.2776 - mse: 52.2776 - mean_absolute_error: 5.5940 - r2_func_tf: 0.8531 - rmse_func_tf: 7.0466 - bias_func_tf: -1.0263e+00 - sdep_func_tf: 5.1571 - val_loss: 27.9996 - val_mse: 27.9996 - val_mean_absolute_error: 3.9836 - val_r2_func_tf: 0.9346 - val_rmse_func_tf: 5.2010 - val_bias_func_tf: -4.7593e-01 - val_sdep_func_tf: 5.0072 - 85ms/epoch - 8ms/step\n",
      "Epoch 187/300\n",
      "10/10 - 0s - loss: 63.8087 - mse: 63.8087 - mean_absolute_error: 6.2791 - r2_func_tf: 0.8471 - rmse_func_tf: 7.8037 - bias_func_tf: -3.3963e-01 - sdep_func_tf: 4.9846 - val_loss: 27.7678 - val_mse: 27.7678 - val_mean_absolute_error: 4.0866 - val_r2_func_tf: 0.9326 - val_rmse_func_tf: 5.1757 - val_bias_func_tf: 0.2802 - val_sdep_func_tf: 4.9961 - 87ms/epoch - 9ms/step\n",
      "Epoch 188/300\n",
      "10/10 - 0s - loss: 45.9538 - mse: 45.9538 - mean_absolute_error: 5.2934 - r2_func_tf: 0.8167 - rmse_func_tf: 6.1391 - bias_func_tf: 0.3792 - sdep_func_tf: 4.5157 - val_loss: 28.0719 - val_mse: 28.0719 - val_mean_absolute_error: 4.1658 - val_r2_func_tf: 0.9306 - val_rmse_func_tf: 5.2017 - val_bias_func_tf: 0.6343 - val_sdep_func_tf: 4.9919 - 81ms/epoch - 8ms/step\n",
      "Epoch 189/300\n",
      "10/10 - 0s - loss: 69.2979 - mse: 69.2979 - mean_absolute_error: 6.4127 - r2_func_tf: 0.8423 - rmse_func_tf: 7.7007 - bias_func_tf: 0.3969 - sdep_func_tf: 5.2011 - val_loss: 28.0236 - val_mse: 28.0236 - val_mean_absolute_error: 4.1602 - val_r2_func_tf: 0.9307 - val_rmse_func_tf: 5.1939 - val_bias_func_tf: 0.6233 - val_sdep_func_tf: 4.9861 - 83ms/epoch - 8ms/step\n",
      "Epoch 190/300\n",
      "10/10 - 0s - loss: 38.7730 - mse: 38.7730 - mean_absolute_error: 4.7771 - r2_func_tf: 0.9002 - rmse_func_tf: 6.0879 - bias_func_tf: -5.4295e-01 - sdep_func_tf: 4.8940 - val_loss: 27.6384 - val_mse: 27.6384 - val_mean_absolute_error: 4.0228 - val_r2_func_tf: 0.9341 - val_rmse_func_tf: 5.1572 - val_bias_func_tf: -5.0384e-02 - val_sdep_func_tf: 4.9881 - 80ms/epoch - 8ms/step\n",
      "Epoch 191/300\n",
      "10/10 - 0s - loss: 37.7302 - mse: 37.7302 - mean_absolute_error: 4.5347 - r2_func_tf: 0.9020 - rmse_func_tf: 6.4681 - bias_func_tf: -1.3529e+00 - sdep_func_tf: 5.0743 - val_loss: 27.7758 - val_mse: 27.7758 - val_mean_absolute_error: 4.1195 - val_r2_func_tf: 0.9319 - val_rmse_func_tf: 5.1693 - val_bias_func_tf: 0.4811 - val_sdep_func_tf: 4.9756 - 88ms/epoch - 9ms/step\n",
      "Epoch 192/300\n",
      "10/10 - 0s - loss: 37.3355 - mse: 37.3355 - mean_absolute_error: 4.7794 - r2_func_tf: 0.8244 - rmse_func_tf: 5.9033 - bias_func_tf: 0.8525 - sdep_func_tf: 4.8039 - val_loss: 30.1320 - val_mse: 30.1320 - val_mean_absolute_error: 4.3957 - val_r2_func_tf: 0.9220 - val_rmse_func_tf: 5.3890 - val_bias_func_tf: 1.5975 - val_sdep_func_tf: 4.9691 - 86ms/epoch - 9ms/step\n",
      "Epoch 193/300\n",
      "10/10 - 0s - loss: 68.8268 - mse: 68.8268 - mean_absolute_error: 6.7507 - r2_func_tf: 0.3359 - rmse_func_tf: 7.6925 - bias_func_tf: 0.6951 - sdep_func_tf: 4.5693 - val_loss: 27.4951 - val_mse: 27.4951 - val_mean_absolute_error: 4.0306 - val_r2_func_tf: 0.9341 - val_rmse_func_tf: 5.1473 - val_bias_func_tf: 0.1147 - val_sdep_func_tf: 4.9676 - 84ms/epoch - 8ms/step\n",
      "Epoch 194/300\n",
      "10/10 - 0s - loss: 43.4881 - mse: 43.4881 - mean_absolute_error: 5.0619 - r2_func_tf: 0.8737 - rmse_func_tf: 6.3485 - bias_func_tf: -5.8378e-01 - sdep_func_tf: 4.9108 - val_loss: 27.5431 - val_mse: 27.5431 - val_mean_absolute_error: 3.9962 - val_r2_func_tf: 0.9347 - val_rmse_func_tf: 5.1550 - val_bias_func_tf: -1.0541e-01 - val_sdep_func_tf: 4.9728 - 82ms/epoch - 8ms/step\n",
      "Epoch 195/300\n",
      "10/10 - 0s - loss: 48.5812 - mse: 48.5812 - mean_absolute_error: 5.4139 - r2_func_tf: 0.6435 - rmse_func_tf: 6.4261 - bias_func_tf: 0.6203 - sdep_func_tf: 4.8471 - val_loss: 27.7111 - val_mse: 27.7111 - val_mean_absolute_error: 4.1015 - val_r2_func_tf: 0.9322 - val_rmse_func_tf: 5.1708 - val_bias_func_tf: 0.4345 - val_sdep_func_tf: 4.9724 - 86ms/epoch - 9ms/step\n",
      "Epoch 196/300\n",
      "10/10 - 0s - loss: 66.3945 - mse: 66.3945 - mean_absolute_error: 6.3532 - r2_func_tf: 0.6192 - rmse_func_tf: 7.6449 - bias_func_tf: 0.7610 - sdep_func_tf: 5.2058 - val_loss: 27.5019 - val_mse: 27.5019 - val_mean_absolute_error: 4.0105 - val_r2_func_tf: 0.9343 - val_rmse_func_tf: 5.1519 - val_bias_func_tf: 0.0014 - val_sdep_func_tf: 4.9722 - 92ms/epoch - 9ms/step\n",
      "Epoch 197/300\n",
      "10/10 - 0s - loss: 48.2882 - mse: 48.2882 - mean_absolute_error: 5.4070 - r2_func_tf: 0.7879 - rmse_func_tf: 6.6156 - bias_func_tf: -5.2739e-01 - sdep_func_tf: 4.8951 - val_loss: 28.3212 - val_mse: 28.3212 - val_mean_absolute_error: 4.0064 - val_r2_func_tf: 0.9354 - val_rmse_func_tf: 5.2298 - val_bias_func_tf: -8.4948e-01 - val_sdep_func_tf: 4.9826 - 85ms/epoch - 9ms/step\n",
      "Epoch 198/300\n",
      "10/10 - 0s - loss: 52.5685 - mse: 52.5685 - mean_absolute_error: 5.6798 - r2_func_tf: 0.0875 - rmse_func_tf: 7.4146 - bias_func_tf: 0.7094 - sdep_func_tf: 4.8501 - val_loss: 27.7295 - val_mse: 27.7295 - val_mean_absolute_error: 3.9774 - val_r2_func_tf: 0.9354 - val_rmse_func_tf: 5.1731 - val_bias_func_tf: -4.4462e-01 - val_sdep_func_tf: 4.9766 - 83ms/epoch - 8ms/step\n",
      "Epoch 199/300\n",
      "10/10 - 0s - loss: 33.2850 - mse: 33.2850 - mean_absolute_error: 4.4287 - r2_func_tf: 0.9157 - rmse_func_tf: 5.7565 - bias_func_tf: -2.4639e-01 - sdep_func_tf: 4.9513 - val_loss: 27.6902 - val_mse: 27.6902 - val_mean_absolute_error: 3.9903 - val_r2_func_tf: 0.9353 - val_rmse_func_tf: 5.1665 - val_bias_func_tf: -3.5627e-01 - val_sdep_func_tf: 4.9819 - 82ms/epoch - 8ms/step\n",
      "Epoch 200/300\n",
      "10/10 - 0s - loss: 38.9300 - mse: 38.9300 - mean_absolute_error: 4.9112 - r2_func_tf: 0.7676 - rmse_func_tf: 6.1041 - bias_func_tf: 0.0735 - sdep_func_tf: 4.7540 - val_loss: 27.5276 - val_mse: 27.5276 - val_mean_absolute_error: 4.0158 - val_r2_func_tf: 0.9346 - val_rmse_func_tf: 5.1486 - val_bias_func_tf: -3.7561e-02 - val_sdep_func_tf: 4.9765 - 85ms/epoch - 8ms/step\n",
      "Epoch 201/300\n",
      "10/10 - 0s - loss: 52.6707 - mse: 52.6707 - mean_absolute_error: 5.8498 - r2_func_tf: 0.8618 - rmse_func_tf: 7.4882 - bias_func_tf: -1.5492e+00 - sdep_func_tf: 4.8370 - val_loss: 27.9419 - val_mse: 27.9419 - val_mean_absolute_error: 3.9820 - val_r2_func_tf: 0.9357 - val_rmse_func_tf: 5.1893 - val_bias_func_tf: -6.1338e-01 - val_sdep_func_tf: 4.9807 - 95ms/epoch - 10ms/step\n",
      "Epoch 202/300\n",
      "10/10 - 0s - loss: 36.0842 - mse: 36.0842 - mean_absolute_error: 4.6551 - r2_func_tf: 0.8738 - rmse_func_tf: 5.9104 - bias_func_tf: -4.0245e-01 - sdep_func_tf: 4.8652 - val_loss: 27.8590 - val_mse: 27.8590 - val_mean_absolute_error: 4.1387 - val_r2_func_tf: 0.9317 - val_rmse_func_tf: 5.1783 - val_bias_func_tf: 0.5856 - val_sdep_func_tf: 4.9700 - 84ms/epoch - 8ms/step\n",
      "Epoch 203/300\n",
      "10/10 - 0s - loss: 65.9263 - mse: 65.9263 - mean_absolute_error: 5.8403 - r2_func_tf: 0.7870 - rmse_func_tf: 8.3750 - bias_func_tf: -9.2027e-01 - sdep_func_tf: 4.8617 - val_loss: 28.1778 - val_mse: 28.1778 - val_mean_absolute_error: 4.1868 - val_r2_func_tf: 0.9300 - val_rmse_func_tf: 5.2081 - val_bias_func_tf: 0.8090 - val_sdep_func_tf: 4.9677 - 87ms/epoch - 9ms/step\n",
      "Epoch 204/300\n",
      "10/10 - 0s - loss: 49.5774 - mse: 49.5774 - mean_absolute_error: 5.3289 - r2_func_tf: 0.7555 - rmse_func_tf: 6.3978 - bias_func_tf: 1.2567 - sdep_func_tf: 4.8248 - val_loss: 28.7456 - val_mse: 28.7456 - val_mean_absolute_error: 4.2545 - val_r2_func_tf: 0.9275 - val_rmse_func_tf: 5.2597 - val_bias_func_tf: 1.0882 - val_sdep_func_tf: 4.9693 - 84ms/epoch - 8ms/step\n",
      "Epoch 205/300\n",
      "10/10 - 0s - loss: 47.1809 - mse: 47.1809 - mean_absolute_error: 5.3161 - r2_func_tf: 0.8227 - rmse_func_tf: 6.4392 - bias_func_tf: 0.5848 - sdep_func_tf: 4.6062 - val_loss: 28.1036 - val_mse: 28.1036 - val_mean_absolute_error: 4.1762 - val_r2_func_tf: 0.9302 - val_rmse_func_tf: 5.1991 - val_bias_func_tf: 0.7863 - val_sdep_func_tf: 4.9618 - 86ms/epoch - 9ms/step\n",
      "Epoch 206/300\n",
      "10/10 - 0s - loss: 40.7285 - mse: 40.7285 - mean_absolute_error: 4.8949 - r2_func_tf: 0.7820 - rmse_func_tf: 6.3459 - bias_func_tf: -2.8022e-01 - sdep_func_tf: 4.7861 - val_loss: 27.3881 - val_mse: 27.3881 - val_mean_absolute_error: 3.9992 - val_r2_func_tf: 0.9351 - val_rmse_func_tf: 5.1341 - val_bias_func_tf: -9.1306e-02 - val_sdep_func_tf: 4.9547 - 84ms/epoch - 8ms/step\n",
      "Epoch 207/300\n",
      "10/10 - 0s - loss: 45.5669 - mse: 45.5669 - mean_absolute_error: 5.0829 - r2_func_tf: 0.8236 - rmse_func_tf: 6.8581 - bias_func_tf: -6.4902e-01 - sdep_func_tf: 5.0402 - val_loss: 27.3699 - val_mse: 27.3699 - val_mean_absolute_error: 4.0124 - val_r2_func_tf: 0.9346 - val_rmse_func_tf: 5.1323 - val_bias_func_tf: 0.0588 - val_sdep_func_tf: 4.9526 - 89ms/epoch - 9ms/step\n",
      "Epoch 208/300\n",
      "10/10 - 0s - loss: 56.2480 - mse: 56.2480 - mean_absolute_error: 5.8804 - r2_func_tf: 0.7724 - rmse_func_tf: 6.8161 - bias_func_tf: 0.5787 - sdep_func_tf: 4.8047 - val_loss: 27.6495 - val_mse: 27.6495 - val_mean_absolute_error: 4.1089 - val_r2_func_tf: 0.9322 - val_rmse_func_tf: 5.1571 - val_bias_func_tf: 0.5302 - val_sdep_func_tf: 4.9512 - 87ms/epoch - 9ms/step\n",
      "Epoch 209/300\n",
      "10/10 - 0s - loss: 54.7293 - mse: 54.7293 - mean_absolute_error: 5.8606 - r2_func_tf: 0.1634 - rmse_func_tf: 7.7836 - bias_func_tf: 2.0322 - sdep_func_tf: 4.7213 - val_loss: 27.3873 - val_mse: 27.3873 - val_mean_absolute_error: 4.0277 - val_r2_func_tf: 0.9342 - val_rmse_func_tf: 5.1341 - val_bias_func_tf: 0.1452 - val_sdep_func_tf: 4.9542 - 85ms/epoch - 8ms/step\n",
      "Epoch 210/300\n",
      "10/10 - 0s - loss: 43.4958 - mse: 43.4958 - mean_absolute_error: 5.0960 - r2_func_tf: 0.7790 - rmse_func_tf: 6.1311 - bias_func_tf: -5.7430e-01 - sdep_func_tf: 4.5488 - val_loss: 28.9177 - val_mse: 28.9177 - val_mean_absolute_error: 4.0644 - val_r2_func_tf: 0.9350 - val_rmse_func_tf: 5.2820 - val_bias_func_tf: -1.1624e+00 - val_sdep_func_tf: 4.9759 - 83ms/epoch - 8ms/step\n",
      "Epoch 211/300\n",
      "10/10 - 0s - loss: 40.9710 - mse: 40.9710 - mean_absolute_error: 5.2057 - r2_func_tf: 0.8789 - rmse_func_tf: 6.3966 - bias_func_tf: -7.0877e-01 - sdep_func_tf: 4.9786 - val_loss: 28.0194 - val_mse: 28.0194 - val_mean_absolute_error: 3.9884 - val_r2_func_tf: 0.9356 - val_rmse_func_tf: 5.1964 - val_bias_func_tf: -7.3146e-01 - val_sdep_func_tf: 4.9688 - 86ms/epoch - 9ms/step\n",
      "Epoch 212/300\n",
      "10/10 - 0s - loss: 45.9738 - mse: 45.9738 - mean_absolute_error: 5.6194 - r2_func_tf: 0.6962 - rmse_func_tf: 6.7280 - bias_func_tf: 0.2993 - sdep_func_tf: 4.6886 - val_loss: 27.4696 - val_mse: 27.4696 - val_mean_absolute_error: 3.9999 - val_r2_func_tf: 0.9350 - val_rmse_func_tf: 5.1405 - val_bias_func_tf: -1.5285e-01 - val_sdep_func_tf: 4.9637 - 87ms/epoch - 9ms/step\n",
      "Epoch 213/300\n",
      "10/10 - 0s - loss: 53.2207 - mse: 53.2207 - mean_absolute_error: 5.9572 - r2_func_tf: 0.7090 - rmse_func_tf: 7.1025 - bias_func_tf: -5.7839e-02 - sdep_func_tf: 4.9623 - val_loss: 28.0028 - val_mse: 28.0028 - val_mean_absolute_error: 3.9893 - val_r2_func_tf: 0.9357 - val_rmse_func_tf: 5.1918 - val_bias_func_tf: -7.1390e-01 - val_sdep_func_tf: 4.9691 - 82ms/epoch - 8ms/step\n",
      "Epoch 214/300\n",
      "10/10 - 0s - loss: 75.6589 - mse: 75.6589 - mean_absolute_error: 6.4641 - r2_func_tf: 0.7888 - rmse_func_tf: 8.0957 - bias_func_tf: 0.7720 - sdep_func_tf: 5.0708 - val_loss: 27.5175 - val_mse: 27.5175 - val_mean_absolute_error: 3.9993 - val_r2_func_tf: 0.9351 - val_rmse_func_tf: 5.1458 - val_bias_func_tf: -1.7701e-01 - val_sdep_func_tf: 4.9676 - 83ms/epoch - 8ms/step\n",
      "Epoch 215/300\n",
      "10/10 - 0s - loss: 47.6835 - mse: 47.6835 - mean_absolute_error: 5.1148 - r2_func_tf: 0.9002 - rmse_func_tf: 6.2083 - bias_func_tf: -2.2039e-01 - sdep_func_tf: 4.8866 - val_loss: 27.8394 - val_mse: 27.8394 - val_mean_absolute_error: 3.9827 - val_r2_func_tf: 0.9356 - val_rmse_func_tf: 5.1781 - val_bias_func_tf: -5.5172e-01 - val_sdep_func_tf: 4.9732 - 84ms/epoch - 8ms/step\n",
      "Epoch 216/300\n",
      "10/10 - 0s - loss: 47.2082 - mse: 47.2082 - mean_absolute_error: 5.4498 - r2_func_tf: 0.8477 - rmse_func_tf: 6.3382 - bias_func_tf: -5.0472e-01 - sdep_func_tf: 4.9406 - val_loss: 27.8606 - val_mse: 27.8606 - val_mean_absolute_error: 3.9804 - val_r2_func_tf: 0.9355 - val_rmse_func_tf: 5.1818 - val_bias_func_tf: -5.5399e-01 - val_sdep_func_tf: 4.9738 - 81ms/epoch - 8ms/step\n",
      "Epoch 217/300\n",
      "10/10 - 0s - loss: 46.5256 - mse: 46.5256 - mean_absolute_error: 5.2706 - r2_func_tf: 0.8970 - rmse_func_tf: 6.2233 - bias_func_tf: -5.4997e-01 - sdep_func_tf: 4.7293 - val_loss: 27.9378 - val_mse: 27.9378 - val_mean_absolute_error: 3.9762 - val_r2_func_tf: 0.9353 - val_rmse_func_tf: 5.1918 - val_bias_func_tf: -5.6242e-01 - val_sdep_func_tf: 4.9800 - 80ms/epoch - 8ms/step\n",
      "Epoch 218/300\n",
      "10/10 - 0s - loss: 41.5991 - mse: 41.5991 - mean_absolute_error: 5.2056 - r2_func_tf: 0.7288 - rmse_func_tf: 6.3698 - bias_func_tf: 0.0242 - sdep_func_tf: 4.6338 - val_loss: 27.6307 - val_mse: 27.6307 - val_mean_absolute_error: 3.9973 - val_r2_func_tf: 0.9346 - val_rmse_func_tf: 5.1624 - val_bias_func_tf: -1.4626e-01 - val_sdep_func_tf: 4.9785 - 88ms/epoch - 9ms/step\n",
      "Epoch 219/300\n",
      "10/10 - 0s - loss: 49.2543 - mse: 49.2543 - mean_absolute_error: 5.4518 - r2_func_tf: 0.8393 - rmse_func_tf: 6.5859 - bias_func_tf: -6.9167e-02 - sdep_func_tf: 4.9349 - val_loss: 27.7732 - val_mse: 27.7732 - val_mean_absolute_error: 3.9820 - val_r2_func_tf: 0.9351 - val_rmse_func_tf: 5.1759 - val_bias_func_tf: -3.6582e-01 - val_sdep_func_tf: 4.9818 - 85ms/epoch - 9ms/step\n",
      "Epoch 220/300\n",
      "10/10 - 0s - loss: 55.1545 - mse: 55.1545 - mean_absolute_error: 5.7157 - r2_func_tf: 0.7057 - rmse_func_tf: 7.1129 - bias_func_tf: -5.9951e-01 - sdep_func_tf: 5.0628 - val_loss: 27.6482 - val_mse: 27.6482 - val_mean_absolute_error: 4.0047 - val_r2_func_tf: 0.9344 - val_rmse_func_tf: 5.1629 - val_bias_func_tf: -1.0884e-01 - val_sdep_func_tf: 4.9817 - 85ms/epoch - 9ms/step\n",
      "Epoch 221/300\n",
      "10/10 - 0s - loss: 66.5554 - mse: 66.5554 - mean_absolute_error: 6.3009 - r2_func_tf: 0.3366 - rmse_func_tf: 7.7511 - bias_func_tf: 0.8893 - sdep_func_tf: 5.0383 - val_loss: 27.8671 - val_mse: 27.8671 - val_mean_absolute_error: 4.1178 - val_r2_func_tf: 0.9318 - val_rmse_func_tf: 5.1806 - val_bias_func_tf: 0.4757 - val_sdep_func_tf: 4.9808 - 85ms/epoch - 9ms/step\n",
      "Epoch 222/300\n",
      "10/10 - 0s - loss: 59.1696 - mse: 59.1696 - mean_absolute_error: 6.0388 - r2_func_tf: 0.8000 - rmse_func_tf: 7.5989 - bias_func_tf: -3.1473e-01 - sdep_func_tf: 5.1139 - val_loss: 27.6516 - val_mse: 27.6516 - val_mean_absolute_error: 4.0094 - val_r2_func_tf: 0.9345 - val_rmse_func_tf: 5.1608 - val_bias_func_tf: -1.0739e-01 - val_sdep_func_tf: 4.9844 - 86ms/epoch - 9ms/step\n",
      "Epoch 223/300\n",
      "10/10 - 0s - loss: 53.7236 - mse: 53.7236 - mean_absolute_error: 5.9800 - r2_func_tf: 0.7631 - rmse_func_tf: 6.7879 - bias_func_tf: 0.2517 - sdep_func_tf: 4.6489 - val_loss: 27.7188 - val_mse: 27.7188 - val_mean_absolute_error: 4.0785 - val_r2_func_tf: 0.9331 - val_rmse_func_tf: 5.1629 - val_bias_func_tf: 0.2835 - val_sdep_func_tf: 4.9847 - 86ms/epoch - 9ms/step\n",
      "Epoch 224/300\n",
      "10/10 - 0s - loss: 60.7853 - mse: 60.7853 - mean_absolute_error: 6.2084 - r2_func_tf: 0.7736 - rmse_func_tf: 7.1302 - bias_func_tf: 0.7272 - sdep_func_tf: 4.3949 - val_loss: 27.9271 - val_mse: 27.9271 - val_mean_absolute_error: 4.1299 - val_r2_func_tf: 0.9319 - val_rmse_func_tf: 5.1814 - val_bias_func_tf: 0.4959 - val_sdep_func_tf: 4.9898 - 84ms/epoch - 8ms/step\n",
      "Epoch 225/300\n",
      "10/10 - 0s - loss: 48.4283 - mse: 48.4283 - mean_absolute_error: 5.3683 - r2_func_tf: 0.8329 - rmse_func_tf: 6.4185 - bias_func_tf: 0.2703 - sdep_func_tf: 4.6245 - val_loss: 27.7604 - val_mse: 27.7604 - val_mean_absolute_error: 4.0096 - val_r2_func_tf: 0.9351 - val_rmse_func_tf: 5.1682 - val_bias_func_tf: -2.9119e-01 - val_sdep_func_tf: 4.9916 - 81ms/epoch - 8ms/step\n",
      "Epoch 226/300\n",
      "10/10 - 0s - loss: 50.3136 - mse: 50.3136 - mean_absolute_error: 5.6468 - r2_func_tf: 0.8294 - rmse_func_tf: 6.4327 - bias_func_tf: -8.0934e-01 - sdep_func_tf: 4.6300 - val_loss: 28.3601 - val_mse: 28.3601 - val_mean_absolute_error: 4.0034 - val_r2_func_tf: 0.9354 - val_rmse_func_tf: 5.2264 - val_bias_func_tf: -7.8777e-01 - val_sdep_func_tf: 4.9988 - 83ms/epoch - 8ms/step\n",
      "Epoch 227/300\n",
      "10/10 - 0s - loss: 43.5285 - mse: 43.5285 - mean_absolute_error: 5.2675 - r2_func_tf: 0.8423 - rmse_func_tf: 6.3815 - bias_func_tf: -8.3977e-01 - sdep_func_tf: 4.7755 - val_loss: 27.7384 - val_mse: 27.7384 - val_mean_absolute_error: 4.0231 - val_r2_func_tf: 0.9350 - val_rmse_func_tf: 5.1649 - val_bias_func_tf: -1.8505e-01 - val_sdep_func_tf: 4.9944 - 88ms/epoch - 9ms/step\n",
      "Epoch 228/300\n",
      "10/10 - 0s - loss: 38.9016 - mse: 38.9016 - mean_absolute_error: 4.7995 - r2_func_tf: 0.8978 - rmse_func_tf: 6.1315 - bias_func_tf: 0.0225 - sdep_func_tf: 5.0291 - val_loss: 28.2122 - val_mse: 28.2122 - val_mean_absolute_error: 4.1713 - val_r2_func_tf: 0.9309 - val_rmse_func_tf: 5.2073 - val_bias_func_tf: 0.6610 - val_sdep_func_tf: 4.9974 - 85ms/epoch - 8ms/step\n",
      "Epoch 229/300\n",
      "10/10 - 0s - loss: 49.7019 - mse: 49.7019 - mean_absolute_error: 5.5340 - r2_func_tf: 0.8755 - rmse_func_tf: 6.6663 - bias_func_tf: 0.3805 - sdep_func_tf: 5.0422 - val_loss: 28.6947 - val_mse: 28.6947 - val_mean_absolute_error: 4.2418 - val_r2_func_tf: 0.9288 - val_rmse_func_tf: 5.2519 - val_bias_func_tf: 0.9398 - val_sdep_func_tf: 4.9993 - 85ms/epoch - 8ms/step\n",
      "Epoch 230/300\n",
      "10/10 - 0s - loss: 83.0391 - mse: 83.0391 - mean_absolute_error: 7.7204 - r2_func_tf: 0.3645 - rmse_func_tf: 8.6703 - bias_func_tf: 1.1041 - sdep_func_tf: 5.1455 - val_loss: 28.6054 - val_mse: 28.6054 - val_mean_absolute_error: 4.2291 - val_r2_func_tf: 0.9291 - val_rmse_func_tf: 5.2432 - val_bias_func_tf: 0.9103 - val_sdep_func_tf: 4.9941 - 84ms/epoch - 8ms/step\n",
      "Epoch 231/300\n",
      "10/10 - 0s - loss: 71.8226 - mse: 71.8226 - mean_absolute_error: 6.7859 - r2_func_tf: 0.1457 - rmse_func_tf: 8.0275 - bias_func_tf: 0.7151 - sdep_func_tf: 5.1414 - val_loss: 27.7264 - val_mse: 27.7264 - val_mean_absolute_error: 4.0197 - val_r2_func_tf: 0.9355 - val_rmse_func_tf: 5.1613 - val_bias_func_tf: -3.1686e-01 - val_sdep_func_tf: 4.9845 - 81ms/epoch - 8ms/step\n",
      "Epoch 232/300\n",
      "10/10 - 0s - loss: 35.3702 - mse: 35.3702 - mean_absolute_error: 4.6097 - r2_func_tf: 0.9200 - rmse_func_tf: 5.6459 - bias_func_tf: -1.0457e+00 - sdep_func_tf: 4.5454 - val_loss: 28.6336 - val_mse: 28.6336 - val_mean_absolute_error: 4.0283 - val_r2_func_tf: 0.9354 - val_rmse_func_tf: 5.2497 - val_bias_func_tf: -1.0014e+00 - val_sdep_func_tf: 4.9863 - 81ms/epoch - 8ms/step\n",
      "Epoch 233/300\n",
      "10/10 - 0s - loss: 60.6592 - mse: 60.6592 - mean_absolute_error: 5.9963 - r2_func_tf: 0.5545 - rmse_func_tf: 7.1987 - bias_func_tf: -9.5579e-01 - sdep_func_tf: 4.9084 - val_loss: 27.7620 - val_mse: 27.7620 - val_mean_absolute_error: 4.0116 - val_r2_func_tf: 0.9357 - val_rmse_func_tf: 5.1672 - val_bias_func_tf: -4.3688e-01 - val_sdep_func_tf: 4.9796 - 80ms/epoch - 8ms/step\n",
      "Epoch 234/300\n",
      "10/10 - 0s - loss: 58.1427 - mse: 58.1427 - mean_absolute_error: 5.8123 - r2_func_tf: 0.7785 - rmse_func_tf: 6.9042 - bias_func_tf: 0.2991 - sdep_func_tf: 4.9420 - val_loss: 27.7246 - val_mse: 27.7246 - val_mean_absolute_error: 4.0701 - val_r2_func_tf: 0.9334 - val_rmse_func_tf: 5.1628 - val_bias_func_tf: 0.2830 - val_sdep_func_tf: 4.9838 - 81ms/epoch - 8ms/step\n",
      "Epoch 235/300\n",
      "10/10 - 0s - loss: 51.1608 - mse: 51.1608 - mean_absolute_error: 5.4038 - r2_func_tf: 0.8832 - rmse_func_tf: 6.4841 - bias_func_tf: -1.5717e-01 - sdep_func_tf: 4.6548 - val_loss: 27.6515 - val_mse: 27.6515 - val_mean_absolute_error: 4.0258 - val_r2_func_tf: 0.9351 - val_rmse_func_tf: 5.1569 - val_bias_func_tf: -1.6772e-01 - val_sdep_func_tf: 4.9829 - 82ms/epoch - 8ms/step\n",
      "Epoch 236/300\n",
      "10/10 - 0s - loss: 47.6793 - mse: 47.6793 - mean_absolute_error: 5.4617 - r2_func_tf: 0.8972 - rmse_func_tf: 6.3168 - bias_func_tf: -2.9608e-01 - sdep_func_tf: 4.9532 - val_loss: 27.5992 - val_mse: 27.5992 - val_mean_absolute_error: 4.0281 - val_r2_func_tf: 0.9350 - val_rmse_func_tf: 5.1509 - val_bias_func_tf: -1.0232e-01 - val_sdep_func_tf: 4.9798 - 83ms/epoch - 8ms/step\n",
      "Epoch 237/300\n",
      "10/10 - 0s - loss: 47.8102 - mse: 47.8102 - mean_absolute_error: 5.4732 - r2_func_tf: 0.7787 - rmse_func_tf: 7.1654 - bias_func_tf: -9.5703e-01 - sdep_func_tf: 5.0170 - val_loss: 27.6185 - val_mse: 27.6185 - val_mean_absolute_error: 4.0442 - val_r2_func_tf: 0.9341 - val_rmse_func_tf: 5.1522 - val_bias_func_tf: 0.1309 - val_sdep_func_tf: 4.9794 - 89ms/epoch - 9ms/step\n",
      "Epoch 238/300\n",
      "10/10 - 0s - loss: 36.0632 - mse: 36.0632 - mean_absolute_error: 4.6762 - r2_func_tf: 0.8892 - rmse_func_tf: 6.0608 - bias_func_tf: -2.2233e-01 - sdep_func_tf: 4.6930 - val_loss: 28.4092 - val_mse: 28.4092 - val_mean_absolute_error: 4.1906 - val_r2_func_tf: 0.9297 - val_rmse_func_tf: 5.2273 - val_bias_func_tf: 0.8251 - val_sdep_func_tf: 4.9879 - 84ms/epoch - 8ms/step\n",
      "Epoch 239/300\n",
      "10/10 - 0s - loss: 50.7869 - mse: 50.7869 - mean_absolute_error: 5.6415 - r2_func_tf: 0.7388 - rmse_func_tf: 6.7174 - bias_func_tf: 0.6446 - sdep_func_tf: 4.9894 - val_loss: 28.3564 - val_mse: 28.3564 - val_mean_absolute_error: 4.1826 - val_r2_func_tf: 0.9298 - val_rmse_func_tf: 5.2242 - val_bias_func_tf: 0.7773 - val_sdep_func_tf: 4.9915 - 87ms/epoch - 9ms/step\n",
      "Epoch 240/300\n",
      "10/10 - 0s - loss: 36.7801 - mse: 36.7801 - mean_absolute_error: 4.8098 - r2_func_tf: 0.6635 - rmse_func_tf: 5.9647 - bias_func_tf: 1.1152 - sdep_func_tf: 4.5225 - val_loss: 28.2077 - val_mse: 28.2077 - val_mean_absolute_error: 4.1572 - val_r2_func_tf: 0.9305 - val_rmse_func_tf: 5.2116 - val_bias_func_tf: 0.6637 - val_sdep_func_tf: 4.9933 - 83ms/epoch - 8ms/step\n",
      "Epoch 241/300\n",
      "10/10 - 0s - loss: 32.7251 - mse: 32.7251 - mean_absolute_error: 4.4525 - r2_func_tf: 0.8402 - rmse_func_tf: 5.6923 - bias_func_tf: -7.3056e-02 - sdep_func_tf: 4.8205 - val_loss: 27.6905 - val_mse: 27.6905 - val_mean_absolute_error: 4.0345 - val_r2_func_tf: 0.9339 - val_rmse_func_tf: 5.1636 - val_bias_func_tf: 0.0669 - val_sdep_func_tf: 4.9883 - 89ms/epoch - 9ms/step\n",
      "Epoch 242/300\n",
      "10/10 - 0s - loss: 39.6220 - mse: 39.6220 - mean_absolute_error: 4.7417 - r2_func_tf: 0.8659 - rmse_func_tf: 5.9923 - bias_func_tf: 0.3101 - sdep_func_tf: 4.9269 - val_loss: 27.7613 - val_mse: 27.7613 - val_mean_absolute_error: 4.0509 - val_r2_func_tf: 0.9334 - val_rmse_func_tf: 5.1708 - val_bias_func_tf: 0.1541 - val_sdep_func_tf: 4.9946 - 100ms/epoch - 10ms/step\n",
      "Epoch 243/300\n",
      "10/10 - 0s - loss: 39.3188 - mse: 39.3188 - mean_absolute_error: 5.0177 - r2_func_tf: 0.9035 - rmse_func_tf: 5.9806 - bias_func_tf: -3.0187e-01 - sdep_func_tf: 4.8407 - val_loss: 27.8678 - val_mse: 27.8678 - val_mean_absolute_error: 4.0007 - val_r2_func_tf: 0.9348 - val_rmse_func_tf: 5.1828 - val_bias_func_tf: -2.7154e-01 - val_sdep_func_tf: 4.9997 - 92ms/epoch - 9ms/step\n",
      "Epoch 244/300\n",
      "10/10 - 0s - loss: 46.1058 - mse: 46.1058 - mean_absolute_error: 5.3969 - r2_func_tf: 0.5804 - rmse_func_tf: 6.3133 - bias_func_tf: -4.8442e-01 - sdep_func_tf: 4.8732 - val_loss: 27.9512 - val_mse: 27.9512 - val_mean_absolute_error: 3.9975 - val_r2_func_tf: 0.9348 - val_rmse_func_tf: 5.1915 - val_bias_func_tf: -3.3160e-01 - val_sdep_func_tf: 5.0041 - 87ms/epoch - 9ms/step\n",
      "Epoch 245/300\n",
      "10/10 - 0s - loss: 57.1889 - mse: 57.1889 - mean_absolute_error: 5.6661 - r2_func_tf: 0.8468 - rmse_func_tf: 6.9735 - bias_func_tf: 0.2873 - sdep_func_tf: 4.8906 - val_loss: 27.8931 - val_mse: 27.8931 - val_mean_absolute_error: 4.0769 - val_r2_func_tf: 0.9328 - val_rmse_func_tf: 5.1861 - val_bias_func_tf: 0.2541 - val_sdep_func_tf: 5.0044 - 88ms/epoch - 9ms/step\n",
      "Epoch 246/300\n",
      "10/10 - 0s - loss: 54.6300 - mse: 54.6300 - mean_absolute_error: 5.9127 - r2_func_tf: 0.6456 - rmse_func_tf: 7.2130 - bias_func_tf: 0.5521 - sdep_func_tf: 4.8748 - val_loss: 27.8641 - val_mse: 27.8641 - val_mean_absolute_error: 4.0350 - val_r2_func_tf: 0.9338 - val_rmse_func_tf: 5.1834 - val_bias_func_tf: -2.1148e-03 - val_sdep_func_tf: 5.0096 - 89ms/epoch - 9ms/step\n",
      "Epoch 247/300\n",
      "10/10 - 0s - loss: 56.1699 - mse: 56.1699 - mean_absolute_error: 5.6131 - r2_func_tf: 0.8448 - rmse_func_tf: 6.8245 - bias_func_tf: -3.2393e-01 - sdep_func_tf: 4.9912 - val_loss: 27.8788 - val_mse: 27.8788 - val_mean_absolute_error: 4.0145 - val_r2_func_tf: 0.9346 - val_rmse_func_tf: 5.1840 - val_bias_func_tf: -2.1656e-01 - val_sdep_func_tf: 5.0064 - 90ms/epoch - 9ms/step\n",
      "Epoch 248/300\n",
      "10/10 - 0s - loss: 54.9450 - mse: 54.9450 - mean_absolute_error: 6.0198 - r2_func_tf: 0.8166 - rmse_func_tf: 7.0168 - bias_func_tf: -4.8119e-01 - sdep_func_tf: 4.7910 - val_loss: 27.7938 - val_mse: 27.7938 - val_mean_absolute_error: 4.0513 - val_r2_func_tf: 0.9337 - val_rmse_func_tf: 5.1743 - val_bias_func_tf: 0.1052 - val_sdep_func_tf: 5.0025 - 90ms/epoch - 9ms/step\n",
      "Epoch 249/300\n",
      "10/10 - 0s - loss: 34.0569 - mse: 34.0569 - mean_absolute_error: 4.5820 - r2_func_tf: 0.7943 - rmse_func_tf: 5.3630 - bias_func_tf: -4.6344e-01 - sdep_func_tf: 4.4845 - val_loss: 27.8739 - val_mse: 27.8739 - val_mean_absolute_error: 4.0828 - val_r2_func_tf: 0.9329 - val_rmse_func_tf: 5.1831 - val_bias_func_tf: 0.2601 - val_sdep_func_tf: 5.0060 - 90ms/epoch - 9ms/step\n",
      "Epoch 250/300\n",
      "10/10 - 0s - loss: 46.1772 - mse: 46.1772 - mean_absolute_error: 5.4558 - r2_func_tf: 0.8924 - rmse_func_tf: 6.3181 - bias_func_tf: -6.1474e-02 - sdep_func_tf: 4.6783 - val_loss: 28.1328 - val_mse: 28.1328 - val_mean_absolute_error: 4.1459 - val_r2_func_tf: 0.9312 - val_rmse_func_tf: 5.2081 - val_bias_func_tf: 0.5243 - val_sdep_func_tf: 5.0117 - 87ms/epoch - 9ms/step\n",
      "Epoch 251/300\n",
      "10/10 - 0s - loss: 54.9406 - mse: 54.9406 - mean_absolute_error: 5.6428 - r2_func_tf: 0.7555 - rmse_func_tf: 6.6718 - bias_func_tf: 0.5037 - sdep_func_tf: 4.5404 - val_loss: 28.2071 - val_mse: 28.2071 - val_mean_absolute_error: 4.1647 - val_r2_func_tf: 0.9307 - val_rmse_func_tf: 5.2152 - val_bias_func_tf: 0.6086 - val_sdep_func_tf: 5.0093 - 86ms/epoch - 9ms/step\n",
      "Epoch 252/300\n",
      "10/10 - 0s - loss: 47.9017 - mse: 47.9017 - mean_absolute_error: 5.1933 - r2_func_tf: 0.8178 - rmse_func_tf: 6.5713 - bias_func_tf: -6.4163e-01 - sdep_func_tf: 4.8447 - val_loss: 27.8040 - val_mse: 27.8040 - val_mean_absolute_error: 4.0176 - val_r2_func_tf: 0.9344 - val_rmse_func_tf: 5.1783 - val_bias_func_tf: -1.9820e-01 - val_sdep_func_tf: 5.0029 - 88ms/epoch - 9ms/step\n",
      "Epoch 253/300\n",
      "10/10 - 0s - loss: 50.4259 - mse: 50.4259 - mean_absolute_error: 5.5897 - r2_func_tf: 0.8371 - rmse_func_tf: 6.6532 - bias_func_tf: -2.4670e-01 - sdep_func_tf: 4.8143 - val_loss: 27.8334 - val_mse: 27.8334 - val_mean_absolute_error: 4.0797 - val_r2_func_tf: 0.9325 - val_rmse_func_tf: 5.1802 - val_bias_func_tf: 0.2832 - val_sdep_func_tf: 5.0019 - 88ms/epoch - 9ms/step\n",
      "Epoch 254/300\n",
      "10/10 - 0s - loss: 65.1575 - mse: 65.1575 - mean_absolute_error: 5.8997 - r2_func_tf: 0.2707 - rmse_func_tf: 8.1953 - bias_func_tf: 1.5752 - sdep_func_tf: 4.7913 - val_loss: 27.9027 - val_mse: 27.9027 - val_mean_absolute_error: 4.1009 - val_r2_func_tf: 0.9320 - val_rmse_func_tf: 5.1866 - val_bias_func_tf: 0.3706 - val_sdep_func_tf: 5.0035 - 87ms/epoch - 9ms/step\n",
      "Epoch 255/300\n",
      "10/10 - 0s - loss: 47.6464 - mse: 47.6464 - mean_absolute_error: 5.3634 - r2_func_tf: 0.8578 - rmse_func_tf: 7.3367 - bias_func_tf: -1.6254e+00 - sdep_func_tf: 4.6384 - val_loss: 27.9876 - val_mse: 27.9876 - val_mean_absolute_error: 3.9934 - val_r2_func_tf: 0.9348 - val_rmse_func_tf: 5.1972 - val_bias_func_tf: -4.8547e-01 - val_sdep_func_tf: 4.9981 - 88ms/epoch - 9ms/step\n",
      "Epoch 256/300\n",
      "10/10 - 0s - loss: 45.4521 - mse: 45.4521 - mean_absolute_error: 4.9418 - r2_func_tf: -1.0610e+00 - rmse_func_tf: 6.8367 - bias_func_tf: 0.5851 - sdep_func_tf: 5.3855 - val_loss: 27.8668 - val_mse: 27.8668 - val_mean_absolute_error: 4.0928 - val_r2_func_tf: 0.9319 - val_rmse_func_tf: 5.1826 - val_bias_func_tf: 0.3972 - val_sdep_func_tf: 4.9936 - 87ms/epoch - 9ms/step\n",
      "Epoch 257/300\n",
      "10/10 - 0s - loss: 61.7395 - mse: 61.7395 - mean_absolute_error: 6.1335 - r2_func_tf: 0.4826 - rmse_func_tf: 7.1729 - bias_func_tf: 0.7119 - sdep_func_tf: 4.6584 - val_loss: 27.7960 - val_mse: 27.7960 - val_mean_absolute_error: 4.0826 - val_r2_func_tf: 0.9322 - val_rmse_func_tf: 5.1745 - val_bias_func_tf: 0.3606 - val_sdep_func_tf: 4.9895 - 89ms/epoch - 9ms/step\n",
      "Epoch 258/300\n",
      "10/10 - 0s - loss: 39.5393 - mse: 39.5393 - mean_absolute_error: 4.8260 - r2_func_tf: 0.9003 - rmse_func_tf: 6.1981 - bias_func_tf: -7.4679e-01 - sdep_func_tf: 4.8315 - val_loss: 27.7185 - val_mse: 27.7185 - val_mean_absolute_error: 4.0107 - val_r2_func_tf: 0.9347 - val_rmse_func_tf: 5.1689 - val_bias_func_tf: -2.5683e-01 - val_sdep_func_tf: 4.9877 - 87ms/epoch - 9ms/step\n",
      "Epoch 259/300\n",
      "10/10 - 0s - loss: 36.3329 - mse: 36.3329 - mean_absolute_error: 4.7715 - r2_func_tf: 0.9141 - rmse_func_tf: 5.9430 - bias_func_tf: 0.0514 - sdep_func_tf: 4.7926 - val_loss: 27.7278 - val_mse: 27.7278 - val_mean_absolute_error: 4.0497 - val_r2_func_tf: 0.9330 - val_rmse_func_tf: 5.1694 - val_bias_func_tf: 0.1942 - val_sdep_func_tf: 4.9909 - 96ms/epoch - 10ms/step\n",
      "Epoch 260/300\n",
      "10/10 - 0s - loss: 54.4094 - mse: 54.4094 - mean_absolute_error: 5.5480 - r2_func_tf: 0.8666 - rmse_func_tf: 7.4236 - bias_func_tf: -1.0655e+00 - sdep_func_tf: 5.1885 - val_loss: 27.7027 - val_mse: 27.7027 - val_mean_absolute_error: 4.0177 - val_r2_func_tf: 0.9341 - val_rmse_func_tf: 5.1693 - val_bias_func_tf: -7.3329e-02 - val_sdep_func_tf: 4.9913 - 94ms/epoch - 9ms/step\n",
      "Epoch 261/300\n",
      "10/10 - 0s - loss: 61.8697 - mse: 61.8697 - mean_absolute_error: 6.2640 - r2_func_tf: 0.7687 - rmse_func_tf: 7.4640 - bias_func_tf: -1.7767e-01 - sdep_func_tf: 4.9461 - val_loss: 28.5725 - val_mse: 28.5725 - val_mean_absolute_error: 4.2109 - val_r2_func_tf: 0.9283 - val_rmse_func_tf: 5.2513 - val_bias_func_tf: 0.8816 - val_sdep_func_tf: 4.9989 - 88ms/epoch - 9ms/step\n",
      "Epoch 262/300\n",
      "10/10 - 0s - loss: 36.9104 - mse: 36.9104 - mean_absolute_error: 4.5935 - r2_func_tf: 0.5813 - rmse_func_tf: 6.4152 - bias_func_tf: 1.4124 - sdep_func_tf: 4.6166 - val_loss: 28.2497 - val_mse: 28.2497 - val_mean_absolute_error: 4.1643 - val_r2_func_tf: 0.9299 - val_rmse_func_tf: 5.2206 - val_bias_func_tf: 0.6881 - val_sdep_func_tf: 4.9980 - 85ms/epoch - 8ms/step\n",
      "Epoch 263/300\n",
      "10/10 - 0s - loss: 36.4699 - mse: 36.4699 - mean_absolute_error: 4.4000 - r2_func_tf: 0.8877 - rmse_func_tf: 6.2055 - bias_func_tf: -8.3358e-01 - sdep_func_tf: 5.2074 - val_loss: 27.7679 - val_mse: 27.7679 - val_mean_absolute_error: 4.0289 - val_r2_func_tf: 0.9334 - val_rmse_func_tf: 5.1766 - val_bias_func_tf: 0.0590 - val_sdep_func_tf: 4.9982 - 88ms/epoch - 9ms/step\n",
      "Epoch 264/300\n",
      "10/10 - 0s - loss: 38.3401 - mse: 38.3401 - mean_absolute_error: 4.7908 - r2_func_tf: 0.8738 - rmse_func_tf: 6.4414 - bias_func_tf: -9.1016e-01 - sdep_func_tf: 5.0597 - val_loss: 27.7122 - val_mse: 27.7122 - val_mean_absolute_error: 4.0419 - val_r2_func_tf: 0.9332 - val_rmse_func_tf: 5.1705 - val_bias_func_tf: 0.1706 - val_sdep_func_tf: 4.9898 - 85ms/epoch - 9ms/step\n",
      "Epoch 265/300\n",
      "10/10 - 0s - loss: 49.7601 - mse: 49.7601 - mean_absolute_error: 5.2401 - r2_func_tf: 0.8393 - rmse_func_tf: 7.2256 - bias_func_tf: -1.0816e+00 - sdep_func_tf: 5.1100 - val_loss: 27.8795 - val_mse: 27.8795 - val_mean_absolute_error: 4.0925 - val_r2_func_tf: 0.9318 - val_rmse_func_tf: 5.1875 - val_bias_func_tf: 0.3881 - val_sdep_func_tf: 4.9956 - 84ms/epoch - 8ms/step\n",
      "Epoch 266/300\n",
      "10/10 - 0s - loss: 40.3224 - mse: 40.3224 - mean_absolute_error: 5.0632 - r2_func_tf: 0.6594 - rmse_func_tf: 6.3563 - bias_func_tf: 1.2203 - sdep_func_tf: 4.8173 - val_loss: 29.6091 - val_mse: 29.6091 - val_mean_absolute_error: 4.3280 - val_r2_func_tf: 0.9240 - val_rmse_func_tf: 5.3491 - val_bias_func_tf: 1.3164 - val_sdep_func_tf: 5.0087 - 88ms/epoch - 9ms/step\n",
      "Epoch 267/300\n",
      "10/10 - 0s - loss: 53.6291 - mse: 53.6291 - mean_absolute_error: 5.6560 - r2_func_tf: 0.8056 - rmse_func_tf: 7.0627 - bias_func_tf: 0.1641 - sdep_func_tf: 5.0013 - val_loss: 27.9363 - val_mse: 27.9363 - val_mean_absolute_error: 4.1176 - val_r2_func_tf: 0.9315 - val_rmse_func_tf: 5.1920 - val_bias_func_tf: 0.4676 - val_sdep_func_tf: 4.9975 - 90ms/epoch - 9ms/step\n",
      "Epoch 268/300\n",
      "10/10 - 0s - loss: 51.4305 - mse: 51.4305 - mean_absolute_error: 5.6785 - r2_func_tf: 0.7765 - rmse_func_tf: 6.6255 - bias_func_tf: 0.4426 - sdep_func_tf: 4.7697 - val_loss: 27.8556 - val_mse: 27.8556 - val_mean_absolute_error: 4.1000 - val_r2_func_tf: 0.9319 - val_rmse_func_tf: 5.1832 - val_bias_func_tf: 0.4080 - val_sdep_func_tf: 4.9944 - 87ms/epoch - 9ms/step\n",
      "Epoch 269/300\n",
      "10/10 - 0s - loss: 33.7796 - mse: 33.7796 - mean_absolute_error: 4.5358 - r2_func_tf: 0.8799 - rmse_func_tf: 5.6946 - bias_func_tf: -4.9470e-02 - sdep_func_tf: 4.8191 - val_loss: 27.7538 - val_mse: 27.7538 - val_mean_absolute_error: 4.0712 - val_r2_func_tf: 0.9326 - val_rmse_func_tf: 5.1734 - val_bias_func_tf: 0.2803 - val_sdep_func_tf: 4.9921 - 92ms/epoch - 9ms/step\n",
      "Epoch 270/300\n",
      "10/10 - 0s - loss: 30.2980 - mse: 30.2980 - mean_absolute_error: 4.2786 - r2_func_tf: 0.9343 - rmse_func_tf: 5.1664 - bias_func_tf: 0.0878 - sdep_func_tf: 4.5666 - val_loss: 27.8555 - val_mse: 27.8555 - val_mean_absolute_error: 4.1023 - val_r2_func_tf: 0.9319 - val_rmse_func_tf: 5.1822 - val_bias_func_tf: 0.4271 - val_sdep_func_tf: 4.9918 - 90ms/epoch - 9ms/step\n",
      "Epoch 271/300\n",
      "10/10 - 0s - loss: 59.0233 - mse: 59.0233 - mean_absolute_error: 6.0264 - r2_func_tf: 0.7849 - rmse_func_tf: 7.2160 - bias_func_tf: -5.7315e-02 - sdep_func_tf: 4.9530 - val_loss: 27.8624 - val_mse: 27.8624 - val_mean_absolute_error: 4.1031 - val_r2_func_tf: 0.9318 - val_rmse_func_tf: 5.1838 - val_bias_func_tf: 0.4349 - val_sdep_func_tf: 4.9907 - 92ms/epoch - 9ms/step\n",
      "Epoch 272/300\n",
      "10/10 - 0s - loss: 32.4130 - mse: 32.4130 - mean_absolute_error: 4.4047 - r2_func_tf: 0.9001 - rmse_func_tf: 5.3587 - bias_func_tf: 0.2971 - sdep_func_tf: 4.5161 - val_loss: 27.7838 - val_mse: 27.7838 - val_mean_absolute_error: 4.0788 - val_r2_func_tf: 0.9324 - val_rmse_func_tf: 5.1770 - val_bias_func_tf: 0.3324 - val_sdep_func_tf: 4.9894 - 86ms/epoch - 9ms/step\n",
      "Epoch 273/300\n",
      "10/10 - 0s - loss: 40.3497 - mse: 40.3497 - mean_absolute_error: 5.0874 - r2_func_tf: 0.7833 - rmse_func_tf: 5.9409 - bias_func_tf: -7.8080e-02 - sdep_func_tf: 4.6390 - val_loss: 27.7081 - val_mse: 27.7081 - val_mean_absolute_error: 4.0658 - val_r2_func_tf: 0.9329 - val_rmse_func_tf: 5.1694 - val_bias_func_tf: 0.2825 - val_sdep_func_tf: 4.9842 - 85ms/epoch - 9ms/step\n",
      "Epoch 274/300\n",
      "10/10 - 0s - loss: 58.9962 - mse: 58.9962 - mean_absolute_error: 5.9450 - r2_func_tf: 0.8325 - rmse_func_tf: 7.1165 - bias_func_tf: 0.1419 - sdep_func_tf: 5.0575 - val_loss: 27.6254 - val_mse: 27.6254 - val_mean_absolute_error: 4.0325 - val_r2_func_tf: 0.9339 - val_rmse_func_tf: 5.1624 - val_bias_func_tf: 0.0566 - val_sdep_func_tf: 4.9839 - 83ms/epoch - 8ms/step\n",
      "Epoch 275/300\n",
      "10/10 - 0s - loss: 30.6141 - mse: 30.6141 - mean_absolute_error: 4.2193 - r2_func_tf: 0.9282 - rmse_func_tf: 5.2793 - bias_func_tf: -4.1518e-01 - sdep_func_tf: 4.5463 - val_loss: 27.5975 - val_mse: 27.5975 - val_mean_absolute_error: 4.0241 - val_r2_func_tf: 0.9341 - val_rmse_func_tf: 5.1607 - val_bias_func_tf: 0.0063 - val_sdep_func_tf: 4.9802 - 87ms/epoch - 9ms/step\n",
      "Epoch 276/300\n",
      "10/10 - 0s - loss: 36.8117 - mse: 36.8117 - mean_absolute_error: 4.8698 - r2_func_tf: 0.8724 - rmse_func_tf: 6.2024 - bias_func_tf: -7.3038e-01 - sdep_func_tf: 4.7451 - val_loss: 27.6915 - val_mse: 27.6915 - val_mean_absolute_error: 4.0623 - val_r2_func_tf: 0.9328 - val_rmse_func_tf: 5.1696 - val_bias_func_tf: 0.2829 - val_sdep_func_tf: 4.9825 - 83ms/epoch - 8ms/step\n",
      "Epoch 277/300\n",
      "10/10 - 0s - loss: 42.1929 - mse: 42.1929 - mean_absolute_error: 4.9782 - r2_func_tf: 0.8896 - rmse_func_tf: 6.1964 - bias_func_tf: 0.3948 - sdep_func_tf: 4.7960 - val_loss: 27.9076 - val_mse: 27.9076 - val_mean_absolute_error: 4.1243 - val_r2_func_tf: 0.9312 - val_rmse_func_tf: 5.1897 - val_bias_func_tf: 0.5506 - val_sdep_func_tf: 4.9816 - 82ms/epoch - 8ms/step\n",
      "Epoch 278/300\n",
      "10/10 - 0s - loss: 52.7948 - mse: 52.7948 - mean_absolute_error: 5.5592 - r2_func_tf: 0.8617 - rmse_func_tf: 6.7927 - bias_func_tf: 0.2115 - sdep_func_tf: 4.6609 - val_loss: 27.9797 - val_mse: 27.9797 - val_mean_absolute_error: 4.1374 - val_r2_func_tf: 0.9308 - val_rmse_func_tf: 5.1963 - val_bias_func_tf: 0.6023 - val_sdep_func_tf: 4.9827 - 82ms/epoch - 8ms/step\n",
      "Epoch 279/300\n",
      "10/10 - 0s - loss: 61.1891 - mse: 61.1891 - mean_absolute_error: 6.1269 - r2_func_tf: 0.8133 - rmse_func_tf: 7.7562 - bias_func_tf: -7.7791e-02 - sdep_func_tf: 5.1933 - val_loss: 27.7901 - val_mse: 27.7901 - val_mean_absolute_error: 4.0788 - val_r2_func_tf: 0.9322 - val_rmse_func_tf: 5.1801 - val_bias_func_tf: 0.3512 - val_sdep_func_tf: 4.9866 - 82ms/epoch - 8ms/step\n",
      "Epoch 280/300\n",
      "10/10 - 0s - loss: 27.4004 - mse: 27.4004 - mean_absolute_error: 4.0318 - r2_func_tf: 0.9199 - rmse_func_tf: 5.2765 - bias_func_tf: 0.6453 - sdep_func_tf: 4.6784 - val_loss: 27.9166 - val_mse: 27.9166 - val_mean_absolute_error: 4.1089 - val_r2_func_tf: 0.9313 - val_rmse_func_tf: 5.1922 - val_bias_func_tf: 0.4933 - val_sdep_func_tf: 4.9866 - 88ms/epoch - 9ms/step\n",
      "Epoch 281/300\n",
      "10/10 - 0s - loss: 43.7796 - mse: 43.7796 - mean_absolute_error: 5.0937 - r2_func_tf: 0.6425 - rmse_func_tf: 6.6406 - bias_func_tf: 0.8945 - sdep_func_tf: 4.9027 - val_loss: 27.6781 - val_mse: 27.6781 - val_mean_absolute_error: 4.0424 - val_r2_func_tf: 0.9331 - val_rmse_func_tf: 5.1690 - val_bias_func_tf: 0.1788 - val_sdep_func_tf: 4.9833 - 88ms/epoch - 9ms/step\n",
      "Epoch 282/300\n",
      "10/10 - 0s - loss: 40.5796 - mse: 40.5796 - mean_absolute_error: 4.8071 - r2_func_tf: 0.9088 - rmse_func_tf: 6.0554 - bias_func_tf: -4.1237e-01 - sdep_func_tf: 4.9877 - val_loss: 27.6784 - val_mse: 27.6784 - val_mean_absolute_error: 4.0071 - val_r2_func_tf: 0.9345 - val_rmse_func_tf: 5.1692 - val_bias_func_tf: -1.9327e-01 - val_sdep_func_tf: 4.9832 - 90ms/epoch - 9ms/step\n",
      "Epoch 283/300\n",
      "10/10 - 0s - loss: 64.8048 - mse: 64.8048 - mean_absolute_error: 6.0197 - r2_func_tf: 0.7616 - rmse_func_tf: 7.0663 - bias_func_tf: -5.2898e-01 - sdep_func_tf: 4.8797 - val_loss: 27.6879 - val_mse: 27.6879 - val_mean_absolute_error: 4.0097 - val_r2_func_tf: 0.9346 - val_rmse_func_tf: 5.1691 - val_bias_func_tf: -2.0471e-01 - val_sdep_func_tf: 4.9843 - 94ms/epoch - 9ms/step\n",
      "Epoch 284/300\n",
      "10/10 - 0s - loss: 41.4629 - mse: 41.4629 - mean_absolute_error: 5.0721 - r2_func_tf: 0.6442 - rmse_func_tf: 6.1402 - bias_func_tf: 0.0036 - sdep_func_tf: 4.7621 - val_loss: 27.6645 - val_mse: 27.6645 - val_mean_absolute_error: 4.0380 - val_r2_func_tf: 0.9334 - val_rmse_func_tf: 5.1659 - val_bias_func_tf: 0.1286 - val_sdep_func_tf: 4.9842 - 100ms/epoch - 10ms/step\n",
      "Epoch 285/300\n",
      "10/10 - 0s - loss: 61.2970 - mse: 61.2970 - mean_absolute_error: 6.2073 - r2_func_tf: 0.6737 - rmse_func_tf: 7.0507 - bias_func_tf: 0.1555 - sdep_func_tf: 4.9153 - val_loss: 27.6758 - val_mse: 27.6758 - val_mean_absolute_error: 4.0433 - val_r2_func_tf: 0.9332 - val_rmse_func_tf: 5.1664 - val_bias_func_tf: 0.1393 - val_sdep_func_tf: 4.9861 - 91ms/epoch - 9ms/step\n",
      "Epoch 286/300\n",
      "10/10 - 0s - loss: 46.0616 - mse: 46.0616 - mean_absolute_error: 5.3739 - r2_func_tf: 0.8902 - rmse_func_tf: 6.7020 - bias_func_tf: -2.0043e-01 - sdep_func_tf: 5.0160 - val_loss: 27.6886 - val_mse: 27.6886 - val_mean_absolute_error: 4.0429 - val_r2_func_tf: 0.9333 - val_rmse_func_tf: 5.1676 - val_bias_func_tf: 0.0835 - val_sdep_func_tf: 4.9906 - 94ms/epoch - 9ms/step\n",
      "Epoch 287/300\n",
      "10/10 - 0s - loss: 45.2928 - mse: 45.2928 - mean_absolute_error: 5.0728 - r2_func_tf: 0.8636 - rmse_func_tf: 6.8318 - bias_func_tf: -7.9303e-01 - sdep_func_tf: 5.0910 - val_loss: 27.7431 - val_mse: 27.7431 - val_mean_absolute_error: 4.0634 - val_r2_func_tf: 0.9327 - val_rmse_func_tf: 5.1714 - val_bias_func_tf: 0.2402 - val_sdep_func_tf: 4.9935 - 83ms/epoch - 8ms/step\n",
      "Epoch 288/300\n",
      "10/10 - 0s - loss: 44.6568 - mse: 44.6568 - mean_absolute_error: 5.2999 - r2_func_tf: 0.8347 - rmse_func_tf: 6.3694 - bias_func_tf: 0.0660 - sdep_func_tf: 5.0355 - val_loss: 28.2809 - val_mse: 28.2809 - val_mean_absolute_error: 4.1726 - val_r2_func_tf: 0.9296 - val_rmse_func_tf: 5.2191 - val_bias_func_tf: 0.7535 - val_sdep_func_tf: 4.9939 - 83ms/epoch - 8ms/step\n",
      "Epoch 289/300\n",
      "10/10 - 0s - loss: 35.0779 - mse: 35.0779 - mean_absolute_error: 4.5837 - r2_func_tf: -1.2792e-01 - rmse_func_tf: 6.0519 - bias_func_tf: 0.9198 - sdep_func_tf: 4.7117 - val_loss: 28.0950 - val_mse: 28.0950 - val_mean_absolute_error: 4.1434 - val_r2_func_tf: 0.9304 - val_rmse_func_tf: 5.2019 - val_bias_func_tf: 0.6372 - val_sdep_func_tf: 4.9916 - 81ms/epoch - 8ms/step\n",
      "Epoch 290/300\n",
      "10/10 - 0s - loss: 46.4547 - mse: 46.4547 - mean_absolute_error: 5.3376 - r2_func_tf: 0.8161 - rmse_func_tf: 6.5346 - bias_func_tf: 0.6210 - sdep_func_tf: 4.6875 - val_loss: 27.8122 - val_mse: 27.8122 - val_mean_absolute_error: 4.0810 - val_r2_func_tf: 0.9323 - val_rmse_func_tf: 5.1757 - val_bias_func_tf: 0.3220 - val_sdep_func_tf: 4.9949 - 82ms/epoch - 8ms/step\n",
      "Epoch 291/300\n",
      "10/10 - 0s - loss: 59.0343 - mse: 59.0343 - mean_absolute_error: 6.0897 - r2_func_tf: 0.7255 - rmse_func_tf: 7.3877 - bias_func_tf: -6.9962e-01 - sdep_func_tf: 5.0995 - val_loss: 27.7625 - val_mse: 27.7625 - val_mean_absolute_error: 4.0269 - val_r2_func_tf: 0.9343 - val_rmse_func_tf: 5.1744 - val_bias_func_tf: -2.2041e-01 - val_sdep_func_tf: 4.9962 - 84ms/epoch - 8ms/step\n",
      "Epoch 292/300\n",
      "10/10 - 0s - loss: 68.6059 - mse: 68.6059 - mean_absolute_error: 6.0219 - r2_func_tf: 0.7714 - rmse_func_tf: 8.4370 - bias_func_tf: -2.0369e+00 - sdep_func_tf: 5.4416 - val_loss: 28.0631 - val_mse: 28.0631 - val_mean_absolute_error: 4.0027 - val_r2_func_tf: 0.9348 - val_rmse_func_tf: 5.2053 - val_bias_func_tf: -5.6233e-01 - val_sdep_func_tf: 4.9984 - 82ms/epoch - 8ms/step\n",
      "Epoch 293/300\n",
      "10/10 - 0s - loss: 48.7029 - mse: 48.7029 - mean_absolute_error: 5.5634 - r2_func_tf: 0.8171 - rmse_func_tf: 6.7429 - bias_func_tf: -2.0402e-01 - sdep_func_tf: 4.7781 - val_loss: 28.4691 - val_mse: 28.4691 - val_mean_absolute_error: 4.1925 - val_r2_func_tf: 0.9285 - val_rmse_func_tf: 5.2396 - val_bias_func_tf: 0.8448 - val_sdep_func_tf: 4.9976 - 85ms/epoch - 9ms/step\n",
      "Epoch 294/300\n",
      "10/10 - 0s - loss: 62.7220 - mse: 62.7220 - mean_absolute_error: 5.9574 - r2_func_tf: -3.1698e-03 - rmse_func_tf: 7.5107 - bias_func_tf: 1.9620 - sdep_func_tf: 4.8702 - val_loss: 29.1821 - val_mse: 29.1821 - val_mean_absolute_error: 4.2761 - val_r2_func_tf: 0.9254 - val_rmse_func_tf: 5.3047 - val_bias_func_tf: 1.1817 - val_sdep_func_tf: 5.0006 - 88ms/epoch - 9ms/step\n",
      "Epoch 295/300\n",
      "10/10 - 0s - loss: 51.6642 - mse: 51.6642 - mean_absolute_error: 5.6666 - r2_func_tf: 0.6854 - rmse_func_tf: 6.7122 - bias_func_tf: 0.6409 - sdep_func_tf: 4.9304 - val_loss: 27.7532 - val_mse: 27.7532 - val_mean_absolute_error: 4.0366 - val_r2_func_tf: 0.9337 - val_rmse_func_tf: 5.1756 - val_bias_func_tf: -9.7702e-02 - val_sdep_func_tf: 5.0004 - 94ms/epoch - 9ms/step\n",
      "Epoch 296/300\n",
      "10/10 - 0s - loss: 44.8456 - mse: 44.8456 - mean_absolute_error: 5.1583 - r2_func_tf: 0.8759 - rmse_func_tf: 6.6841 - bias_func_tf: -1.0513e+00 - sdep_func_tf: 4.8811 - val_loss: 28.2716 - val_mse: 28.2716 - val_mean_absolute_error: 4.0091 - val_r2_func_tf: 0.9344 - val_rmse_func_tf: 5.2265 - val_bias_func_tf: -6.2721e-01 - val_sdep_func_tf: 5.0138 - 87ms/epoch - 9ms/step\n",
      "Epoch 297/300\n",
      "10/10 - 0s - loss: 50.0964 - mse: 50.0964 - mean_absolute_error: 5.4252 - r2_func_tf: 0.8717 - rmse_func_tf: 6.7571 - bias_func_tf: -7.7966e-01 - sdep_func_tf: 5.2050 - val_loss: 28.1069 - val_mse: 28.1069 - val_mean_absolute_error: 4.0068 - val_r2_func_tf: 0.9342 - val_rmse_func_tf: 5.2114 - val_bias_func_tf: -4.1735e-01 - val_sdep_func_tf: 5.0196 - 88ms/epoch - 9ms/step\n",
      "Epoch 298/300\n",
      "10/10 - 0s - loss: 43.9061 - mse: 43.9061 - mean_absolute_error: 5.2107 - r2_func_tf: 0.8626 - rmse_func_tf: 6.6074 - bias_func_tf: -3.0837e-01 - sdep_func_tf: 4.8682 - val_loss: 28.1171 - val_mse: 28.1171 - val_mean_absolute_error: 4.1204 - val_r2_func_tf: 0.9309 - val_rmse_func_tf: 5.2088 - val_bias_func_tf: 0.4850 - val_sdep_func_tf: 5.0146 - 87ms/epoch - 9ms/step\n",
      "Epoch 299/300\n",
      "10/10 - 0s - loss: 54.3382 - mse: 54.3382 - mean_absolute_error: 6.1492 - r2_func_tf: 0.5719 - rmse_func_tf: 7.2221 - bias_func_tf: 1.1120 - sdep_func_tf: 4.8319 - val_loss: 28.1716 - val_mse: 28.1716 - val_mean_absolute_error: 4.1334 - val_r2_func_tf: 0.9306 - val_rmse_func_tf: 5.2127 - val_bias_func_tf: 0.5364 - val_sdep_func_tf: 5.0150 - 89ms/epoch - 9ms/step\n",
      "Epoch 300/300\n",
      "10/10 - 0s - loss: 30.7384 - mse: 30.7384 - mean_absolute_error: 4.1595 - r2_func_tf: 0.9190 - rmse_func_tf: 5.1225 - bias_func_tf: 0.4521 - sdep_func_tf: 4.5272 - val_loss: 27.9002 - val_mse: 27.9002 - val_mean_absolute_error: 4.0616 - val_r2_func_tf: 0.9329 - val_rmse_func_tf: 5.1877 - val_bias_func_tf: 0.1342 - val_sdep_func_tf: 5.0154 - 89ms/epoch - 9ms/step\n"
     ]
    }
   ],
   "source": [
    "history=test_model.fit(X_padded_train, y_1_train,\n",
    "            epochs = epochs,\n",
    "            batch_size=batch,\n",
    "            verbose = 2,\n",
    "            validation_data =(X_padded_val, y_1_val),\n",
    "             # validation_split = 0.2,\n",
    "            callbacks=keras_callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "id": "f18d7820-a849-4d99-851f-24ccaa9d9a97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "5/5 [==============================] - 0s 2ms/step\n"
     ]
    }
   ],
   "source": [
    "predictions_test = test_model.predict(X_padded_test)\n",
    "predictions_val = test_model.predict(X_padded_val)\n",
    "predictions_train = test_model.predict(X_padded_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "id": "d020afd9-d159-4f3c-8111-970b805ce1c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test: r2 = 0.937] | rmsd = 5.320\n"
     ]
    }
   ],
   "source": [
    "r2, rmsd, bias, sdep, plot_a, plot_b, mse, mae = stats_hp(predictions_test, Y_test, prop)\n",
    "print(f'test: r2 = {r2}] | rmsd = {rmsd}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "id": "976b0930-86c6-44b4-bcd0-d6e32846cb98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val: r2 = 0.950] | rmsd = 5.282\n"
     ]
    }
   ],
   "source": [
    "r2, rmsd, bias, sdep, plot_a, plot_b, mse, mae = stats_hp(predictions_val, Y_val, prop)\n",
    "print(f'val: r2 = {r2}] | rmsd = {rmsd}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "id": "ff6727f1-5f2b-4741-bc73-0dc9fb5cf310",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: r2 = 0.946] | rmsd = 4.997\n"
     ]
    }
   ],
   "source": [
    "r2, rmsd, bias, sdep, plot_a, plot_b, mse, mae = stats_hp(predictions_train, Y_train, prop)\n",
    "print(f'train: r2 = {r2}] | rmsd = {rmsd}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "id": "a918ed7f-9e00-4bfb-a2b5-bca15f455eb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def stats_csv(y_test_pred, Y_test, prop, csv_name, set_type,resample):\n",
    "    y_test_np = Y_test[f'{prop}'].to_numpy()\n",
    "    y_pred_test_np = y_test_pred\n",
    "\n",
    "    r2_test = r2_score(y_test_np, y_pred_test_np)\n",
    "    rmsd_test = (mean_squared_error(y_test_np, y_pred_test_np))**0.5\n",
    "    bias_test = np.mean(y_pred_test_np - y_test_np)\n",
    "    sdep_test = (np.mean((y_pred_test_np - y_test_np - bias_test)**2))**0.5\n",
    "    r2 = '{:.3f}'.format(r2_test)\n",
    "    rmsd = '{:.3f}'.format(rmsd_test)\n",
    "    bias = '{:.3f}'.format(bias_test)\n",
    "    sdep = '{:.3f}'.format(sdep_test)\n",
    "    \n",
    "    \n",
    "    mse=mean_squared_error(y_test_np, y_pred_test_np)\n",
    "    mse='{:.3f}'.format(mse)\n",
    "    mae=mean_absolute_error(y_test_np, y_pred_test_np)\n",
    "    mae='{:.3f}'.format(mae)\n",
    "    try:\n",
    "        a, b = np.polyfit(y_test_np, y_pred_test_np, 1)\n",
    "        plot_a = '{:.3f}'.format(a[0])\n",
    "        plot_b = '{:.3f}'.format(b[0])\n",
    "    except np.linalg.LinAlgError:\n",
    "        pass\n",
    "        # 'index':np.array(Y_test.index),'ID':np.array(Y_test.index +1),\n",
    "    y_pred_test_np = y_test_pred.squeeze()\n",
    "    csv_df=pd.DataFrame({'index':np.array(Y_test.index),'ID':np.array(Y_test.index +1),'y_true': y_test_np, 'y_pred': y_pred_test_np})\n",
    "    csv_df.to_csv(csv_name,index=None)\n",
    "\n",
    "    csv_df_stats=pd.DataFrame(data=np.array([[resample, r2, rmsd, bias, sdep, plot_a, plot_b, mse, mae]]),\n",
    "                              # index=None, \n",
    "                              columns=['resample','r2','rmsd', 'bias', 'sdep', 'plot_a', 'plot_b', 'mse', 'mae'])\n",
    "    csv_df_stats.to_csv(f'{csv_name[:-4]}_stats.csv',mode='a',index='resample')\n",
    "    \n",
    "    return csv_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "id": "9f42b96d-7ce6-4c6f-95e5-d25f58578204",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'test'"
      ]
     },
     "execution_count": 319,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "csv_name[:-4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "id": "26c5e66e-9d79-43b9-89ff-a097b6eb92dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n"
     ]
    }
   ],
   "source": [
    "# for set_type in ['test','val','train']:\n",
    "set_types = ['train','val','test']\n",
    "set_type = 'test'\n",
    "csv_name=f'{directory_path}/{set_type}.csv'\n",
    "csv_name=f'{set_type}.csv'\n",
    "\n",
    "list_indexes = [train, val, test]\n",
    "index_counter=-1\n",
    "for indexes in list_indexes:\n",
    "    index_counter+=1\n",
    "    csv_name=f'{directory_path}/{set_types[index_counter]}.csv'\n",
    "    y_1,  y_2,  y_3,  y_4,  Y,  X_padded,  X  = load_xy(indexes,desc)\n",
    "    predictions = test_model.predict(X_padded)\n",
    "    csv_df = stats_csv(predictions, Y, prop, csv_name, set_types[index_counter],resample)\n",
    "\n",
    "# r2, rmsd, bias, sdep, plot_a, plot_b, mse, mae , csv_df = stats_csv(predictions_test, Y_test, prop, set_type)\n",
    "# csv_df.to_csv(csv_name,index=None)\n",
    "# r2, rmsd, bias, sdep, plot_a, plot_b, mse, mae , csv_df_val = stats_csv(predictions_val, Y_val, prop)\n",
    "# r2, rmsd, bias, sdep, plot_a, plot_b, mse, mae , csv_df_train = stats_csv(predictions_train, Y_train, prop)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd706852-d855-4296-b793-77db02785c44",
   "metadata": {},
   "source": [
    "## Access resamples data and produce individual or erro bar plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "id": "14bb4997-a8c1-4951-aabf-6f851925cfb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "# csv_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 594,
   "id": "2ce38ff3-5ec5-40cf-b4c1-e4652ef6f2dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code Execution \n",
    "\n",
    "# df=pd.read_csv(\"Lomzov_dataset_IY.csv\")\n",
    "home=os.getcwd()\n",
    "# data Generation\n",
    "# cv_hp(df,home)\n",
    "\n",
    "# Actual instrucitons\n",
    "# GSHT_list=['dH','dS','dG','Tm']\n",
    "resample=0\n",
    "# fold=5\n",
    "desc='RF-Score'\n",
    "prop = 'dH' \n",
    "model_name = f\"1DConv_st_{prop}\" \n",
    "# epochs = 300\n",
    "# batch  = 16"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2559c113-a43e-4cd9-aefa-237c59c7684f",
   "metadata": {},
   "source": [
    "## Compile Plot error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 595,
   "id": "0cc52a39-05b4-46b8-a549-e26e8df0d5ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_err(stats_stack,csv_stacks,model_name,prop,desc,set_type):\n",
    "    \n",
    "    model_name\n",
    "    if prop == 'Tm':\n",
    "        name = 'T'\n",
    "    elif prop == 'dS':\n",
    "        name = 'S'\n",
    "    elif prop == 'dH':\n",
    "        name = 'H'\n",
    "    else:\n",
    "        name = 'G'\n",
    "    # name = prop\n",
    "    descriptor_name = desc\n",
    "    set_name=set_type\n",
    "# Compute mean and std in pred, access true value, compute mean and std in stats\n",
    "    y_pred_test = csv_stacks.filter(like='y_pred').mean(axis=1)\n",
    "    yerr = csv_stacks.filter(like='y_pred').std(axis=1)\n",
    "    y_test = csv_stacks.filter(like='y_true').mean(axis=1)\n",
    "    stats_describe=stats_stack.describe()  \n",
    "    \n",
    "#     Load list\n",
    "\n",
    "    # Average results over resamples:\n",
    "    r2 = '{:.3f}'.format(stats_describe['r2']['mean'])\n",
    "    rmsd = '{:.3f}'.format(stats_describe['rmsd']['mean'])\n",
    "    bias = '{:.3f}'.format(stats_describe['bias']['mean'])\n",
    "    sdep = '{:.3f}'.format(stats_describe['sdep']['mean'])\n",
    "    # Sample Standard deviation results over resamples\n",
    "    r2_sd = '{:.3f}'.format(stats_describe['r2']['std'])\n",
    "    rmsd_sd = '{:.3f}'.format(stats_describe['rmsd']['std'])\n",
    "    bias_sd = '{:.3f}'.format(stats_describe['bias']['std'])\n",
    "    sdep_sd = '{:.3f}'.format(stats_describe['sdep']['std'])\n",
    "\n",
    "\n",
    "    fig, ax = plt.subplots()   \n",
    "\n",
    "     # Line of best fit\n",
    "    try:\n",
    "        a, b = np.polyfit(y_test, y_pred_test, 1)\n",
    "        plot_a = '{:.3f}'.format(a)\n",
    "        plot_b = '{:.3f}'.format(b)\n",
    "    except np.linalg.LinAlgError:\n",
    "        pass\n",
    "\n",
    "    # Plot everything\n",
    "    try:\n",
    "#         Tab tittle\n",
    "        if name=='T':\n",
    "            plt.title(f'{model_name} | ${name}_m$ | {descriptor_name} | {set_name} set')\n",
    "            plt.plot([], [], ' ', label=f'{model_name} | ${name}_m$ | {set_name} set')\n",
    "        elif name=='S':\n",
    "            plt.title(f'{model_name} | Δ{name} | {descriptor_name} | {set_name} set')\n",
    "            plt.plot([], [], ' ', label=f'{model_name} | Δ{name} | {set_name} set')\n",
    "        else:\n",
    "            plt.title(f'{model_name} | Δ{name} | {descriptor_name} | {set_name} set')\n",
    "            plt.plot([], [], ' ', label=f'{model_name} | Δ{name} | {set_name} set')\n",
    "\n",
    "#         Stats\n",
    "        plt.plot([], [], ' ', label=f'$R^{2}$ : {r2} $\\pm$ {r2_sd} ')\n",
    "        plt.plot([], [], ' ', label=f'RMSD : {rmsd} $\\pm$ {rmsd_sd} ')\n",
    "        plt.plot([], [], ' ', label=f'Bias : {bias} $\\pm$ {bias_sd} ')\n",
    "        plt.plot([], [], ' ', label=f'SDEP : {sdep} $\\pm$ {sdep_sd} ')\n",
    "#         provide information about the gradient\n",
    "        plt.plot([], [], ' ', label=f'y = {plot_a}x + {plot_b}')       \n",
    "#         plot scatter plot\n",
    "        plt.scatter(y_test, y_pred_test)\n",
    "#         Plot error bars\n",
    "        plt.errorbar(y_test, y_pred_test, yerr=yerr, fmt='none',ecolor='black',elinewidth=0.8,capsize=2,\n",
    "                    barsabove=False)\n",
    "#     plot line of best fit\n",
    "        plt.plot(y_test, a * y_test + b, color='purple')\n",
    "        order = [0,1,2,3,4,5]\n",
    "    except NameError:\n",
    "        pass\n",
    "\n",
    "    # x=y line\n",
    "    lims = [\n",
    "            np.min([ax.get_xlim(), ax.get_ylim()]),  # min of both axes\n",
    "            np.max([ax.get_xlim(), ax.get_ylim()]),  # max of both axes\n",
    "           ]\n",
    "    ax.plot(lims, lims, 'k--', alpha=0.75, zorder=0)\n",
    "    ax.set_aspect('equal')\n",
    "    ax.set_xlim(lims)\n",
    "    ax.set_ylim(lims)\n",
    "\n",
    "    # Legend\n",
    "#     Axis labes\n",
    "    if name=='T':\n",
    "        plt.xlabel(f' ${name}_m$ True (°C)')\n",
    "        plt.ylabel(f' ${name}_m$ Pred (°C)')\n",
    "    elif name=='S':\n",
    "        plt.xlabel(f' Δ{name} True (cal/mol/K)')\n",
    "        plt.ylabel(f' Δ{name} Pred (cal/mol/K)')\n",
    "    else:\n",
    "        plt.xlabel(f' Δ{name} True (kcal/mol)')\n",
    "        plt.ylabel(f' Δ{name} Pred (kcal/mol)')\n",
    "#     legend labels\n",
    "    handles, labels = plt.gca().get_legend_handles_labels()\n",
    "    leg = plt.legend([handles[idx] for idx in order],[labels[idx] for idx in order])\n",
    "    leg.get_frame().set_linewidth(0.0)\n",
    "#     Most crucail -> file name! \n",
    "    fig.savefig(f'Resamples_mean_std_{model_name}_{set_name}_{name}_{descriptor_name}.png', bbox_inches='tight', dpi=800)\n",
    "#     clear and close fig\n",
    "    plt.clf()\n",
    "    plt.cla()\n",
    "    plt.close(fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86fd481a-d10d-46b6-b7da-137778d86767",
   "metadata": {},
   "source": [
    "## Compiled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "527bc2e2-8c7f-4f9f-9356-6e4050a4271e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 622,
   "id": "fb782c6a-df23-4fe5-9ca4-b812f7f9cf87",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def plots(csv_name):\n",
    "\n",
    "    csv_df_stats=pd.read_csv(f'{csv_name[:-4]}_stats.csv')\n",
    "    csv_df=pd.read_csv(f'{csv_name[:-4]}.csv',index_col='ID')\n",
    "    return csv_df_stats,csv_df\n",
    "\n",
    "directory_path = Path(f\"{os.getcwd()}/CV/{resample}/{desc}/{model_name}/\")\n",
    "\n",
    "set_types = ['train','val','test']\n",
    "set_type = 'test'\n",
    "desc='CountDNAp'\n",
    "for prop in GSHT_list:\n",
    "    model_name = f\"1DConv_st_{prop}\" \n",
    "    for set_type in set_types:\n",
    "        stats_stack=pd.DataFrame()\n",
    "        csv_stacks=pd.DataFrame()\n",
    "        for resample in range(50):\n",
    "            try:\n",
    "                directory_path = Path(f\"{os.getcwd()}/CV/{resample}/{desc}/{model_name}/\")\n",
    "                csv_name=f'{directory_path}/{set_type}.csv'\n",
    "                csv_df_stats,csv_df=plots(csv_name)\n",
    "                stats_stack=pd.concat([stats_stack,csv_df_stats],\n",
    "                                        axis=0)\n",
    "                csv_stacks=pd.concat([csv_stacks,csv_df],\n",
    "                                        axis=1)\n",
    "                result = pd.concat([csv_stacks, csv_df], axis=1, join='outer')\n",
    "            except:\n",
    "                print(resample)\n",
    "                pass\n",
    "        plot_err(stats_stack,csv_stacks,model_name,prop,desc,set_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 605,
   "id": "99c73068-028a-4d7f-b460-c99e222f3143",
   "metadata": {},
   "outputs": [],
   "source": [
    "# result\n",
    "desc\n",
    "desc_type = ['Granulated', 'OHEP', 'LP_dec2', 'DNA-Groups']\n",
    "desc_type = ['RF-Score', 'CountDNAp', 'H-Bonding']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 608,
   "id": "e80172cb-b1d6-461b-b7cb-66a29e1a928b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RF-Score 1\n",
      "RF-Score 6\n",
      "RF-Score 24\n",
      "RF-Score 34\n",
      "RF-Score 1\n",
      "RF-Score 6\n",
      "RF-Score 24\n",
      "RF-Score 34\n",
      "RF-Score 1\n",
      "RF-Score 6\n",
      "RF-Score 24\n",
      "RF-Score 34\n",
      "H-Bonding 27\n",
      "H-Bonding 27\n",
      "H-Bonding 27\n"
     ]
    }
   ],
   "source": [
    "desc='RF-Score'\n",
    "columns=['Model_name','Descriptor', 'Property','Units','Set_type',\n",
    "                                          'r2','r2_std', \n",
    "                                          'rmsd','rmsd_std', \n",
    "                                          'bias','bias_std',\n",
    "                                         'sdep','sdep_std',\n",
    "                                          'a','a_std',\n",
    "                                          'b','b_std',\n",
    "                                          'mse','mse_std',\n",
    "                                          'mae' ,'mae_std']\n",
    "df_stats_comparison=pd.DataFrame(columns=columns)\n",
    "for desc in desc_type:\n",
    "    for prop in GSHT_list:\n",
    "        units='N'\n",
    "        model_name = f\"1DConv_st_{prop}\" \n",
    "        for set_type in set_types:\n",
    "            stats_stack=pd.DataFrame()\n",
    "            csv_stacks=pd.DataFrame()\n",
    "            for resample in range(50):\n",
    "                try:\n",
    "                    directory_path = Path(f\"{os.getcwd()}/CV/{resample}/{desc}/{model_name}/\")\n",
    "                    csv_name=f'{directory_path}/{set_type}.csv'\n",
    "                    csv_df_stats,csv_df=plots(csv_name)\n",
    "                    stats_stack=pd.concat([stats_stack,csv_df_stats],\n",
    "                                            axis=0)\n",
    "                    csv_stacks=pd.concat([csv_stacks,csv_df],\n",
    "                                            axis=1)\n",
    "                    result = pd.concat([csv_stacks, csv_df], axis=1, join='outer')\n",
    "                except:\n",
    "                    print(desc,resample)\n",
    "                    pass\n",
    "            stats_describe=stats_stack.describe()  \n",
    "            # Average results over resamples:\n",
    "            r2 = '{:.3f}'.format(stats_describe['r2']['mean'])\n",
    "            rmsd = '{:.3f}'.format(stats_describe['rmsd']['mean'])\n",
    "            bias = '{:.3f}'.format(stats_describe['bias']['mean'])\n",
    "            sdep = '{:.3f}'.format(stats_describe['sdep']['mean'])\n",
    "            a = '{:.3f}'.format(stats_describe['plot_a']['mean'])\n",
    "            b = '{:.3f}'.format(stats_describe['plot_b']['mean'])\n",
    "            mse = '{:.3f}'.format(stats_describe['mse']['mean'])\n",
    "            mae = '{:.3f}'.format(stats_describe['mae']['mean'])\n",
    "            # Sample Standard deviation results over resamples\n",
    "            r2_sd = '{:.3f}'.format(stats_describe['r2']['std'])\n",
    "            rmsd_sd = '{:.3f}'.format(stats_describe['rmsd']['std'])\n",
    "            bias_sd = '{:.3f}'.format(stats_describe['bias']['std'])\n",
    "            sdep_sd = '{:.3f}'.format(stats_describe['sdep']['std'])\n",
    "            a_sd = '{:.3f}'.format(stats_describe['plot_a']['std'])\n",
    "            b_sd = '{:.3f}'.format(stats_describe['plot_b']['std'])\n",
    "            mse_sd = '{:.3f}'.format(stats_describe['mse']['std'])\n",
    "            mae_sd = '{:.3f}'.format(stats_describe['mae']['std'])\n",
    "            \n",
    "            # df_stats_comparison = \n",
    "            # f'SDEP : {sdep} $\\pm$ {sdep_sd} '\n",
    "    \n",
    "            new_row_values = [model_name,desc,prop,units,set_type,r2,r2_sd,rmsd,rmsd_sd,bias,bias_sd,sdep,sdep_sd,a,a_sd,b,b_sd,mse,mse_sd,mae,mae_sd]\n",
    "            df_stats_comparison = pd.concat([df_stats_comparison,pd.DataFrame(new_row_values, index=columns).T])\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 481,
   "id": "004c50dd-aef1-4366-a4d8-5cc6e9d68217",
   "metadata": {},
   "outputs": [],
   "source": [
    "bias_sd = '{:.3f}'.format(stats_describe['bias']['std'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 609,
   "id": "405ec01e-1a79-49d8-a8f7-f73254db9373",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_stats_comparison.to_csv('1Dconv_st_all_descriptors_all_properties_H_RF_Count_stats.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abec48c1-a4cb-40b9-9b8a-48bb885bfab2",
   "metadata": {},
   "source": [
    "### SK-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 610,
   "id": "f205e0ba-cc64-447c-9c7f-34e9e2579bfe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/users/qdb16186/SK-learn/CV/'"
      ]
     },
     "execution_count": 610,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path_sk = '/users/qdb16186/SK-learn/CV/'\n",
    "os.getcwd()\n",
    "path_sk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 611,
   "id": "925c388f-ac44-4624-9422-10fca9107b17",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plots_sk(csv_name):\n",
    "\n",
    "    csv_df=pd.read_csv(f'{csv_name}',index_col='ID')\n",
    "    return csv_df\n",
    "\n",
    "def stats_csv_sk(y_test_pred, Y_test, resample):\n",
    "    y_test_np = Y_test\n",
    "    y_pred_test_np = y_test_pred\n",
    "\n",
    "    r2_test = r2_score(y_test_np, y_pred_test_np)\n",
    "    rmsd_test = (mean_squared_error(y_test_np, y_pred_test_np))**0.5\n",
    "    bias_test = np.mean(y_pred_test_np - y_test_np)\n",
    "    sdep_test = (np.mean((y_pred_test_np - y_test_np - bias_test)**2))**0.5\n",
    "    r2 = '{:.3f}'.format(r2_test)\n",
    "    rmsd = '{:.3f}'.format(rmsd_test)\n",
    "    bias = '{:.3f}'.format(bias_test)\n",
    "    sdep = '{:.3f}'.format(sdep_test)\n",
    "    \n",
    "    \n",
    "    mse=mean_squared_error(y_test_np, y_pred_test_np)\n",
    "    # mse='{:.3f}'.format(mse)\n",
    "    mae=mean_absolute_error(y_test_np, y_pred_test_np)\n",
    "    # mae='{:.3f}'.format(mae)\n",
    "    try:\n",
    "        a, b = np.polyfit(y_test_np, y_pred_test_np, 1)\n",
    "        plot_a = '{:.3f}'.format(a)\n",
    "        plot_b = '{:.3f}'.format(b)\n",
    "    except np.linalg.LinAlgError:\n",
    "        pass\n",
    "        # 'index':np.array(Y_test.index),'ID':np.array(Y_test.index +1),\n",
    "    # y_pred_test_np = y_test_pred.squeeze()\n",
    "    # csv_df=pd.DataFrame({'index':np.array(Y_test.index),'ID':np.array(Y_test.index +1),'y_true': y_test_np, 'y_pred': y_pred_test_np})\n",
    "    # csv_df.to_csv(csv_name,index=None)\n",
    "\n",
    "    csv_df_stats=pd.DataFrame(data=np.array([[resample, r2_test, rmsd_test, bias_test, sdep_test, a, b, mse, mae]]),\n",
    "                              # index=None, \n",
    "                              columns=['resample','r2','rmsd', 'bias', 'sdep', 'plot_a', 'plot_b', 'mse', 'mae'])\n",
    "    # csv_df_stats.to_csv(f'{csv_name[:-4]}_stats.csv',mode='a',index='resample')\n",
    "    \n",
    "    return csv_df_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 613,
   "id": "70566b17-5fce-4a98-9b0b-66668c72452e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['RF-Score', 'CountDNAp', 'H-Bonding']"
      ]
     },
     "execution_count": 613,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "desc_type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 619,
   "id": "71959f56-0325-48d0-9a6f-00cacdffe5ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns=['Model_name','Descriptor', 'Property','Units','Set_type',\n",
    "                                          'r2','r2_std', \n",
    "                                          'rmsd','rmsd_std', \n",
    "                                          'bias','bias_std',\n",
    "                                         'sdep','sdep_std',\n",
    "                                          'a','a_std',\n",
    "                                          'b','b_std',\n",
    "                                          'mse','mse_std',\n",
    "                                          'mae' ,'mae_std']\n",
    "set_type='test'\n",
    "df_stats_comparison=pd.DataFrame()\n",
    "for desc in desc_type:\n",
    "    for prop in GSHT_list:\n",
    "        units='N'\n",
    "        # model_name = f\"1DConv_st_{prop}\" \n",
    "        model_name = \"KNN\" \n",
    "        stats_stack=pd.DataFrame()\n",
    "        csv_stacks=pd.DataFrame()\n",
    "        # df_stats_comparison=pd.DataFrame()\n",
    "        for resample in range(1,51):\n",
    "            directory_path = Path(f\"{path_sk}/{resample}/{model_name}/{desc}/{prop}\")\n",
    "            csv_name=f'{directory_path}/Split_{resample}_type_test_pipe_cond_No_scalling.csv'\n",
    "            \n",
    "            csv_df=plots_sk(csv_name)\n",
    "        \n",
    "            csv_df_stats = stats_csv_sk(csv_df['y_true'],csv_df['y_pred'],resample)\n",
    "            \n",
    "            stats_stack=pd.concat([stats_stack,csv_df_stats],\n",
    "                                    axis=0)\n",
    "            csv_stacks=pd.concat([csv_stacks,csv_df],\n",
    "                                    axis=1)\n",
    "            result = pd.concat([csv_stacks, csv_df], axis=1, join='outer')\n",
    "        result\n",
    "        # csv_name\n",
    "        stats_stack\n",
    "        # calculate stats for each resample\n",
    "        stats_stack_summary=stats_stack.reset_index(drop=True).rename(columns={\"index\":\"resample\"}).describe()\n",
    "        mean_y_pred = csv_stacks.filter(like='y_pred').mean(axis=1)\n",
    "        mean_y_pred\n",
    "        std_y_pred = csv_stacks.filter(like='y_pred').std(axis=1)\n",
    "        std_y_pred\n",
    "        mean_y_true = csv_stacks.filter(like='y_true').mean(axis=1)\n",
    "        mean_y_true\n",
    "        # plot_err(stats_stack,csv_stacks,model_name,prop,desc,set_type)\n",
    "        # plot_err(stats_stack,csv_stacks,model_name,prop,desc,'test')\n",
    "        \n",
    "        stats_describe=stats_stack.describe()  \n",
    "        # Average results over resamples:\n",
    "        r2 = '{:.3f}'.format(stats_describe['r2']['mean'])\n",
    "        rmsd = '{:.3f}'.format(stats_describe['rmsd']['mean'])\n",
    "        bias = '{:.3f}'.format(stats_describe['bias']['mean'])\n",
    "        sdep = '{:.3f}'.format(stats_describe['sdep']['mean'])\n",
    "        a = '{:.3f}'.format(stats_describe['plot_a']['mean'])\n",
    "        b = '{:.3f}'.format(stats_describe['plot_b']['mean'])\n",
    "        mse = '{:.3f}'.format(stats_describe['mse']['mean'])\n",
    "        mae = '{:.3f}'.format(stats_describe['mae']['mean'])\n",
    "        # Sample Standard deviation results over resamples\n",
    "        r2_sd = '{:.3f}'.format(stats_describe['r2']['std'])\n",
    "        rmsd_sd = '{:.3f}'.format(stats_describe['rmsd']['std'])\n",
    "        bias_sd = '{:.3f}'.format(stats_describe['bias']['std'])\n",
    "        sdep_sd = '{:.3f}'.format(stats_describe['sdep']['std'])\n",
    "        a_sd = '{:.3f}'.format(stats_describe['plot_a']['std'])\n",
    "        b_sd = '{:.3f}'.format(stats_describe['plot_b']['std'])\n",
    "        mse_sd = '{:.3f}'.format(stats_describe['mse']['std'])\n",
    "        mae_sd = '{:.3f}'.format(stats_describe['mae']['std'])\n",
    "        \n",
    "        # df_stats_comparison = \n",
    "        # f'SDEP : {sdep} $\\pm$ {sdep_sd} '\n",
    "        plot_err(stats_stack,csv_stacks,model_name,prop,desc,set_type)\n",
    "        new_row_values = [model_name,desc,prop,units,set_type,r2,r2_sd,rmsd,rmsd_sd,bias,bias_sd,sdep,sdep_sd,a,a_sd,b,b_sd,mse,mse_sd,mae,mae_sd]\n",
    "        df_stats_comparison = pd.concat([df_stats_comparison,pd.DataFrame(new_row_values, index=columns).T])\n",
    "# df_stats_comparison.to_csv(f'{model_name}__rf_score_h_bonding_cound_all.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 616,
   "id": "2eec8367-876b-4b60-88e5-892a6b23e691",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>y_true</th>\n",
       "      <th>y_pred</th>\n",
       "      <th>y_true</th>\n",
       "      <th>y_pred</th>\n",
       "      <th>y_true</th>\n",
       "      <th>y_pred</th>\n",
       "      <th>y_true</th>\n",
       "      <th>y_pred</th>\n",
       "      <th>y_true</th>\n",
       "      <th>y_pred</th>\n",
       "      <th>...</th>\n",
       "      <th>y_true</th>\n",
       "      <th>y_pred</th>\n",
       "      <th>y_true</th>\n",
       "      <th>y_pred</th>\n",
       "      <th>y_true</th>\n",
       "      <th>y_pred</th>\n",
       "      <th>y_true</th>\n",
       "      <th>y_pred</th>\n",
       "      <th>y_true</th>\n",
       "      <th>y_pred</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>207</th>\n",
       "      <td>35.3</td>\n",
       "      <td>28.762505</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>35.3</td>\n",
       "      <td>28.762505</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>35.3</td>\n",
       "      <td>38.015655</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>191</th>\n",
       "      <td>48.9</td>\n",
       "      <td>47.578420</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>48.9</td>\n",
       "      <td>49.998796</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>222</th>\n",
       "      <td>46.4</td>\n",
       "      <td>42.276667</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>46.4</td>\n",
       "      <td>44.033743</td>\n",
       "      <td>46.4</td>\n",
       "      <td>44.735579</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>46.4</td>\n",
       "      <td>43.642171</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>177</th>\n",
       "      <td>77.8</td>\n",
       "      <td>70.349467</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>77.8</td>\n",
       "      <td>70.989219</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>77.8</td>\n",
       "      <td>69.009762</td>\n",
       "      <td>77.8</td>\n",
       "      <td>69.870013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>260</th>\n",
       "      <td>66.3</td>\n",
       "      <td>67.904085</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>66.3</td>\n",
       "      <td>66.863751</td>\n",
       "      <td>66.3</td>\n",
       "      <td>67.381925</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>213</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>51.8</td>\n",
       "      <td>49.092459</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>31.7</td>\n",
       "      <td>27.201166</td>\n",
       "      <td>31.7</td>\n",
       "      <td>28.362207</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>296</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>35.4</td>\n",
       "      <td>35.228701</td>\n",
       "      <td>35.4</td>\n",
       "      <td>35.888716</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>218</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>65.6</td>\n",
       "      <td>68.455016</td>\n",
       "      <td>65.6</td>\n",
       "      <td>67.569909</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>33.9</td>\n",
       "      <td>28.366068</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>33.9</td>\n",
       "      <td>34.809368</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>305 rows × 100 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     y_true     y_pred  y_true  y_pred  y_true     y_pred  y_true     y_pred  \\\n",
       "ID                                                                             \n",
       "207    35.3  28.762505     NaN     NaN    35.3  28.762505     NaN        NaN   \n",
       "191    48.9  47.578420     NaN     NaN     NaN        NaN     NaN        NaN   \n",
       "222    46.4  42.276667     NaN     NaN     NaN        NaN    46.4  44.033743   \n",
       "177    77.8  70.349467     NaN     NaN     NaN        NaN    77.8  70.989219   \n",
       "260    66.3  67.904085     NaN     NaN     NaN        NaN     NaN        NaN   \n",
       "..      ...        ...     ...     ...     ...        ...     ...        ...   \n",
       "213     NaN        NaN     NaN     NaN     NaN        NaN     NaN        NaN   \n",
       "76      NaN        NaN     NaN     NaN     NaN        NaN     NaN        NaN   \n",
       "296     NaN        NaN     NaN     NaN     NaN        NaN     NaN        NaN   \n",
       "218     NaN        NaN     NaN     NaN     NaN        NaN     NaN        NaN   \n",
       "92      NaN        NaN     NaN     NaN     NaN        NaN     NaN        NaN   \n",
       "\n",
       "     y_true     y_pred  ...  y_true     y_pred  y_true     y_pred  y_true  \\\n",
       "ID                      ...                                                 \n",
       "207    35.3  38.015655  ...     NaN        NaN     NaN        NaN     NaN   \n",
       "191    48.9  49.998796  ...     NaN        NaN     NaN        NaN     NaN   \n",
       "222    46.4  44.735579  ...     NaN        NaN     NaN        NaN     NaN   \n",
       "177     NaN        NaN  ...     NaN        NaN     NaN        NaN     NaN   \n",
       "260     NaN        NaN  ...     NaN        NaN    66.3  66.863751    66.3   \n",
       "..      ...        ...  ...     ...        ...     ...        ...     ...   \n",
       "213     NaN        NaN  ...     NaN        NaN     NaN        NaN     NaN   \n",
       "76      NaN        NaN  ...     NaN        NaN     NaN        NaN    31.7   \n",
       "296     NaN        NaN  ...     NaN        NaN     NaN        NaN     NaN   \n",
       "218     NaN        NaN  ...    65.6  68.455016    65.6  67.569909     NaN   \n",
       "92      NaN        NaN  ...     NaN        NaN    33.9  28.366068     NaN   \n",
       "\n",
       "        y_pred  y_true     y_pred  y_true     y_pred  \n",
       "ID                                                    \n",
       "207        NaN     NaN        NaN     NaN        NaN  \n",
       "191        NaN     NaN        NaN     NaN        NaN  \n",
       "222        NaN     NaN        NaN    46.4  43.642171  \n",
       "177        NaN    77.8  69.009762    77.8  69.870013  \n",
       "260  67.381925     NaN        NaN     NaN        NaN  \n",
       "..         ...     ...        ...     ...        ...  \n",
       "213        NaN     NaN        NaN    51.8  49.092459  \n",
       "76   27.201166    31.7  28.362207     NaN        NaN  \n",
       "296        NaN    35.4  35.228701    35.4  35.888716  \n",
       "218        NaN     NaN        NaN     NaN        NaN  \n",
       "92         NaN     NaN        NaN    33.9  34.809368  \n",
       "\n",
       "[305 rows x 100 columns]"
      ]
     },
     "execution_count": 616,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(mean_y_pred,mean_y_true)\n",
    "csv_stacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 593,
   "id": "080c2898-1b9a-48e4-8860-edd4e13883f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['OHEP_28_pos_7_T', 'OHEP_29_pos_8_A', 'OHEP_30_pos_8_C',\n",
       "       'OHEP_31_pos_8_G', 'OHEP_32_pos_8_T', 'OHEP_33_pos_9_A',\n",
       "       'OHEP_34_pos_9_C', 'OHEP_35_pos_9_G', 'OHEP_36_pos_9_T',\n",
       "       'OHEP_37_pos_10_A', 'OHEP_38_pos_10_C', 'OHEP_39_pos_10_G',\n",
       "       'OHEP_40_pos_10_T', 'OHEP_41_pos_11_A', 'OHEP_42_pos_11_C',\n",
       "       'OHEP_43_pos_11_G', 'OHEP_44_pos_11_T', 'OHEP_45_pos_12_A',\n",
       "       'OHEP_46_pos_12_C', 'OHEP_47_pos_12_G', 'OHEP_48_pos_12_T',\n",
       "       'OHEP_49_pos_13_A', 'OHEP_50_pos_13_C', 'OHEP_51_pos_13_G',\n",
       "       'OHEP_52_pos_13_T', 'OHEP_53_pos_14_A', 'OHEP_54_pos_14_C',\n",
       "       'OHEP_55_pos_14_G', 'OHEP_56_pos_14_T', 'OHEP_57_pos_15_A',\n",
       "       'OHEP_58_pos_15_C', 'OHEP_59_pos_15_G', 'OHEP_60_pos_15_T',\n",
       "       'OHEP_61_pos_16_A', 'OHEP_62_pos_16_C', 'OHEP_63_pos_16_G',\n",
       "       'OHEP_64_pos_16_T', 'OHEP_65_pos_17_A', 'OHEP_66_pos_17_C',\n",
       "       'OHEP_67_pos_17_G', 'OHEP_68_pos_17_T', 'OHEP_69_pos_18_A',\n",
       "       'OHEP_70_pos_18_C', 'OHEP_71_pos_18_G', 'OHEP_72_pos_18_T',\n",
       "       'OHEP_73_pos_19_A', 'OHEP_74_pos_19_C', 'OHEP_75_pos_19_G',\n",
       "       'OHEP_76_pos_19_T', 'OHEP_77_pos_20_A', 'OHEP_78_pos_20_C',\n",
       "       'OHEP_79_pos_20_G', 'OHEP_80_pos_20_T', 'LP_dec2_pos_1',\n",
       "       'LP_dec2_pos_2', 'LP_dec2_pos_3', 'LP_dec2_pos_4', 'LP_dec2_pos_5',\n",
       "       'LP_dec2_pos_6', 'LP_dec2_pos_7', 'LP_dec2_pos_8', 'LP_dec2_pos_9',\n",
       "       'LP_dec2_pos_10', 'LP_dec2_pos_11', 'LP_dec2_pos_12', 'LP_dec2_pos_13',\n",
       "       'LP_dec2_pos_14', 'LP_dec2_pos_15', 'LP_dec2_pos_16', 'LP_dec2_pos_17',\n",
       "       'LP_dec2_pos_18', 'LP_dec2_pos_19', 'LP_dec2_pos_20', 'CountDNA_pos_A',\n",
       "       'CountDNA_pos_G', 'CountDNA_pos_C', 'CountDNA_pos_T',\n",
       "       'CountDNA_pos_Tot', 'CountDNAp_pos_A', 'CountDNAp_pos_G',\n",
       "       'CountDNAp_pos_C', 'CountDNAp_pos_T', 'CountDNAp_pos_Tot'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 593,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file.columns[300:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 567,
   "id": "e6a11bde-dbcc-4525-97fd-df1baac5f284",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>resample</th>\n",
       "      <th>r2</th>\n",
       "      <th>rmsd</th>\n",
       "      <th>bias</th>\n",
       "      <th>sdep</th>\n",
       "      <th>plot_a</th>\n",
       "      <th>plot_b</th>\n",
       "      <th>mse</th>\n",
       "      <th>mae</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>50.00000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>50.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>25.50000</td>\n",
       "      <td>0.879926</td>\n",
       "      <td>4.209823</td>\n",
       "      <td>-0.534454</td>\n",
       "      <td>4.148665</td>\n",
       "      <td>1.030948</td>\n",
       "      <td>-1.834564</td>\n",
       "      <td>18.057828</td>\n",
       "      <td>2.934574</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>14.57738</td>\n",
       "      <td>0.036346</td>\n",
       "      <td>0.584857</td>\n",
       "      <td>0.499431</td>\n",
       "      <td>0.568133</td>\n",
       "      <td>0.045784</td>\n",
       "      <td>2.075104</td>\n",
       "      <td>5.051730</td>\n",
       "      <td>0.351115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.779190</td>\n",
       "      <td>2.987493</td>\n",
       "      <td>-1.728595</td>\n",
       "      <td>2.965893</td>\n",
       "      <td>0.883948</td>\n",
       "      <td>-6.488141</td>\n",
       "      <td>8.925112</td>\n",
       "      <td>2.246179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>13.25000</td>\n",
       "      <td>0.861198</td>\n",
       "      <td>3.845186</td>\n",
       "      <td>-0.865549</td>\n",
       "      <td>3.809099</td>\n",
       "      <td>1.002471</td>\n",
       "      <td>-2.989852</td>\n",
       "      <td>14.785460</td>\n",
       "      <td>2.738471</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>25.50000</td>\n",
       "      <td>0.886745</td>\n",
       "      <td>4.199823</td>\n",
       "      <td>-0.555774</td>\n",
       "      <td>4.137579</td>\n",
       "      <td>1.029416</td>\n",
       "      <td>-1.804703</td>\n",
       "      <td>17.638538</td>\n",
       "      <td>2.952223</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>37.75000</td>\n",
       "      <td>0.904206</td>\n",
       "      <td>4.500979</td>\n",
       "      <td>-0.186846</td>\n",
       "      <td>4.454812</td>\n",
       "      <td>1.056984</td>\n",
       "      <td>-0.269687</td>\n",
       "      <td>20.259160</td>\n",
       "      <td>3.083044</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>50.00000</td>\n",
       "      <td>0.935251</td>\n",
       "      <td>5.712470</td>\n",
       "      <td>0.413563</td>\n",
       "      <td>5.591227</td>\n",
       "      <td>1.124582</td>\n",
       "      <td>4.635767</td>\n",
       "      <td>32.632309</td>\n",
       "      <td>3.896518</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       resample         r2       rmsd       bias       sdep     plot_a  \\\n",
       "count  50.00000  50.000000  50.000000  50.000000  50.000000  50.000000   \n",
       "mean   25.50000   0.879926   4.209823  -0.534454   4.148665   1.030948   \n",
       "std    14.57738   0.036346   0.584857   0.499431   0.568133   0.045784   \n",
       "min     1.00000   0.779190   2.987493  -1.728595   2.965893   0.883948   \n",
       "25%    13.25000   0.861198   3.845186  -0.865549   3.809099   1.002471   \n",
       "50%    25.50000   0.886745   4.199823  -0.555774   4.137579   1.029416   \n",
       "75%    37.75000   0.904206   4.500979  -0.186846   4.454812   1.056984   \n",
       "max    50.00000   0.935251   5.712470   0.413563   5.591227   1.124582   \n",
       "\n",
       "          plot_b        mse        mae  \n",
       "count  50.000000  50.000000  50.000000  \n",
       "mean   -1.834564  18.057828   2.934574  \n",
       "std     2.075104   5.051730   0.351115  \n",
       "min    -6.488141   8.925112   2.246179  \n",
       "25%    -2.989852  14.785460   2.738471  \n",
       "50%    -1.804703  17.638538   2.952223  \n",
       "75%    -0.269687  20.259160   3.083044  \n",
       "max     4.635767  32.632309   3.896518  "
      ]
     },
     "execution_count": 567,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stats_stack.reset_index(drop=True).rename(columns={\"index\":\"resample\"}).describe()\n",
    "# stats_stack."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5c876bc-bbc4-4280-86de-7d7cbfbd1219",
   "metadata": {},
   "outputs": [],
   "source": [
    "for desc in desc_type:\n",
    "    for prop in GSHT_list:\n",
    "        units='N'\n",
    "        model_name = f\"1DConv_st_{prop}\" \n",
    "        for set_type in set_types:\n",
    "            stats_stack=pd.DataFrame()\n",
    "            csv_stacks=pd.DataFrame()\n",
    "            for resample in range(50):\n",
    "                try:\n",
    "                    directory_path = Path(f\"{os.getcwd()}/CV/{resample}/{desc}/{model_name}/\")\n",
    "                    csv_name=f'{directory_path}/{set_type}.csv'\n",
    "                    csv_df_stats,csv_df=plots(csv_name)\n",
    "                    stats_stack=pd.concat([stats_stack,csv_df_stats],\n",
    "                                            axis=0)\n",
    "                    csv_stacks=pd.concat([csv_stacks,csv_df],\n",
    "                                            axis=1)\n",
    "                    result = pd.concat([csv_stacks, csv_df], axis=1, join='outer')\n",
    "                except:\n",
    "                    print(resample)\n",
    "                    pass\n",
    "            stats_describe=stats_stack.describe() "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38b06066-cd94-4837-8d7f-fe27465ab4ad",
   "metadata": {},
   "source": [
    "### DEV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 431,
   "id": "4312376a-0df7-4183-9097-c0d7d68fd13a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>y_true</th>\n",
       "      <th>y_pred</th>\n",
       "      <th>index</th>\n",
       "      <th>y_true</th>\n",
       "      <th>y_pred</th>\n",
       "      <th>index</th>\n",
       "      <th>y_true</th>\n",
       "      <th>y_pred</th>\n",
       "      <th>index</th>\n",
       "      <th>y_true</th>\n",
       "      <th>y_pred</th>\n",
       "      <th>index</th>\n",
       "      <th>y_true</th>\n",
       "      <th>y_pred</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-46.3</td>\n",
       "      <td>-59.446934</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-46.3</td>\n",
       "      <td>-60.083447</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-46.3</td>\n",
       "      <td>-58.675243</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>4.0</td>\n",
       "      <td>-55.4</td>\n",
       "      <td>-58.704082</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>-55.4</td>\n",
       "      <td>-58.623340</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>5.0</td>\n",
       "      <td>-54.6</td>\n",
       "      <td>-57.756733</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.0</td>\n",
       "      <td>-54.6</td>\n",
       "      <td>-59.40774</td>\n",
       "      <td>5.0</td>\n",
       "      <td>-54.6</td>\n",
       "      <td>-57.0334</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>9.0</td>\n",
       "      <td>-50.2</td>\n",
       "      <td>-50.036663</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>11.0</td>\n",
       "      <td>-89.9</td>\n",
       "      <td>-91.014854</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11.0</td>\n",
       "      <td>-89.9</td>\n",
       "      <td>-90.46723</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11.0</td>\n",
       "      <td>-89.9</td>\n",
       "      <td>-85.998830</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>246</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>245.0</td>\n",
       "      <td>-57.7</td>\n",
       "      <td>-60.730410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>255</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>254.0</td>\n",
       "      <td>-32.7</td>\n",
       "      <td>-46.057510</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>267</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>266.0</td>\n",
       "      <td>-128.0</td>\n",
       "      <td>-117.075226</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>269</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>268.0</td>\n",
       "      <td>-120.4</td>\n",
       "      <td>-121.062490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>300</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>299.0</td>\n",
       "      <td>-56.5</td>\n",
       "      <td>-57.969982</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>244 rows × 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     index  y_true     y_pred  index  y_true     y_pred  index  y_true  \\\n",
       "ID                                                                       \n",
       "1      0.0   -46.3 -59.446934    0.0   -46.3 -60.083447    NaN     NaN   \n",
       "5      4.0   -55.4 -58.704082    NaN     NaN        NaN    NaN     NaN   \n",
       "6      5.0   -54.6 -57.756733    NaN     NaN        NaN    5.0   -54.6   \n",
       "10     9.0   -50.2 -50.036663    NaN     NaN        NaN    NaN     NaN   \n",
       "12    11.0   -89.9 -91.014854    NaN     NaN        NaN   11.0   -89.9   \n",
       "..     ...     ...        ...    ...     ...        ...    ...     ...   \n",
       "246    NaN     NaN        NaN    NaN     NaN        NaN    NaN     NaN   \n",
       "255    NaN     NaN        NaN    NaN     NaN        NaN    NaN     NaN   \n",
       "267    NaN     NaN        NaN    NaN     NaN        NaN    NaN     NaN   \n",
       "269    NaN     NaN        NaN    NaN     NaN        NaN    NaN     NaN   \n",
       "300    NaN     NaN        NaN    NaN     NaN        NaN    NaN     NaN   \n",
       "\n",
       "       y_pred  index  y_true   y_pred  index  y_true      y_pred  \n",
       "ID                                                                \n",
       "1         NaN    NaN     NaN      NaN    0.0   -46.3  -58.675243  \n",
       "5         NaN    NaN     NaN      NaN    4.0   -55.4  -58.623340  \n",
       "6   -59.40774    5.0   -54.6 -57.0334    NaN     NaN         NaN  \n",
       "10        NaN    NaN     NaN      NaN    NaN     NaN         NaN  \n",
       "12  -90.46723    NaN     NaN      NaN   11.0   -89.9  -85.998830  \n",
       "..        ...    ...     ...      ...    ...     ...         ...  \n",
       "246       NaN    NaN     NaN      NaN  245.0   -57.7  -60.730410  \n",
       "255       NaN    NaN     NaN      NaN  254.0   -32.7  -46.057510  \n",
       "267       NaN    NaN     NaN      NaN  266.0  -128.0 -117.075226  \n",
       "269       NaN    NaN     NaN      NaN  268.0  -120.4 -121.062490  \n",
       "300       NaN    NaN     NaN      NaN  299.0   -56.5  -57.969982  \n",
       "\n",
       "[244 rows x 15 columns]"
      ]
     },
     "execution_count": 431,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "    \n",
    "def plots(csv_name):\n",
    "\n",
    "    csv_df_stats=pd.read_csv(f'{csv_name[:-4]}_stats.csv')\n",
    "    csv_df=pd.read_csv(f'{csv_name[:-4]}.csv',index_col='ID')\n",
    "    return csv_df_stats,csv_df\n",
    "\n",
    "directory_path = Path(f\"{os.getcwd()}/CV/{resample}/{desc}/{model_name}/\")\n",
    "\n",
    "set_types = ['train','val','test']\n",
    "set_type = 'test'\n",
    "\n",
    "stats_stack=pd.DataFrame()\n",
    "csv_stacks=pd.DataFrame()\n",
    "for resample in range(5):\n",
    "    directory_path = Path(f\"{os.getcwd()}/CV/{resample}/{desc}/{model_name}/\")\n",
    "    csv_name=f'{directory_path}/{set_type}.csv'\n",
    "    csv_df_stats,csv_df=plots(csv_name)\n",
    "    stats_stack=pd.concat([stats_stack,csv_df_stats],\n",
    "                            axis=0)\n",
    "    csv_stacks=pd.concat([csv_stacks,csv_df],\n",
    "                            axis=1)\n",
    "    result = pd.concat([csv_stacks, csv_df], axis=1, join='outer')\n",
    "    \n",
    "stats_stack\n",
    "csv_stacks\n",
    "result\n",
    "csv_stacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 435,
   "id": "20fbd63b-8bd2-4d5e-9ab1-d103221482b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ID\n",
       "1      -46.3\n",
       "5      -55.4\n",
       "6      -54.6\n",
       "10     -50.2\n",
       "12     -89.9\n",
       "       ...  \n",
       "246    -57.7\n",
       "255    -32.7\n",
       "267   -128.0\n",
       "269   -120.4\n",
       "300    -56.5\n",
       "Length: 244, dtype: float64"
      ]
     },
     "execution_count": 435,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_y_pred = csv_stacks.filter(like='y_pred').mean(axis=1)\n",
    "mean_y_pred\n",
    "std_y_pred = csv_stacks.filter(like='y_pred').std(axis=1)\n",
    "std_y_pred\n",
    "mean_y_true = csv_stacks.filter(like='y_true').mean(axis=1)\n",
    "mean_y_true"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 427,
   "id": "dcef1ee7-cf11-4286-b882-3b8f105a4ab4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>resample</th>\n",
       "      <th>r2</th>\n",
       "      <th>rmsd</th>\n",
       "      <th>bias</th>\n",
       "      <th>sdep</th>\n",
       "      <th>plot_a</th>\n",
       "      <th>plot_b</th>\n",
       "      <th>mse</th>\n",
       "      <th>mae</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>5.0</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.0</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.946600</td>\n",
       "      <td>5.042200</td>\n",
       "      <td>0.200400</td>\n",
       "      <td>30.152400</td>\n",
       "      <td>0.917800</td>\n",
       "      <td>-5.402000</td>\n",
       "      <td>25.617400</td>\n",
       "      <td>3.841000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.581139</td>\n",
       "      <td>0.010991</td>\n",
       "      <td>0.491465</td>\n",
       "      <td>0.755824</td>\n",
       "      <td>1.228012</td>\n",
       "      <td>0.026013</td>\n",
       "      <td>2.476529</td>\n",
       "      <td>4.986507</td>\n",
       "      <td>0.316068</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.936000</td>\n",
       "      <td>4.549000</td>\n",
       "      <td>-1.039000</td>\n",
       "      <td>28.644000</td>\n",
       "      <td>0.881000</td>\n",
       "      <td>-9.327000</td>\n",
       "      <td>20.692000</td>\n",
       "      <td>3.402000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.940000</td>\n",
       "      <td>4.553000</td>\n",
       "      <td>0.074000</td>\n",
       "      <td>29.429000</td>\n",
       "      <td>0.901000</td>\n",
       "      <td>-6.298000</td>\n",
       "      <td>20.731000</td>\n",
       "      <td>3.772000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.0</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.940000</td>\n",
       "      <td>5.196000</td>\n",
       "      <td>0.450000</td>\n",
       "      <td>29.916000</td>\n",
       "      <td>0.928000</td>\n",
       "      <td>-4.311000</td>\n",
       "      <td>26.998000</td>\n",
       "      <td>3.806000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.0</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.958000</td>\n",
       "      <td>5.215000</td>\n",
       "      <td>0.604000</td>\n",
       "      <td>31.130000</td>\n",
       "      <td>0.936000</td>\n",
       "      <td>-3.835000</td>\n",
       "      <td>27.199000</td>\n",
       "      <td>3.949000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>0.0</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>0.959000</td>\n",
       "      <td>5.698000</td>\n",
       "      <td>0.913000</td>\n",
       "      <td>31.643000</td>\n",
       "      <td>0.943000</td>\n",
       "      <td>-3.239000</td>\n",
       "      <td>32.467000</td>\n",
       "      <td>4.276000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Unnamed: 0  resample        r2      rmsd      bias       sdep  \\\n",
       "count         5.0  5.000000  5.000000  5.000000  5.000000   5.000000   \n",
       "mean          0.0  2.000000  0.946600  5.042200  0.200400  30.152400   \n",
       "std           0.0  1.581139  0.010991  0.491465  0.755824   1.228012   \n",
       "min           0.0  0.000000  0.936000  4.549000 -1.039000  28.644000   \n",
       "25%           0.0  1.000000  0.940000  4.553000  0.074000  29.429000   \n",
       "50%           0.0  2.000000  0.940000  5.196000  0.450000  29.916000   \n",
       "75%           0.0  3.000000  0.958000  5.215000  0.604000  31.130000   \n",
       "max           0.0  4.000000  0.959000  5.698000  0.913000  31.643000   \n",
       "\n",
       "         plot_a    plot_b        mse       mae  \n",
       "count  5.000000  5.000000   5.000000  5.000000  \n",
       "mean   0.917800 -5.402000  25.617400  3.841000  \n",
       "std    0.026013  2.476529   4.986507  0.316068  \n",
       "min    0.881000 -9.327000  20.692000  3.402000  \n",
       "25%    0.901000 -6.298000  20.731000  3.772000  \n",
       "50%    0.928000 -4.311000  26.998000  3.806000  \n",
       "75%    0.936000 -3.835000  27.199000  3.949000  \n",
       "max    0.943000 -3.239000  32.467000  4.276000  "
      ]
     },
     "execution_count": 427,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stats_stack.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82cc07c7-ff1b-4470-816e-ffe62ae685af",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 439,
   "id": "de891b46-4bbb-4f10-ae51-537bf8b6f34c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-148.30499999999998, -22.574778619306567)"
      ]
     },
     "execution_count": 439,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots()   \n",
    "\n",
    "plt.scatter(mean_y_true,mean_y_pred)\n",
    "plt.errorbar(mean_y_true, mean_y_pred, yerr=std_y_pred, fmt='none',ecolor='black',elinewidth=0.8,capsize=2,\n",
    "                    barsabove=False)\n",
    "\n",
    "lims = [\n",
    "            np.min([ax.get_xlim(), ax.get_ylim()]),  # min of both axes\n",
    "            np.max([ax.get_xlim(), ax.get_ylim()]),  # max of both axes\n",
    "           ]\n",
    "ax.plot(lims, lims, 'k--', alpha=0.75, zorder=0)\n",
    "ax.set_aspect('equal')\n",
    "ax.set_xlim(lims)\n",
    "ax.set_ylim(lims)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 443,
   "id": "53770dca-67d7-42a9-a84c-696b643f1981",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9466000000000001"
      ]
     },
     "execution_count": 443,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stats_describe=stats_stack.describe()#['r2']['mean']\n",
    "stats_describe['r2']['mean']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "id": "16431e67-d3aa-4e22-b558-57e743a1cd30",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x15009ebe2df0>"
      ]
     },
     "execution_count": 314,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "plt.scatter(csv_df_train['y_true'], csv_df_train['y_pred'],alpha=0.5)\n",
    "plt.scatter(csv_df_val['y_true'], csv_df_val['y_pred'])\n",
    "plt.scatter(csv_df['y_true'], csv_df['y_pred'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 455,
   "id": "08533d90-474c-4215-87e6-58ce93e6b879",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_err(stats_stack,csv_stacks,model_name,prop,desc,set_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 454,
   "id": "3921ed22-6f41-45ed-89ca-efe606990b59",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_err(stats_stack,csv_stacks,model_name,prop,desc,set_type):\n",
    "    \n",
    "    model_name\n",
    "    if prop == 'Tm':\n",
    "        name = 'T'\n",
    "    elif prop == 'dS':\n",
    "        name = 'S'\n",
    "    elif prop == 'dH':\n",
    "        name = 'H'\n",
    "    else:\n",
    "        name = 'G'\n",
    "    # name = prop\n",
    "    descriptor_name = desc\n",
    "    set_name=set_type\n",
    "# Compute mean and std in pred, access true value, compute mean and std in stats\n",
    "    y_pred_test = csv_stacks.filter(like='y_pred').mean(axis=1)\n",
    "    yerr = csv_stacks.filter(like='y_pred').std(axis=1)\n",
    "    y_test = csv_stacks.filter(like='y_true').mean(axis=1)\n",
    "    stats_describe=stats_stack.describe()  \n",
    "    \n",
    "#     Load list\n",
    "\n",
    "    # Average results over resamples:\n",
    "    r2 = '{:.3f}'.format(stats_describe['r2']['mean'])\n",
    "    rmsd = '{:.3f}'.format(stats_describe['rmsd']['mean'])\n",
    "    bias = '{:.3f}'.format(stats_describe['bias']['mean'])\n",
    "    sdep = '{:.3f}'.format(stats_describe['sdep']['mean'])\n",
    "    # Sample Standard deviation results over resamples\n",
    "    r2_sd = '{:.3f}'.format(stats_describe['r2']['std'])\n",
    "    rmsd_sd = '{:.3f}'.format(stats_describe['rmsd']['std'])\n",
    "    bias_sd = '{:.3f}'.format(stats_describe['bias']['std'])\n",
    "    sdep_sd = '{:.3f}'.format(stats_describe['sdep']['std'])\n",
    "\n",
    "\n",
    "    fig, ax = plt.subplots()   \n",
    "\n",
    "     # Line of best fit\n",
    "    try:\n",
    "        a, b = np.polyfit(y_test, y_pred_test, 1)\n",
    "        plot_a = '{:.3f}'.format(a)\n",
    "        plot_b = '{:.3f}'.format(b)\n",
    "    except np.linalg.LinAlgError:\n",
    "        pass\n",
    "\n",
    "    # Plot everything\n",
    "    try:\n",
    "#         Tab tittle\n",
    "        if name=='T':\n",
    "            plt.title(f'{model_name} | ${name}_m$ | {descriptor_name} | {set_name} set')\n",
    "            plt.plot([], [], ' ', label=f'{model_name} | ${name}_m$ | {set_name} set')\n",
    "        elif name=='S':\n",
    "            plt.title(f'{model_name} | Δ{name} | {descriptor_name} | {set_name} set')\n",
    "            plt.plot([], [], ' ', label=f'{model_name} | Δ{name} | {set_name} set')\n",
    "        else:\n",
    "            plt.title(f'{model_name} | Δ{name} | {descriptor_name} | {set_name} set')\n",
    "            plt.plot([], [], ' ', label=f'{model_name} | Δ{name} | {set_name} set')\n",
    "\n",
    "#         Stats\n",
    "        plt.plot([], [], ' ', label=f'$R^{2}$ : {r2} $\\pm$ {r2_sd} ')\n",
    "        plt.plot([], [], ' ', label=f'RMSD : {rmsd} $\\pm$ {rmsd_sd} ')\n",
    "        plt.plot([], [], ' ', label=f'Bias : {bias} $\\pm$ {bias_sd} ')\n",
    "        plt.plot([], [], ' ', label=f'SDEP : {sdep} $\\pm$ {sdep_sd} ')\n",
    "#         provide information about the gradient\n",
    "        plt.plot([], [], ' ', label=f'y = {plot_a}x + {plot_b}')       \n",
    "#         plot scatter plot\n",
    "        plt.scatter(y_test, y_pred_test)\n",
    "#         Plot error bars\n",
    "        plt.errorbar(y_test, y_pred_test, yerr=yerr, fmt='none',ecolor='black',elinewidth=0.8,capsize=2,\n",
    "                    barsabove=False)\n",
    "#     plot line of best fit\n",
    "        plt.plot(y_test, a * y_test + b, color='purple')\n",
    "        order = [0,1,2,3,4,5]\n",
    "    except NameError:\n",
    "        pass\n",
    "\n",
    "    # x=y line\n",
    "    lims = [\n",
    "            np.min([ax.get_xlim(), ax.get_ylim()]),  # min of both axes\n",
    "            np.max([ax.get_xlim(), ax.get_ylim()]),  # max of both axes\n",
    "           ]\n",
    "    ax.plot(lims, lims, 'k--', alpha=0.75, zorder=0)\n",
    "    ax.set_aspect('equal')\n",
    "    ax.set_xlim(lims)\n",
    "    ax.set_ylim(lims)\n",
    "\n",
    "    # Legend\n",
    "#     Axis labes\n",
    "    if name=='T':\n",
    "        plt.xlabel(f' ${name}_m$ True (°C)')\n",
    "        plt.ylabel(f' ${name}_m$ Pred (°C)')\n",
    "    elif name=='S':\n",
    "        plt.xlabel(f' Δ{name} True (cal/mol/K)')\n",
    "        plt.ylabel(f' Δ{name} Pred (cal/mol/K)')\n",
    "    else:\n",
    "        plt.xlabel(f' Δ{name} True (kcal/mol)')\n",
    "        plt.ylabel(f' Δ{name} Pred (kcal/mol)')\n",
    "#     legend labels\n",
    "    handles, labels = plt.gca().get_legend_handles_labels()\n",
    "    leg = plt.legend([handles[idx] for idx in order],[labels[idx] for idx in order])\n",
    "    leg.get_frame().set_linewidth(0.0)\n",
    "#     Most crucail -> file name! \n",
    "    fig.savefig(f'Resamples_mean_std_{model_name}_{set_name}_{name}_{descriptor_name}.png', bbox_inches='tight', dpi=800)\n",
    "#     clear and close fig\n",
    "    plt.clf()\n",
    "    plt.cla()\n",
    "    plt.close(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4921371c-1580-45e4-aff4-08e19ccca75f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8326753c-7f5c-4722-a9e6-7b1cf92a1ecd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "babc0126-10b7-4bc8-a09e-1973cbde0adb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c010d92-fc64-4583-87dc-cf9e89b32fb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot(trial_number,set_type):\n",
    "    test=os.getcwd()+f'/trial_predictions/trial_predictions_{trial_number}_{set_type}plot.csv'\n",
    "    df=pd.read_csv(test)\n",
    "    df2=df\n",
    "    y_test = df2[f'y_{string}']\n",
    "    y_pred_test = df2[f'y_{string}_pred']\n",
    "    y_test_np = y_test.to_numpy()\n",
    "    y_pred_test_np = y_pred_test.to_numpy()\n",
    "    r2_test = r2_score(y_test_np, y_pred_test_np)\n",
    "    rmsd_test = (mean_squared_error(y_test_np, y_pred_test_np))**0.5\n",
    "    bias_test = np.mean(y_pred_test_np - y_test_np)\n",
    "    sdep_test = (np.mean((y_pred_test_np - y_test_np - bias_test)**2))**0.5\n",
    "    r2_test = '{:.3f}'.format(r2_test)\n",
    "    rmsd_test = '{:.3f}'.format(rmsd_test)\n",
    "    bias_test = '{:.3f}'.format(bias_test)\n",
    "    sdep_test = '{:.3f}'.format(sdep_test)\n",
    "\n",
    "    fig, ax = plt.subplots()   \n",
    "\n",
    "    # Line of best fit\n",
    "    try:\n",
    "        a, b = np.polyfit(df2[f'y_{string}'], df2[f'y_{string}_pred'], 1)\n",
    "        plot_a = '{:.3f}'.format(a)\n",
    "        plot_b = '{:.3f}'.format(b)\n",
    "    except np.linalg.LinAlgError:\n",
    "        pass\n",
    "\n",
    "    # Plot everything\n",
    "    try:\n",
    "        plt.plot([], [], ' ', label=f'{set_type} set , trial {trial_number}'+f'{string}')\n",
    "        plt.plot([], [], ' ', label=f'$R^{2}$ : {r2_test}')\n",
    "        plt.plot([], [], ' ', label=f'RMSD : {rmsd_test}')\n",
    "        plt.plot([], [], ' ', label=f'Bias : {bias_test}')\n",
    "        plt.plot([], [], ' ', label=f'SDEP : {sdep_test}')\n",
    "        plt.plot([], [], ' ', label=f'y = {plot_a}x + {plot_b}')\n",
    "        plt.scatter(df2[f'y_{string}'], df2[f'y_{string}_pred'])\n",
    "        plt.plot(df2[f'y_{string}'], a * df2[f'y_{string}'] + b, color='purple')\n",
    "        order = [0,1,2,3,4,5]\n",
    "    except NameError:\n",
    "        pass\n",
    "\n",
    "    # x=y line\n",
    "    lims = [\n",
    "            np.min([ax.get_xlim(), ax.get_ylim()]),  # min of both axes\n",
    "            np.max([ax.get_xlim(), ax.get_ylim()]),  # max of both axes\n",
    "           ]\n",
    "    ax.plot(lims, lims, 'k--', alpha=0.75, zorder=0)\n",
    "    ax.set_aspect('equal')\n",
    "    ax.set_xlim(lims)\n",
    "    ax.set_ylim(lims)\n",
    "\n",
    "    # Legend\n",
    "    plt.xlabel('$ΔH^{exp}_{solv}$ (kcal/mol)')\n",
    "    plt.ylabel('$ΔH^{calc}_{solv}$ (kcal/mol)')\n",
    "    handles, labels = plt.gca().get_legend_handles_labels()\n",
    "    leg = plt.legend([handles[idx] for idx in order],[labels[idx] for idx in order])\n",
    "    leg.get_frame().set_linewidth(0.0)\n",
    "    fig.savefig(f'{os.getcwd()}/trial_predictions/{string}_trial_{trial_number}.png', bbox_inches='tight', dpi=1000)\n",
    "    plt.clf()\n",
    "    plt.cla()\n",
    "    plt.close(fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb97966d-d23f-4604-9cd0-90cdc24eda69",
   "metadata": {},
   "source": [
    "# Trouble shoot script template 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 351,
   "id": "cd7ba4d8-6d34-4c29-af35-227a0f6a3273",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code Execution \n",
    "\n",
    "df=pd.read_csv(\"Lomzov_dataset_IY.csv\")\n",
    "home=os.getcwd()\n",
    "# data Generation\n",
    "# cv_hp(df,home)\n",
    "\n",
    "# Actual instrucitons\n",
    "GSHT_list=['dH','dS','dG','Tm']\n",
    "resample=0\n",
    "fold=5\n",
    "desc='Granulated'\n",
    "prop = 'dH' \n",
    "model_name = f\"1DConv_st_dH\" \n",
    "epochs = 300\n",
    "batch  = 16\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 352,
   "id": "4ea0d5ec-e212-44e2-a22a-df8a41c195b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#  ANALYSIS SCRIPT \n",
    "from sklearn.metrics import r2_score, mean_squared_error, explained_variance_score\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "import sys\n",
    "\n",
    "def stats_hp(y_test_pred, Y_test, prop):\n",
    "    y_test_np = Y_test[f'{prop}'].to_numpy()\n",
    "    y_pred_test_np = y_test_pred\n",
    "\n",
    "    r2_test = r2_score(y_test_np, y_pred_test_np)\n",
    "    rmsd_test = (mean_squared_error(y_test_np, y_pred_test_np))**0.5\n",
    "    bias_test = np.mean(y_pred_test_np - y_test_np)\n",
    "    sdep_test = (np.mean((y_pred_test_np - y_test_np - bias_test)**2))**0.5\n",
    "    r2 = '{:.3f}'.format(r2_test)\n",
    "    rmsd = '{:.3f}'.format(rmsd_test)\n",
    "    bias = '{:.3f}'.format(bias_test)\n",
    "    sdep = '{:.3f}'.format(sdep_test)\n",
    "    \n",
    "    \n",
    "    mse=mean_squared_error(y_test_np, y_pred_test_np)\n",
    "    mse='{:.3f}'.format(mse)\n",
    "    mae=mean_absolute_error(y_test_np, y_pred_test_np)\n",
    "    mae='{:.3f}'.format(mae)\n",
    "    try:\n",
    "        a, b = np.polyfit(y_test_np, y_pred_test_np, 1)\n",
    "        plot_a = '{:.3f}'.format(a[0])\n",
    "        plot_b = '{:.3f}'.format(b[0])\n",
    "    except np.linalg.LinAlgError:\n",
    "        pass\n",
    "    \n",
    "    return r2, rmsd, bias, sdep, plot_a, plot_b, mse, mae\n",
    "\n",
    "def grid_analysis(df,home,resample,fold,prop, model_name):\n",
    "    df2=pd.DataFrame()\n",
    "    keyList = ['trial',\n",
    "               'model_type1', 'model_type',\n",
    "               'layer_3_3', 'layer_2_2', 'layer_1',\n",
    "               f'r2_{prop}_{fold}',\n",
    "               f'rmsd_{prop}_{fold}',\n",
    "               f'bias_{prop}_{fold}',\n",
    "               f'SDEP_{prop}_{fold}',\n",
    "               f'gradient_{prop}_{fold}',\n",
    "               f'b_{prop}_{fold}',\n",
    "               f'mse_{prop}_{fold}',\n",
    "               f'mae_{prop}_{fold}']\n",
    "    n = dict(zip(keyList, [None]*len(keyList)))\n",
    "    \n",
    "    df_grid=pd.DataFrame(n,index=['a'])\n",
    "   \n",
    "    dir=path_fold(home, resample, fold)\n",
    "    # model_name = f\"1DConv_st_{prop}\" \n",
    "    tunner_path =f\"{dir}/{desc}/{model_name}/tunner\"\n",
    "    tuner = kt.GridSearch(build_model,\n",
    "                           objective=kt.Objective('val_loss', 'min'),\n",
    "                            # loss = 'val_loss',\n",
    "                           # objective = ['val_mse','epoch_entropy_pred_mse','val_free_energy_pred_mse'],\n",
    "                          directory=tunner_path,\n",
    "                          overwrite=False,\n",
    "                          project_name=f'{batch}')\n",
    "\n",
    "    # Find all trial number and cycle through them\n",
    "    selection=os.listdir(tuner.project_dir)\n",
    "    for dir_ in selection:\n",
    "        if \"trial_\" not in dir_:\n",
    "            continue\n",
    "        trial_number=str(dir_.replace(\"trial_\",\"\"))\n",
    "        trial=tuner.oracle.get_trial(trial_number)\n",
    "        model=tuner.load_model(trial)\n",
    "\n",
    "        # train, val, test = access_resample_csv(df,home,resample)\n",
    "        train_fold, val_fold, test_fold = access_fold_csv(df,home,resample,fold)\n",
    "        \n",
    "        y_1_train, y_2_train, y_3_train, y_4_train, Y_train, X_padded_train, X_train = load_xy(train_fold,desc)\n",
    "        y_1_val,   y_2_val,   y_3_val,   y_4_val,   Y_val,   X_padded_val,   X_val   = load_xy(val_fold,desc)\n",
    "        y_1_test,  y_2_test,  y_3_test,  y_4_test,  Y_test,  X_padded_test,  X_test  = load_xy(test_fold,desc)\n",
    "\n",
    "        y_test_pred = model.predict(X_padded_test)\n",
    "        \n",
    "        r2, rmsd, bias, sdep, plot_a, plot_b, mse, mae = stats_hp(y_test_pred, Y_test, prop)\n",
    "        if trial_number in df_grid.index:\n",
    "            n = df_grid.loc[trial_number].to_dict()\n",
    "        n.update({\"trial\":trial_number,})\n",
    "        n.update({f'r2_{prop}_{fold}':r2,f'rmsd_{prop}_{fold}': rmsd, \n",
    "                  f'bias_{prop}_{fold}': bias, f'SDEP_{prop}_{fold}': sdep,\n",
    "                  f'gradient_{prop}_{fold}': plot_a, f'b_{prop}_{fold}': plot_b, \n",
    "                  f'mse_{prop}_{fold}':mse, f'mae_{prop}_{fold}':mae,})\n",
    "\n",
    "        original_stdout = sys.stdout \t\n",
    "        with open(f'{prop}_{fold}_{resample}.txt', 'w') as f:\n",
    "            sys.stdout = f\n",
    "            trial.display_hyperparameters()\n",
    "            # Reset the standard output\n",
    "            sys.stdout = original_stdout \n",
    "        f.close\n",
    "        data = open(f'{prop}_{fold}_{resample}.txt', 'r').read()\n",
    "        data_hyp_param=data.replace(': ','\\n').split('\\n')\n",
    "        i_index=0\n",
    "        while i_index+1 < len(data_hyp_param):\n",
    "            n.update({data_hyp_param[i_index]:data_hyp_param[i_index+1]})\n",
    "            i_index+=2\n",
    "        os.system(f'rm {prop}_{fold}_{resample}.txt')\n",
    "\n",
    "        df_grid.loc[f'{trial_number}']=n\n",
    "    df_grid.to_csv(f'{dir}/{desc}/{model_name}/{prop}_{fold}.csv')\n",
    "    # df_grid.to_csv(f'{prop}_{fold}.csv')\n",
    "    return\n",
    "# No longer needed this execution\n",
    "# grid_analysis(df,home,resample,fold,prop,model_name)\n",
    "\n",
    "####### Template for Archiving and Deleting Files\n",
    "\n",
    "import tarfile\n",
    "import os\n",
    "from pathlib import Path\n",
    "#  Create Archive and Delete Folders\n",
    "\n",
    "def create_tar_archive(work_dir,files):\n",
    "    # Create a tar.gz archive\n",
    "    with tarfile.open(f\"{work_dir}tuner_results.tar.gz\", \"w:gz\") as archive:\n",
    "        for file in files:\n",
    "            archive.add(f\"{work_dir}{file}\", arcname=os.path.basename(f\"{file}\"))\n",
    "        archive.close()\n",
    "\n",
    "        \n",
    "def archive_hyper_params(home,resample,fold,prop,desc,model_name):\n",
    "    # prop not required\n",
    "    dir=path_fold(home, resample, fold)\n",
    "    folder_dir=f'{dir}/{desc}/{model_name}/'\n",
    "    folders_to_archive=os.listdir(folder_dir)\n",
    "    create_tar_archive(folder_dir, folders_to_archive)\n",
    "    \n",
    "    return\n",
    "\n",
    "def delete_folders_after_archive(home,resample,fold,prop,desc,model_name):\n",
    "    # prop not required\n",
    "    dir=path_fold(home, resample, fold)\n",
    "    folder_dir=f'{dir}/{desc}/{model_name}/'\n",
    "    folders_to_archive=os.listdir(folder_dir)\n",
    "    folders_to_archive = list(filter(lambda i:'.' not in i, folders_to_archive))\n",
    "    for folder in folders_to_archive:\n",
    "        os.system(f'rm -r {folder_dir}{folder}')\n",
    "\n",
    "    return\n",
    "# no longer need execution  \n",
    "# archive_hyper_params(home,resample,fold,prop,desc,model_name)\n",
    "# delete_folders_after_archive(home,resample,fold,prop,desc,model_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 353,
   "id": "5af95855-5094-4cb0-be8a-e4b2a0c2bf22",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ######## Find best hyper params and train and evaluation on resample data\n",
    "train, val, test = access_resample_csv(df,home,resample)\n",
    "\n",
    "y_1_train, y_2_train, y_3_train, y_4_train, Y_train, X_padded_train, X_train = load_xy(train,desc)\n",
    "y_1_val,   y_2_val,   y_3_val,   y_4_val,   Y_val,   X_padded_val,   X_val   = load_xy(val,desc)\n",
    "y_1_test,  y_2_test,  y_3_test,  y_4_test,  Y_test,  X_padded_test,  X_test  = load_xy(test,desc)\n",
    "\n",
    "fold_path = path_fold(home,resample,fold)\n",
    "resample_path = path_resample(home,resample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 385,
   "id": "531e1d67-ce8d-4eca-baa2-eacd7a462a1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df_combine = pd.DataFrame()\n",
    "df_summary = pd.DataFrame()\n",
    "df_combine_all = pd.DataFrame()\n",
    "\n",
    "# for resample in range(1):\n",
    "df_combine_all = pd.DataFrame()\n",
    "df_summary = pd.DataFrame()\n",
    "# for prop in GSHT_list:\n",
    "#     print(prop)\n",
    "for fold in range(5):\n",
    "    dir = path_fold(home, resample, fold)\n",
    "    model_name = f\"1DConv_st_{prop}\"\n",
    "    try:\n",
    "        df_read=pd.read_csv(f'{dir}/{desc}/{model_name}/{prop}_{fold}.csv')\n",
    "        # Combine\n",
    "        df_combine=pd.concat([df_combine,df_read],\n",
    "                            axis=1)\n",
    "    except:\n",
    "        pass\n",
    "        \n",
    "    # count=0\n",
    "df_combine = df_combine.T.drop_duplicates().T\n",
    "stats_list=['r2','rmsd','bias','SDEP','gradient','b','mse','mae']\n",
    "for stat in stats_list:\n",
    "    columns_to_compute = df_combine.filter(regex=f'^{stat}_{prop}')\n",
    "    # print(columns_to_compute)\n",
    "    # Compute mean and std for the specified columns\n",
    "    mean_values = df_combine.filter(regex=f'^{stat}_{prop}').mean(axis=1)\n",
    "    std_values = df_combine.filter(regex=f'^{stat}_{prop}').std(axis=1)\n",
    "    df_combine_all[f'{stat}_{prop}_mean'] = mean_values\n",
    "    df_combine_all[f'{stat}_{prop}_std']  = std_values\n",
    "    if stat == 'r2' or stat =='rmsd':\n",
    "        df_summary[f'{stat}_{prop}_mean'] = mean_values\n",
    "        df_summary[f'{stat}_{prop}_std']  = std_values\n",
    "\n",
    "df_summary['trial_id']=df_combine['Unnamed: 0']\n",
    "#  Find the trial number with the best hyper paramteres\n",
    "trial_number_fin_model = df_summary.loc[df_summary[f'r2_{prop}_mean'].idxmax()]['trial_id']\n",
    "\n",
    "# Load best hyper parameters into a dataframe\n",
    "best_hps=df_combine.loc[df_combine['Unnamed: 0']==trial_number_fin_model][df_combine.columns[1:8]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 405,
   "id": "672fd99f-32a8-4d03-8da6-527c3e9c0e30",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df_combine = pd.DataFrame()\n",
    "df_summary = pd.DataFrame()\n",
    "df_combine_all = pd.DataFrame()\n",
    "\n",
    "# for resample in range(1):\n",
    "df_combine_all = pd.DataFrame()\n",
    "df_summary = pd.DataFrame()\n",
    "# for prop in GSHT_list:\n",
    "#     print(prop)\n",
    "for fold in range(5):\n",
    "    dir = path_fold(home, resample, fold)\n",
    "    model_name = f\"1DConv_st_{prop}\"\n",
    "    try:\n",
    "        df_read=pd.read_csv(f'{dir}/{desc}/{model_name}/{prop}_{fold}.csv')\n",
    "        # Combine\n",
    "        df_combine=pd.concat([df_combine,df_read],\n",
    "                            axis=1)\n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 406,
   "id": "e40fafea-d84b-45c0-870c-df0f871cc11f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Unnamed: 0', 'trial', 'model_type1', 'model_type', 'layer_3_3',\n",
       "       'layer_2_2', 'layer_1', 'r2_dH_0', 'rmsd_dH_0', 'bias_dH_0',\n",
       "       'SDEP_dH_0', 'gradient_dH_0', 'b_dH_0', 'mse_dH_0', 'mae_dH_0',\n",
       "       'Unnamed: 0', 'trial', 'model_type1', 'model_type', 'layer_3_3',\n",
       "       'layer_2_2', 'layer_1', 'r2_dH_1', 'rmsd_dH_1', 'bias_dH_1',\n",
       "       'SDEP_dH_1', 'gradient_dH_1', 'b_dH_1', 'mse_dH_1', 'mae_dH_1',\n",
       "       'Unnamed: 0', 'trial', 'model_type1', 'model_type', 'layer_3_3',\n",
       "       'layer_2_2', 'layer_1', 'r2_dH_2', 'rmsd_dH_2', 'bias_dH_2',\n",
       "       'SDEP_dH_2', 'gradient_dH_2', 'b_dH_2', 'mse_dH_2', 'mae_dH_2',\n",
       "       'Unnamed: 0', 'trial', 'model_type1', 'model_type', 'layer_3_3',\n",
       "       'layer_2_2', 'layer_1', 'r2_dH_3', 'rmsd_dH_3', 'bias_dH_3',\n",
       "       'SDEP_dH_3', 'gradient_dH_3', 'b_dH_3', 'mse_dH_3', 'mae_dH_3',\n",
       "       'Unnamed: 0', 'trial', 'model_type1', 'model_type', 'layer_3_3',\n",
       "       'layer_2_2', 'layer_1', 'r2_dH_4', 'rmsd_dH_4', 'bias_dH_4',\n",
       "       'SDEP_dH_4', 'gradient_dH_4', 'b_dH_4', 'mse_dH_4', 'mae_dH_4'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 406,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# df_combine = df_combine.T.drop_duplicates().T\n",
    "df_combine.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 407,
   "id": "58e7b398-007d-463b-92d0-f1e1592bf9d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "stats_list=['r2','rmsd','bias','SDEP','gradient','b','mse','mae']\n",
    "for stat in stats_list:\n",
    "    columns_to_compute = df_combine.filter(regex=f'^{stat}_{prop}')\n",
    "    # print(columns_to_compute)\n",
    "    # Compute mean and std for the specified columns\n",
    "    mean_values = df_combine.filter(regex=f'^{stat}_{prop}').mean(axis=1)\n",
    "    std_values = df_combine.filter(regex=f'^{stat}_{prop}').std(axis=1)\n",
    "    df_combine_all[f'{stat}_{prop}_mean'] = mean_values\n",
    "    df_combine_all[f'{stat}_{prop}_std']  = std_values\n",
    "    if stat == 'r2' or stat =='rmsd':\n",
    "        df_summary[f'{stat}_{prop}_mean'] = mean_values\n",
    "        df_summary[f'{stat}_{prop}_std']  = std_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 408,
   "id": "46dcb856-2c69-48a0-829a-3a316de1e8d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>trial</th>\n",
       "      <th>model_type1</th>\n",
       "      <th>model_type</th>\n",
       "      <th>layer_3_3</th>\n",
       "      <th>layer_2_2</th>\n",
       "      <th>layer_1</th>\n",
       "      <th>r2_dH_0</th>\n",
       "      <th>rmsd_dH_0</th>\n",
       "      <th>bias_dH_0</th>\n",
       "      <th>...</th>\n",
       "      <th>mse_dH_3</th>\n",
       "      <th>mae_dH_3</th>\n",
       "      <th>r2_dH_4</th>\n",
       "      <th>rmsd_dH_4</th>\n",
       "      <th>bias_dH_4</th>\n",
       "      <th>SDEP_dH_4</th>\n",
       "      <th>gradient_dH_4</th>\n",
       "      <th>b_dH_4</th>\n",
       "      <th>mse_dH_4</th>\n",
       "      <th>mae_dH_4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>a</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>CNN3</td>\n",
       "      <td>Dense3</td>\n",
       "      <td>16.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>0.938</td>\n",
       "      <td>5.509</td>\n",
       "      <td>-1.793</td>\n",
       "      <td>...</td>\n",
       "      <td>27.146</td>\n",
       "      <td>3.921</td>\n",
       "      <td>0.915</td>\n",
       "      <td>6.863</td>\n",
       "      <td>1.548</td>\n",
       "      <td>32.630</td>\n",
       "      <td>0.918</td>\n",
       "      <td>-4.241</td>\n",
       "      <td>47.101</td>\n",
       "      <td>5.297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0007</td>\n",
       "      <td>7.0</td>\n",
       "      <td>CNN2</td>\n",
       "      <td>Dense3</td>\n",
       "      <td>16.0</td>\n",
       "      <td>128.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>0.938</td>\n",
       "      <td>5.472</td>\n",
       "      <td>-1.084</td>\n",
       "      <td>...</td>\n",
       "      <td>22.354</td>\n",
       "      <td>3.744</td>\n",
       "      <td>0.916</td>\n",
       "      <td>6.847</td>\n",
       "      <td>2.136</td>\n",
       "      <td>32.808</td>\n",
       "      <td>0.931</td>\n",
       "      <td>-2.757</td>\n",
       "      <td>46.885</td>\n",
       "      <td>5.545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0002</td>\n",
       "      <td>2.0</td>\n",
       "      <td>CNN3</td>\n",
       "      <td>Dense3</td>\n",
       "      <td>16.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>0.945</td>\n",
       "      <td>5.187</td>\n",
       "      <td>-1.140</td>\n",
       "      <td>...</td>\n",
       "      <td>29.875</td>\n",
       "      <td>4.112</td>\n",
       "      <td>0.919</td>\n",
       "      <td>6.712</td>\n",
       "      <td>0.656</td>\n",
       "      <td>32.870</td>\n",
       "      <td>0.933</td>\n",
       "      <td>-4.125</td>\n",
       "      <td>45.050</td>\n",
       "      <td>5.104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0010</td>\n",
       "      <td>10.0</td>\n",
       "      <td>CNN1</td>\n",
       "      <td>Dense3</td>\n",
       "      <td>16.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>0.933</td>\n",
       "      <td>5.717</td>\n",
       "      <td>-1.178</td>\n",
       "      <td>...</td>\n",
       "      <td>29.931</td>\n",
       "      <td>4.385</td>\n",
       "      <td>0.917</td>\n",
       "      <td>6.777</td>\n",
       "      <td>0.842</td>\n",
       "      <td>33.159</td>\n",
       "      <td>0.949</td>\n",
       "      <td>-2.757</td>\n",
       "      <td>45.933</td>\n",
       "      <td>5.027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0003</td>\n",
       "      <td>3.0</td>\n",
       "      <td>CNN3</td>\n",
       "      <td>Dense3</td>\n",
       "      <td>16.0</td>\n",
       "      <td>128.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>0.926</td>\n",
       "      <td>6.009</td>\n",
       "      <td>-1.582</td>\n",
       "      <td>...</td>\n",
       "      <td>31.746</td>\n",
       "      <td>4.344</td>\n",
       "      <td>0.911</td>\n",
       "      <td>7.049</td>\n",
       "      <td>2.157</td>\n",
       "      <td>32.621</td>\n",
       "      <td>0.918</td>\n",
       "      <td>-3.691</td>\n",
       "      <td>49.687</td>\n",
       "      <td>5.740</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0004</td>\n",
       "      <td>4.0</td>\n",
       "      <td>CNN2</td>\n",
       "      <td>Dense3</td>\n",
       "      <td>16.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>0.944</td>\n",
       "      <td>5.220</td>\n",
       "      <td>-0.606</td>\n",
       "      <td>...</td>\n",
       "      <td>30.530</td>\n",
       "      <td>4.427</td>\n",
       "      <td>0.912</td>\n",
       "      <td>7.008</td>\n",
       "      <td>2.060</td>\n",
       "      <td>32.247</td>\n",
       "      <td>0.896</td>\n",
       "      <td>-5.329</td>\n",
       "      <td>49.107</td>\n",
       "      <td>5.721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0001</td>\n",
       "      <td>1.0</td>\n",
       "      <td>CNN3</td>\n",
       "      <td>Dense3</td>\n",
       "      <td>16.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>0.935</td>\n",
       "      <td>5.640</td>\n",
       "      <td>-1.602</td>\n",
       "      <td>...</td>\n",
       "      <td>25.336</td>\n",
       "      <td>3.904</td>\n",
       "      <td>0.920</td>\n",
       "      <td>6.686</td>\n",
       "      <td>0.666</td>\n",
       "      <td>32.275</td>\n",
       "      <td>0.898</td>\n",
       "      <td>-6.569</td>\n",
       "      <td>44.705</td>\n",
       "      <td>5.039</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0006</td>\n",
       "      <td>6.0</td>\n",
       "      <td>CNN2</td>\n",
       "      <td>Dense3</td>\n",
       "      <td>16.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>0.943</td>\n",
       "      <td>5.250</td>\n",
       "      <td>-1.542</td>\n",
       "      <td>...</td>\n",
       "      <td>25.052</td>\n",
       "      <td>3.787</td>\n",
       "      <td>0.909</td>\n",
       "      <td>7.101</td>\n",
       "      <td>1.659</td>\n",
       "      <td>33.782</td>\n",
       "      <td>0.985</td>\n",
       "      <td>0.567</td>\n",
       "      <td>50.418</td>\n",
       "      <td>5.432</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0009</td>\n",
       "      <td>9.0</td>\n",
       "      <td>CNN1</td>\n",
       "      <td>Dense3</td>\n",
       "      <td>16.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>0.931</td>\n",
       "      <td>5.777</td>\n",
       "      <td>-0.095</td>\n",
       "      <td>...</td>\n",
       "      <td>21.203</td>\n",
       "      <td>3.509</td>\n",
       "      <td>0.917</td>\n",
       "      <td>6.803</td>\n",
       "      <td>1.354</td>\n",
       "      <td>32.951</td>\n",
       "      <td>0.938</td>\n",
       "      <td>-3.076</td>\n",
       "      <td>46.275</td>\n",
       "      <td>5.170</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0011</td>\n",
       "      <td>11.0</td>\n",
       "      <td>CNN1</td>\n",
       "      <td>Dense3</td>\n",
       "      <td>16.0</td>\n",
       "      <td>128.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>0.930</td>\n",
       "      <td>5.821</td>\n",
       "      <td>-0.822</td>\n",
       "      <td>...</td>\n",
       "      <td>23.265</td>\n",
       "      <td>3.845</td>\n",
       "      <td>0.912</td>\n",
       "      <td>6.989</td>\n",
       "      <td>1.318</td>\n",
       "      <td>33.287</td>\n",
       "      <td>0.955</td>\n",
       "      <td>-1.859</td>\n",
       "      <td>48.845</td>\n",
       "      <td>5.335</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0005</td>\n",
       "      <td>5.0</td>\n",
       "      <td>CNN2</td>\n",
       "      <td>Dense3</td>\n",
       "      <td>16.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>0.935</td>\n",
       "      <td>5.605</td>\n",
       "      <td>-0.635</td>\n",
       "      <td>...</td>\n",
       "      <td>28.226</td>\n",
       "      <td>4.157</td>\n",
       "      <td>0.917</td>\n",
       "      <td>6.798</td>\n",
       "      <td>-0.666</td>\n",
       "      <td>32.599</td>\n",
       "      <td>0.916</td>\n",
       "      <td>-6.653</td>\n",
       "      <td>46.220</td>\n",
       "      <td>4.866</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0008</td>\n",
       "      <td>8.0</td>\n",
       "      <td>CNN1</td>\n",
       "      <td>Dense3</td>\n",
       "      <td>16.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>0.947</td>\n",
       "      <td>5.062</td>\n",
       "      <td>-1.192</td>\n",
       "      <td>...</td>\n",
       "      <td>23.870</td>\n",
       "      <td>3.978</td>\n",
       "      <td>0.926</td>\n",
       "      <td>6.410</td>\n",
       "      <td>0.973</td>\n",
       "      <td>32.246</td>\n",
       "      <td>0.900</td>\n",
       "      <td>-6.118</td>\n",
       "      <td>41.091</td>\n",
       "      <td>4.996</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>13 rows × 47 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  trial model_type1 model_type  layer_3_3  layer_2_2  layer_1  \\\n",
       "0           a    NaN         NaN        NaN        NaN        NaN      NaN   \n",
       "1        0000    0.0        CNN3     Dense3       16.0       16.0     16.0   \n",
       "2        0007    7.0        CNN2     Dense3       16.0      128.0     16.0   \n",
       "3        0002    2.0        CNN3     Dense3       16.0       64.0     16.0   \n",
       "4        0010   10.0        CNN1     Dense3       16.0       64.0     16.0   \n",
       "5        0003    3.0        CNN3     Dense3       16.0      128.0     16.0   \n",
       "6        0004    4.0        CNN2     Dense3       16.0       16.0     16.0   \n",
       "7        0001    1.0        CNN3     Dense3       16.0       32.0     16.0   \n",
       "8        0006    6.0        CNN2     Dense3       16.0       64.0     16.0   \n",
       "9        0009    9.0        CNN1     Dense3       16.0       32.0     16.0   \n",
       "10       0011   11.0        CNN1     Dense3       16.0      128.0     16.0   \n",
       "11       0005    5.0        CNN2     Dense3       16.0       32.0     16.0   \n",
       "12       0008    8.0        CNN1     Dense3       16.0       16.0     16.0   \n",
       "\n",
       "    r2_dH_0  rmsd_dH_0  bias_dH_0  ...  mse_dH_3  mae_dH_3  r2_dH_4  \\\n",
       "0       NaN        NaN        NaN  ...       NaN       NaN      NaN   \n",
       "1     0.938      5.509     -1.793  ...    27.146     3.921    0.915   \n",
       "2     0.938      5.472     -1.084  ...    22.354     3.744    0.916   \n",
       "3     0.945      5.187     -1.140  ...    29.875     4.112    0.919   \n",
       "4     0.933      5.717     -1.178  ...    29.931     4.385    0.917   \n",
       "5     0.926      6.009     -1.582  ...    31.746     4.344    0.911   \n",
       "6     0.944      5.220     -0.606  ...    30.530     4.427    0.912   \n",
       "7     0.935      5.640     -1.602  ...    25.336     3.904    0.920   \n",
       "8     0.943      5.250     -1.542  ...    25.052     3.787    0.909   \n",
       "9     0.931      5.777     -0.095  ...    21.203     3.509    0.917   \n",
       "10    0.930      5.821     -0.822  ...    23.265     3.845    0.912   \n",
       "11    0.935      5.605     -0.635  ...    28.226     4.157    0.917   \n",
       "12    0.947      5.062     -1.192  ...    23.870     3.978    0.926   \n",
       "\n",
       "    rmsd_dH_4  bias_dH_4  SDEP_dH_4  gradient_dH_4  b_dH_4  mse_dH_4  mae_dH_4  \n",
       "0         NaN        NaN        NaN            NaN     NaN       NaN       NaN  \n",
       "1       6.863      1.548     32.630          0.918  -4.241    47.101     5.297  \n",
       "2       6.847      2.136     32.808          0.931  -2.757    46.885     5.545  \n",
       "3       6.712      0.656     32.870          0.933  -4.125    45.050     5.104  \n",
       "4       6.777      0.842     33.159          0.949  -2.757    45.933     5.027  \n",
       "5       7.049      2.157     32.621          0.918  -3.691    49.687     5.740  \n",
       "6       7.008      2.060     32.247          0.896  -5.329    49.107     5.721  \n",
       "7       6.686      0.666     32.275          0.898  -6.569    44.705     5.039  \n",
       "8       7.101      1.659     33.782          0.985   0.567    50.418     5.432  \n",
       "9       6.803      1.354     32.951          0.938  -3.076    46.275     5.170  \n",
       "10      6.989      1.318     33.287          0.955  -1.859    48.845     5.335  \n",
       "11      6.798     -0.666     32.599          0.916  -6.653    46.220     4.866  \n",
       "12      6.410      0.973     32.246          0.900  -6.118    41.091     4.996  \n",
       "\n",
       "[13 rows x 47 columns]"
      ]
     },
     "execution_count": 408,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_combine_clean = df_combine.loc[:,~df_combine.columns.duplicated()].copy()\n",
    "df_combine_clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 409,
   "id": "65eb7667-e700-4278-887a-7719fb822dfe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Unnamed: 0', 'trial', 'model_type1', 'model_type', 'layer_3_3',\n",
       "       'layer_2_2', 'layer_1', 'r2_dH_0', 'rmsd_dH_0', 'bias_dH_0',\n",
       "       'SDEP_dH_0', 'gradient_dH_0', 'b_dH_0', 'mse_dH_0', 'mae_dH_0',\n",
       "       'r2_dH_1', 'rmsd_dH_1', 'bias_dH_1', 'SDEP_dH_1', 'gradient_dH_1',\n",
       "       'b_dH_1', 'mse_dH_1', 'mae_dH_1', 'r2_dH_2', 'rmsd_dH_2', 'bias_dH_2',\n",
       "       'SDEP_dH_2', 'gradient_dH_2', 'b_dH_2', 'mse_dH_2', 'mae_dH_2',\n",
       "       'r2_dH_3', 'rmsd_dH_3', 'bias_dH_3', 'SDEP_dH_3', 'gradient_dH_3',\n",
       "       'b_dH_3', 'mse_dH_3', 'mae_dH_3', 'r2_dH_4', 'rmsd_dH_4', 'bias_dH_4',\n",
       "       'SDEP_dH_4', 'gradient_dH_4', 'b_dH_4', 'mse_dH_4', 'mae_dH_4'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 409,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_combine_clean.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 414,
   "id": "72188184-76b4-49f5-bf3e-ee3dea874cc7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_summary['trial_id']=df_combine_clean['Unnamed: 0']\n",
    "#  Find the trial number with the best hyper paramteres\n",
    "trial_number_fin_model = df_summary.loc[df_summary[f'r2_{prop}_mean'].idxmax()]['trial_id']\n",
    "\n",
    "# Load best hyper parameters into a dataframe\n",
    "best_hps=df_combine_clean.loc[df_combine_clean['Unnamed: 0']==trial_number_fin_model][df_combine.columns[2:7]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 415,
   "id": "fc189274-69e0-4606-a082-8e525c9a23ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model_type1</th>\n",
       "      <th>model_type</th>\n",
       "      <th>layer_3_3</th>\n",
       "      <th>layer_2_2</th>\n",
       "      <th>layer_1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>CNN3</td>\n",
       "      <td>Dense3</td>\n",
       "      <td>16.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>16.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  model_type1 model_type  layer_3_3  layer_2_2  layer_1\n",
       "7        CNN3     Dense3       16.0       32.0     16.0"
      ]
     },
     "execution_count": 415,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_hps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 359,
   "id": "539144c0-ab1d-4130-8e10-dc7ae3b5d1ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0001'"
      ]
     },
     "execution_count": 359,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trial_number_fin_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 360,
   "id": "0dc0e700-c618-4970-b413-fa54ac5fb8f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>r2_dH_mean</th>\n",
       "      <th>r2_dH_std</th>\n",
       "      <th>rmsd_dH_mean</th>\n",
       "      <th>rmsd_dH_std</th>\n",
       "      <th>trial_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.915</td>\n",
       "      <td>0.016882</td>\n",
       "      <td>6.1726</td>\n",
       "      <td>1.084398</td>\n",
       "      <td>0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.921</td>\n",
       "      <td>0.014832</td>\n",
       "      <td>5.932</td>\n",
       "      <td>0.833571</td>\n",
       "      <td>0007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.919</td>\n",
       "      <td>0.021296</td>\n",
       "      <td>5.9652</td>\n",
       "      <td>0.82774</td>\n",
       "      <td>0002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.9148</td>\n",
       "      <td>0.017326</td>\n",
       "      <td>6.1428</td>\n",
       "      <td>0.702311</td>\n",
       "      <td>0010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.9134</td>\n",
       "      <td>0.020623</td>\n",
       "      <td>6.1648</td>\n",
       "      <td>0.594373</td>\n",
       "      <td>0003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.915</td>\n",
       "      <td>0.021424</td>\n",
       "      <td>6.1254</td>\n",
       "      <td>0.906978</td>\n",
       "      <td>0004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.9256</td>\n",
       "      <td>0.014206</td>\n",
       "      <td>5.757</td>\n",
       "      <td>0.71669</td>\n",
       "      <td>0001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.9168</td>\n",
       "      <td>0.015287</td>\n",
       "      <td>6.1022</td>\n",
       "      <td>1.064208</td>\n",
       "      <td>0006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.9222</td>\n",
       "      <td>0.005541</td>\n",
       "      <td>5.9356</td>\n",
       "      <td>0.919673</td>\n",
       "      <td>0009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.9228</td>\n",
       "      <td>0.011606</td>\n",
       "      <td>5.899</td>\n",
       "      <td>1.010422</td>\n",
       "      <td>0011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.9208</td>\n",
       "      <td>0.017782</td>\n",
       "      <td>5.9056</td>\n",
       "      <td>0.621539</td>\n",
       "      <td>0005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.9254</td>\n",
       "      <td>0.014258</td>\n",
       "      <td>5.7522</td>\n",
       "      <td>0.775684</td>\n",
       "      <td>0008</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   r2_dH_mean r2_dH_std rmsd_dH_mean rmsd_dH_std trial_id\n",
       "0         NaN       NaN          NaN         NaN        a\n",
       "1       0.915  0.016882       6.1726    1.084398     0000\n",
       "2       0.921  0.014832        5.932    0.833571     0007\n",
       "3       0.919  0.021296       5.9652     0.82774     0002\n",
       "4      0.9148  0.017326       6.1428    0.702311     0010\n",
       "5      0.9134  0.020623       6.1648    0.594373     0003\n",
       "6       0.915  0.021424       6.1254    0.906978     0004\n",
       "7      0.9256  0.014206        5.757     0.71669     0001\n",
       "8      0.9168  0.015287       6.1022    1.064208     0006\n",
       "9      0.9222  0.005541       5.9356    0.919673     0009\n",
       "10     0.9228  0.011606        5.899    1.010422     0011\n",
       "11     0.9208  0.017782       5.9056    0.621539     0005\n",
       "12     0.9254  0.014258       5.7522    0.775684     0008"
      ]
     },
     "execution_count": 360,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41ba777c-efff-4a5f-980e-9f834b529c08",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 416,
   "id": "7ab1b215-e261-4d7f-81f0-d61ea869e52d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n",
      "10/10 - 2s - loss: 4976.3125 - mse: 4976.3125 - mean_absolute_error: 67.2766 - r2_func_tf: -1.2733e+01 - rmse_func_tf: 69.9794 - bias_func_tf: -6.7165e+01 - sdep_func_tf: 19.3283 - val_loss: 1481.1564 - val_mse: 1481.1564 - val_mean_absolute_error: 36.5277 - val_r2_func_tf: -2.4899e+00 - val_rmse_func_tf: 38.2729 - val_bias_func_tf: -3.6528e+01 - val_sdep_func_tf: 11.2423 - 2s/epoch - 242ms/step\n",
      "Epoch 2/300\n",
      "10/10 - 0s - loss: 3354.4141 - mse: 3354.4141 - mean_absolute_error: 54.5599 - r2_func_tf: -9.0656e+00 - rmse_func_tf: 58.0793 - bias_func_tf: -5.5258e+01 - sdep_func_tf: 17.5306 - val_loss: 560.8002 - val_mse: 560.8002 - val_mean_absolute_error: 20.6930 - val_r2_func_tf: -5.2236e-01 - val_rmse_func_tf: 23.4852 - val_bias_func_tf: 20.5847 - val_sdep_func_tf: 10.8698 - 102ms/epoch - 10ms/step\n",
      "Epoch 3/300\n",
      "10/10 - 0s - loss: 843.2722 - mse: 843.2722 - mean_absolute_error: 21.9748 - r2_func_tf: -6.2227e-01 - rmse_func_tf: 24.1318 - bias_func_tf: -1.9993e+01 - sdep_func_tf: 12.0579 - val_loss: 13265.7969 - val_mse: 13265.7969 - val_mean_absolute_error: 108.8341 - val_r2_func_tf: -3.2908e+01 - val_rmse_func_tf: 114.8464 - val_bias_func_tf: 108.8341 - val_sdep_func_tf: 35.7421 - 96ms/epoch - 10ms/step\n",
      "Epoch 4/300\n",
      "10/10 - 0s - loss: 128.1283 - mse: 128.1283 - mean_absolute_error: 9.3689 - r2_func_tf: 0.4820 - rmse_func_tf: 10.6305 - bias_func_tf: 6.8746 - sdep_func_tf: 6.1369 - val_loss: 22877.7090 - val_mse: 22877.7090 - val_mean_absolute_error: 140.6783 - val_r2_func_tf: -5.6035e+01 - val_rmse_func_tf: 150.7331 - val_bias_func_tf: 140.6783 - val_sdep_func_tf: 52.8138 - 104ms/epoch - 10ms/step\n",
      "Epoch 5/300\n",
      "10/10 - 0s - loss: 120.3909 - mse: 120.3909 - mean_absolute_error: 8.8190 - r2_func_tf: 0.2277 - rmse_func_tf: 10.0938 - bias_func_tf: -5.5207e+00 - sdep_func_tf: 5.2365 - val_loss: 16739.5996 - val_mse: 16739.5996 - val_mean_absolute_error: 121.2156 - val_r2_func_tf: -4.1193e+01 - val_rmse_func_tf: 129.0049 - val_bias_func_tf: 121.2156 - val_sdep_func_tf: 43.0040 - 100ms/epoch - 10ms/step\n",
      "Epoch 6/300\n",
      "10/10 - 0s - loss: 93.7851 - mse: 93.7851 - mean_absolute_error: 7.8712 - r2_func_tf: 0.6873 - rmse_func_tf: 8.8730 - bias_func_tf: 4.2834 - sdep_func_tf: 5.4948 - val_loss: 9591.3906 - val_mse: 9591.3906 - val_mean_absolute_error: 92.0181 - val_r2_func_tf: -2.3394e+01 - val_rmse_func_tf: 97.6817 - val_bias_func_tf: 92.0181 - val_sdep_func_tf: 31.8273 - 96ms/epoch - 10ms/step\n",
      "Epoch 7/300\n",
      "10/10 - 0s - loss: 85.4915 - mse: 85.4915 - mean_absolute_error: 7.2080 - r2_func_tf: 0.7356 - rmse_func_tf: 8.5801 - bias_func_tf: -2.9561e+00 - sdep_func_tf: 5.6346 - val_loss: 6561.1963 - val_mse: 6561.1963 - val_mean_absolute_error: 76.1454 - val_r2_func_tf: -1.5799e+01 - val_rmse_func_tf: 80.8100 - val_bias_func_tf: 76.1454 - val_sdep_func_tf: 26.2252 - 95ms/epoch - 9ms/step\n",
      "Epoch 8/300\n",
      "10/10 - 0s - loss: 83.6048 - mse: 83.6048 - mean_absolute_error: 7.1491 - r2_func_tf: 0.5919 - rmse_func_tf: 8.5312 - bias_func_tf: -4.9387e-01 - sdep_func_tf: 5.5834 - val_loss: 4700.7974 - val_mse: 4700.7974 - val_mean_absolute_error: 64.6459 - val_r2_func_tf: -1.1141e+01 - val_rmse_func_tf: 68.4200 - val_bias_func_tf: 64.6459 - val_sdep_func_tf: 21.6607 - 94ms/epoch - 9ms/step\n",
      "Epoch 9/300\n",
      "10/10 - 0s - loss: 95.2459 - mse: 95.2459 - mean_absolute_error: 7.8581 - r2_func_tf: 0.4138 - rmse_func_tf: 9.3220 - bias_func_tf: 3.1685 - sdep_func_tf: 5.5045 - val_loss: 3029.0508 - val_mse: 3029.0508 - val_mean_absolute_error: 52.0963 - val_r2_func_tf: -6.9409e+00 - val_rmse_func_tf: 54.9427 - val_bias_func_tf: 52.0963 - val_sdep_func_tf: 16.8104 - 100ms/epoch - 10ms/step\n",
      "Epoch 10/300\n",
      "10/10 - 0s - loss: 71.0560 - mse: 71.0560 - mean_absolute_error: 6.4987 - r2_func_tf: 0.7805 - rmse_func_tf: 7.7472 - bias_func_tf: -1.3409e+00 - sdep_func_tf: 5.2977 - val_loss: 1691.4575 - val_mse: 1691.4575 - val_mean_absolute_error: 38.7479 - val_r2_func_tf: -3.5088e+00 - val_rmse_func_tf: 41.0612 - val_bias_func_tf: 38.7479 - val_sdep_func_tf: 13.0634 - 91ms/epoch - 9ms/step\n",
      "Epoch 11/300\n",
      "10/10 - 0s - loss: 60.5096 - mse: 60.5096 - mean_absolute_error: 6.2380 - r2_func_tf: 0.8127 - rmse_func_tf: 7.2669 - bias_func_tf: -1.2102e+00 - sdep_func_tf: 5.0439 - val_loss: 1490.6206 - val_mse: 1490.6206 - val_mean_absolute_error: 36.3505 - val_r2_func_tf: -2.9839e+00 - val_rmse_func_tf: 38.5482 - val_bias_func_tf: 36.3505 - val_sdep_func_tf: 12.3096 - 92ms/epoch - 9ms/step\n",
      "Epoch 12/300\n",
      "10/10 - 0s - loss: 37.2595 - mse: 37.2595 - mean_absolute_error: 4.9374 - r2_func_tf: 0.9085 - rmse_func_tf: 5.9919 - bias_func_tf: 1.2232 - sdep_func_tf: 4.6683 - val_loss: 1040.8466 - val_mse: 1040.8466 - val_mean_absolute_error: 30.2824 - val_r2_func_tf: -1.8178e+00 - val_rmse_func_tf: 32.2112 - val_bias_func_tf: 30.2824 - val_sdep_func_tf: 10.4974 - 92ms/epoch - 9ms/step\n",
      "Epoch 13/300\n",
      "10/10 - 0s - loss: 47.9211 - mse: 47.9211 - mean_absolute_error: 5.3364 - r2_func_tf: 0.4530 - rmse_func_tf: 7.2104 - bias_func_tf: 1.6128 - sdep_func_tf: 5.0788 - val_loss: 638.6210 - val_mse: 638.6210 - val_mean_absolute_error: 23.5954 - val_r2_func_tf: -7.6426e-01 - val_rmse_func_tf: 25.2272 - val_bias_func_tf: 23.5480 - val_sdep_func_tf: 8.6004 - 95ms/epoch - 9ms/step\n",
      "Epoch 14/300\n",
      "10/10 - 0s - loss: 62.8642 - mse: 62.8642 - mean_absolute_error: 6.5377 - r2_func_tf: 0.8171 - rmse_func_tf: 7.6492 - bias_func_tf: -2.0336e+00 - sdep_func_tf: 5.0067 - val_loss: 386.0100 - val_mse: 386.0100 - val_mean_absolute_error: 18.1994 - val_r2_func_tf: -9.6853e-02 - val_rmse_func_tf: 19.5948 - val_bias_func_tf: 18.0743 - val_sdep_func_tf: 7.1402 - 91ms/epoch - 9ms/step\n",
      "Epoch 15/300\n",
      "10/10 - 0s - loss: 71.6634 - mse: 71.6634 - mean_absolute_error: 6.2985 - r2_func_tf: 0.8616 - rmse_func_tf: 7.5930 - bias_func_tf: -2.2000e+00 - sdep_func_tf: 5.1125 - val_loss: 378.9896 - val_mse: 378.9896 - val_mean_absolute_error: 18.0893 - val_r2_func_tf: -8.1752e-02 - val_rmse_func_tf: 19.4133 - val_bias_func_tf: 17.9703 - val_sdep_func_tf: 6.9199 - 95ms/epoch - 10ms/step\n",
      "Epoch 16/300\n",
      "10/10 - 0s - loss: 81.9827 - mse: 81.9827 - mean_absolute_error: 7.1380 - r2_func_tf: 0.6848 - rmse_func_tf: 8.9967 - bias_func_tf: 0.0072 - sdep_func_tf: 5.4881 - val_loss: 329.6676 - val_mse: 329.6676 - val_mean_absolute_error: 16.8682 - val_r2_func_tf: 0.0485 - val_rmse_func_tf: 18.0996 - val_bias_func_tf: 16.7270 - val_sdep_func_tf: 6.5027 - 92ms/epoch - 9ms/step\n",
      "Epoch 17/300\n",
      "10/10 - 0s - loss: 40.5030 - mse: 40.5030 - mean_absolute_error: 5.1885 - r2_func_tf: 0.7047 - rmse_func_tf: 6.4208 - bias_func_tf: 2.5017 - sdep_func_tf: 4.8884 - val_loss: 251.1206 - val_mse: 251.1206 - val_mean_absolute_error: 14.6664 - val_r2_func_tf: 0.2606 - val_rmse_func_tf: 15.7846 - val_bias_func_tf: 14.4464 - val_sdep_func_tf: 5.9780 - 91ms/epoch - 9ms/step\n",
      "Epoch 18/300\n",
      "10/10 - 0s - loss: 56.3042 - mse: 56.3042 - mean_absolute_error: 5.7714 - r2_func_tf: 0.8168 - rmse_func_tf: 7.7442 - bias_func_tf: -7.4122e-01 - sdep_func_tf: 5.7284 - val_loss: 114.2417 - val_mse: 114.2417 - val_mean_absolute_error: 9.5124 - val_r2_func_tf: 0.6444 - val_rmse_func_tf: 10.5912 - val_bias_func_tf: 9.0503 - val_sdep_func_tf: 5.1719 - 91ms/epoch - 9ms/step\n",
      "Epoch 19/300\n",
      "10/10 - 0s - loss: 55.3677 - mse: 55.3677 - mean_absolute_error: 5.5796 - r2_func_tf: 0.8405 - rmse_func_tf: 7.6237 - bias_func_tf: -1.6768e+00 - sdep_func_tf: 5.4566 - val_loss: 132.0586 - val_mse: 132.0586 - val_mean_absolute_error: 10.3278 - val_r2_func_tf: 0.5915 - val_rmse_func_tf: 11.3972 - val_bias_func_tf: 9.8935 - val_sdep_func_tf: 5.3176 - 91ms/epoch - 9ms/step\n",
      "Epoch 20/300\n",
      "10/10 - 0s - loss: 81.9367 - mse: 81.9367 - mean_absolute_error: 7.2037 - r2_func_tf: -9.2989e-01 - rmse_func_tf: 8.9509 - bias_func_tf: 2.6575 - sdep_func_tf: 5.1117 - val_loss: 154.7750 - val_mse: 154.7750 - val_mean_absolute_error: 11.2680 - val_r2_func_tf: 0.5279 - val_rmse_func_tf: 12.3546 - val_bias_func_tf: 10.8667 - val_sdep_func_tf: 5.5251 - 93ms/epoch - 9ms/step\n",
      "Epoch 21/300\n",
      "10/10 - 0s - loss: 53.2812 - mse: 53.2812 - mean_absolute_error: 5.8525 - r2_func_tf: 0.8353 - rmse_func_tf: 7.4500 - bias_func_tf: -1.6021e-01 - sdep_func_tf: 4.8548 - val_loss: 65.4208 - val_mse: 65.4208 - val_mean_absolute_error: 6.8793 - val_r2_func_tf: 0.7908 - val_rmse_func_tf: 7.9650 - val_bias_func_tf: 5.8652 - val_sdep_func_tf: 5.0521 - 93ms/epoch - 9ms/step\n",
      "Epoch 22/300\n",
      "10/10 - 0s - loss: 52.7756 - mse: 52.7756 - mean_absolute_error: 5.8803 - r2_func_tf: 0.5868 - rmse_func_tf: 7.3393 - bias_func_tf: -1.1386e-01 - sdep_func_tf: 5.5290 - val_loss: 49.0145 - val_mse: 49.0145 - val_mean_absolute_error: 5.8922 - val_r2_func_tf: 0.8410 - val_rmse_func_tf: 6.8660 - val_bias_func_tf: 4.4125 - val_sdep_func_tf: 4.9222 - 98ms/epoch - 10ms/step\n",
      "Epoch 23/300\n",
      "10/10 - 0s - loss: 35.6535 - mse: 35.6535 - mean_absolute_error: 4.5253 - r2_func_tf: 0.9086 - rmse_func_tf: 5.7399 - bias_func_tf: -7.8639e-01 - sdep_func_tf: 5.1127 - val_loss: 35.6838 - val_mse: 35.6838 - val_mean_absolute_error: 4.7571 - val_r2_func_tf: 0.8866 - val_rmse_func_tf: 5.8549 - val_bias_func_tf: 2.6446 - val_sdep_func_tf: 4.8539 - 95ms/epoch - 10ms/step\n",
      "Epoch 24/300\n",
      "10/10 - 0s - loss: 55.0716 - mse: 55.0716 - mean_absolute_error: 5.9279 - r2_func_tf: 0.6715 - rmse_func_tf: 7.6895 - bias_func_tf: 1.4766 - sdep_func_tf: 4.8224 - val_loss: 35.0048 - val_mse: 35.0048 - val_mean_absolute_error: 4.6345 - val_r2_func_tf: 0.8896 - val_rmse_func_tf: 5.7996 - val_bias_func_tf: 2.4994 - val_sdep_func_tf: 4.8681 - 97ms/epoch - 10ms/step\n",
      "Epoch 25/300\n",
      "10/10 - 0s - loss: 44.9114 - mse: 44.9114 - mean_absolute_error: 5.1930 - r2_func_tf: 0.3325 - rmse_func_tf: 6.6835 - bias_func_tf: -1.5519e-01 - sdep_func_tf: 4.5609 - val_loss: 28.9574 - val_mse: 28.9574 - val_mean_absolute_error: 3.9599 - val_r2_func_tf: 0.9188 - val_rmse_func_tf: 5.3129 - val_bias_func_tf: 0.4261 - val_sdep_func_tf: 4.8783 - 98ms/epoch - 10ms/step\n",
      "Epoch 26/300\n",
      "10/10 - 0s - loss: 78.8424 - mse: 78.8424 - mean_absolute_error: 7.0164 - r2_func_tf: 0.7543 - rmse_func_tf: 8.1145 - bias_func_tf: -1.9404e+00 - sdep_func_tf: 5.3254 - val_loss: 29.7939 - val_mse: 29.7939 - val_mean_absolute_error: 4.0431 - val_r2_func_tf: 0.9239 - val_rmse_func_tf: 5.4236 - val_bias_func_tf: -6.3389e-01 - val_sdep_func_tf: 4.9377 - 95ms/epoch - 10ms/step\n",
      "Epoch 27/300\n",
      "10/10 - 0s - loss: 38.0273 - mse: 38.0273 - mean_absolute_error: 4.7647 - r2_func_tf: 0.9127 - rmse_func_tf: 5.7345 - bias_func_tf: -7.1614e-01 - sdep_func_tf: 4.8090 - val_loss: 33.2255 - val_mse: 33.2255 - val_mean_absolute_error: 4.4343 - val_r2_func_tf: 0.8953 - val_rmse_func_tf: 5.6628 - val_bias_func_tf: 2.0711 - val_sdep_func_tf: 4.9038 - 93ms/epoch - 9ms/step\n",
      "Epoch 28/300\n",
      "10/10 - 0s - loss: 41.3390 - mse: 41.3390 - mean_absolute_error: 5.3596 - r2_func_tf: 0.9019 - rmse_func_tf: 6.4530 - bias_func_tf: 0.9558 - sdep_func_tf: 5.0125 - val_loss: 36.1002 - val_mse: 36.1002 - val_mean_absolute_error: 4.7448 - val_r2_func_tf: 0.8847 - val_rmse_func_tf: 5.8902 - val_bias_func_tf: 2.7048 - val_sdep_func_tf: 4.8940 - 93ms/epoch - 9ms/step\n",
      "Epoch 29/300\n",
      "10/10 - 0s - loss: 54.4206 - mse: 54.4206 - mean_absolute_error: 5.8595 - r2_func_tf: 0.8280 - rmse_func_tf: 6.7586 - bias_func_tf: 0.9814 - sdep_func_tf: 4.9705 - val_loss: 30.8608 - val_mse: 30.8608 - val_mean_absolute_error: 4.1783 - val_r2_func_tf: 0.9073 - val_rmse_func_tf: 5.4617 - val_bias_func_tf: 1.5282 - val_sdep_func_tf: 4.8788 - 91ms/epoch - 9ms/step\n",
      "Epoch 30/300\n",
      "10/10 - 0s - loss: 55.7066 - mse: 55.7066 - mean_absolute_error: 5.5798 - r2_func_tf: 0.8522 - rmse_func_tf: 6.9451 - bias_func_tf: -8.1556e-01 - sdep_func_tf: 5.0580 - val_loss: 28.8247 - val_mse: 28.8247 - val_mean_absolute_error: 3.9526 - val_r2_func_tf: 0.9238 - val_rmse_func_tf: 5.3262 - val_bias_func_tf: -2.0919e-01 - val_sdep_func_tf: 4.9134 - 97ms/epoch - 10ms/step\n",
      "Epoch 31/300\n",
      "10/10 - 0s - loss: 74.5607 - mse: 74.5607 - mean_absolute_error: 6.6592 - r2_func_tf: -2.3427e-02 - rmse_func_tf: 7.9144 - bias_func_tf: 0.1952 - sdep_func_tf: 4.9060 - val_loss: 29.1011 - val_mse: 29.1011 - val_mean_absolute_error: 3.9755 - val_r2_func_tf: 0.9176 - val_rmse_func_tf: 5.3411 - val_bias_func_tf: 0.5933 - val_sdep_func_tf: 4.9259 - 88ms/epoch - 9ms/step\n",
      "Epoch 32/300\n",
      "10/10 - 0s - loss: 46.4512 - mse: 46.4512 - mean_absolute_error: 5.5824 - r2_func_tf: 0.8812 - rmse_func_tf: 6.6695 - bias_func_tf: -5.1119e-01 - sdep_func_tf: 4.7040 - val_loss: 29.4296 - val_mse: 29.4296 - val_mean_absolute_error: 4.0159 - val_r2_func_tf: 0.9243 - val_rmse_func_tf: 5.3889 - val_bias_func_tf: -5.8950e-01 - val_sdep_func_tf: 4.9575 - 90ms/epoch - 9ms/step\n",
      "Epoch 33/300\n",
      "10/10 - 0s - loss: 64.8729 - mse: 64.8729 - mean_absolute_error: 6.3137 - r2_func_tf: 0.5945 - rmse_func_tf: 8.2632 - bias_func_tf: 1.3819 - sdep_func_tf: 5.2459 - val_loss: 29.2451 - val_mse: 29.2451 - val_mean_absolute_error: 4.0074 - val_r2_func_tf: 0.9233 - val_rmse_func_tf: 5.3708 - val_bias_func_tf: -3.7656e-01 - val_sdep_func_tf: 4.9630 - 89ms/epoch - 9ms/step\n",
      "Epoch 34/300\n",
      "10/10 - 0s - loss: 51.9745 - mse: 51.9745 - mean_absolute_error: 5.4107 - r2_func_tf: 0.7896 - rmse_func_tf: 7.2838 - bias_func_tf: 0.8832 - sdep_func_tf: 5.1383 - val_loss: 34.0474 - val_mse: 34.0474 - val_mean_absolute_error: 4.4104 - val_r2_func_tf: 0.9229 - val_rmse_func_tf: 5.7741 - val_bias_func_tf: -2.1214e+00 - val_sdep_func_tf: 5.0041 - 90ms/epoch - 9ms/step\n",
      "Epoch 35/300\n",
      "10/10 - 0s - loss: 48.7145 - mse: 48.7145 - mean_absolute_error: 5.3867 - r2_func_tf: 0.8617 - rmse_func_tf: 6.8256 - bias_func_tf: -1.7495e+00 - sdep_func_tf: 5.0136 - val_loss: 35.2781 - val_mse: 35.2781 - val_mean_absolute_error: 4.5385 - val_r2_func_tf: 0.9217 - val_rmse_func_tf: 5.8664 - val_bias_func_tf: -2.4822e+00 - val_sdep_func_tf: 4.9690 - 92ms/epoch - 9ms/step\n",
      "Epoch 36/300\n",
      "10/10 - 0s - loss: 59.1519 - mse: 59.1519 - mean_absolute_error: 5.9758 - r2_func_tf: 0.6085 - rmse_func_tf: 6.9625 - bias_func_tf: -2.1556e-01 - sdep_func_tf: 4.9824 - val_loss: 28.5316 - val_mse: 28.5316 - val_mean_absolute_error: 3.9197 - val_r2_func_tf: 0.9252 - val_rmse_func_tf: 5.2889 - val_bias_func_tf: -3.5861e-01 - val_sdep_func_tf: 4.8999 - 93ms/epoch - 9ms/step\n",
      "Epoch 37/300\n",
      "10/10 - 0s - loss: 33.4118 - mse: 33.4118 - mean_absolute_error: 4.5926 - r2_func_tf: 0.9272 - rmse_func_tf: 5.6911 - bias_func_tf: 0.0882 - sdep_func_tf: 4.6330 - val_loss: 29.5234 - val_mse: 29.5234 - val_mean_absolute_error: 3.9960 - val_r2_func_tf: 0.9247 - val_rmse_func_tf: 5.3923 - val_bias_func_tf: -7.5885e-01 - val_sdep_func_tf: 4.9511 - 93ms/epoch - 9ms/step\n",
      "Epoch 38/300\n",
      "10/10 - 0s - loss: 57.2949 - mse: 57.2949 - mean_absolute_error: 5.8897 - r2_func_tf: 0.8696 - rmse_func_tf: 6.8506 - bias_func_tf: -4.9311e-01 - sdep_func_tf: 4.6545 - val_loss: 36.7832 - val_mse: 36.7832 - val_mean_absolute_error: 4.5866 - val_r2_func_tf: 0.9181 - val_rmse_func_tf: 6.0014 - val_bias_func_tf: -2.5389e+00 - val_sdep_func_tf: 5.0792 - 108ms/epoch - 11ms/step\n",
      "Epoch 39/300\n",
      "10/10 - 0s - loss: 44.0928 - mse: 44.0928 - mean_absolute_error: 5.1903 - r2_func_tf: -5.3535e-01 - rmse_func_tf: 6.6286 - bias_func_tf: 0.8580 - sdep_func_tf: 4.7500 - val_loss: 31.0617 - val_mse: 31.0617 - val_mean_absolute_error: 4.1075 - val_r2_func_tf: 0.9237 - val_rmse_func_tf: 5.5397 - val_bias_func_tf: -1.2248e+00 - val_sdep_func_tf: 5.0147 - 92ms/epoch - 9ms/step\n",
      "Epoch 40/300\n",
      "10/10 - 0s - loss: 71.2729 - mse: 71.2729 - mean_absolute_error: 6.4435 - r2_func_tf: 0.4356 - rmse_func_tf: 8.1496 - bias_func_tf: 0.5366 - sdep_func_tf: 4.9706 - val_loss: 39.1943 - val_mse: 39.1943 - val_mean_absolute_error: 4.7971 - val_r2_func_tf: 0.9145 - val_rmse_func_tf: 6.1848 - val_bias_func_tf: -2.9351e+00 - val_sdep_func_tf: 5.1070 - 95ms/epoch - 9ms/step\n",
      "Epoch 41/300\n",
      "10/10 - 0s - loss: 55.5396 - mse: 55.5396 - mean_absolute_error: 5.3442 - r2_func_tf: 0.8402 - rmse_func_tf: 6.5618 - bias_func_tf: -1.0872e-01 - sdep_func_tf: 4.7400 - val_loss: 34.5164 - val_mse: 34.5164 - val_mean_absolute_error: 4.4031 - val_r2_func_tf: 0.9216 - val_rmse_func_tf: 5.8225 - val_bias_func_tf: -2.1370e+00 - val_sdep_func_tf: 5.0521 - 95ms/epoch - 9ms/step\n",
      "Epoch 42/300\n",
      "10/10 - 0s - loss: 64.2031 - mse: 64.2031 - mean_absolute_error: 6.4229 - r2_func_tf: 0.5602 - rmse_func_tf: 7.2386 - bias_func_tf: -9.9094e-01 - sdep_func_tf: 4.7989 - val_loss: 38.7698 - val_mse: 38.7698 - val_mean_absolute_error: 4.8078 - val_r2_func_tf: 0.9156 - val_rmse_func_tf: 6.1486 - val_bias_func_tf: -2.9718e+00 - val_sdep_func_tf: 5.0531 - 103ms/epoch - 10ms/step\n",
      "Epoch 43/300\n",
      "10/10 - 0s - loss: 64.7237 - mse: 64.7237 - mean_absolute_error: 6.3157 - r2_func_tf: 0.7131 - rmse_func_tf: 7.5368 - bias_func_tf: 0.2902 - sdep_func_tf: 4.9771 - val_loss: 28.9358 - val_mse: 28.9358 - val_mean_absolute_error: 3.9410 - val_r2_func_tf: 0.9254 - val_rmse_func_tf: 5.3324 - val_bias_func_tf: -6.0881e-01 - val_sdep_func_tf: 4.9276 - 91ms/epoch - 9ms/step\n",
      "Epoch 44/300\n",
      "10/10 - 0s - loss: 72.9946 - mse: 72.9946 - mean_absolute_error: 6.6512 - r2_func_tf: 0.4108 - rmse_func_tf: 8.4860 - bias_func_tf: 1.7979 - sdep_func_tf: 5.1116 - val_loss: 30.1247 - val_mse: 30.1247 - val_mean_absolute_error: 4.0525 - val_r2_func_tf: 0.9248 - val_rmse_func_tf: 5.4475 - val_bias_func_tf: -1.0699e+00 - val_sdep_func_tf: 4.9713 - 92ms/epoch - 9ms/step\n",
      "Epoch 45/300\n",
      "10/10 - 0s - loss: 78.7193 - mse: 78.7193 - mean_absolute_error: 6.4548 - r2_func_tf: 0.7481 - rmse_func_tf: 9.1431 - bias_func_tf: -2.2914e+00 - sdep_func_tf: 5.3453 - val_loss: 42.2929 - val_mse: 42.2929 - val_mean_absolute_error: 5.0602 - val_r2_func_tf: 0.9085 - val_rmse_func_tf: 6.4208 - val_bias_func_tf: -3.3671e+00 - val_sdep_func_tf: 5.1479 - 94ms/epoch - 9ms/step\n",
      "Epoch 46/300\n",
      "10/10 - 0s - loss: 99.5007 - mse: 99.5007 - mean_absolute_error: 7.2969 - r2_func_tf: 0.3855 - rmse_func_tf: 9.4208 - bias_func_tf: 1.4559 - sdep_func_tf: 5.3626 - val_loss: 28.8262 - val_mse: 28.8262 - val_mean_absolute_error: 3.8808 - val_r2_func_tf: 0.9206 - val_rmse_func_tf: 5.3159 - val_bias_func_tf: 0.0180 - val_sdep_func_tf: 4.9673 - 91ms/epoch - 9ms/step\n",
      "Epoch 47/300\n",
      "10/10 - 0s - loss: 57.9103 - mse: 57.9103 - mean_absolute_error: 5.7349 - r2_func_tf: 0.7027 - rmse_func_tf: 7.6038 - bias_func_tf: 0.6638 - sdep_func_tf: 5.3314 - val_loss: 31.5748 - val_mse: 31.5748 - val_mean_absolute_error: 4.1759 - val_r2_func_tf: 0.9228 - val_rmse_func_tf: 5.5777 - val_bias_func_tf: -1.5401e+00 - val_sdep_func_tf: 4.9975 - 92ms/epoch - 9ms/step\n",
      "Epoch 48/300\n",
      "10/10 - 0s - loss: 58.3396 - mse: 58.3396 - mean_absolute_error: 5.6837 - r2_func_tf: 0.8532 - rmse_func_tf: 7.8296 - bias_func_tf: -2.8902e+00 - sdep_func_tf: 5.3341 - val_loss: 35.2395 - val_mse: 35.2395 - val_mean_absolute_error: 4.4789 - val_r2_func_tf: 0.9185 - val_rmse_func_tf: 5.8859 - val_bias_func_tf: -2.3566e+00 - val_sdep_func_tf: 5.0445 - 97ms/epoch - 10ms/step\n",
      "Epoch 49/300\n",
      "10/10 - 0s - loss: 46.4140 - mse: 46.4140 - mean_absolute_error: 5.4563 - r2_func_tf: 0.8773 - rmse_func_tf: 6.6360 - bias_func_tf: -1.8343e-01 - sdep_func_tf: 4.8617 - val_loss: 30.2278 - val_mse: 30.2278 - val_mean_absolute_error: 4.0552 - val_r2_func_tf: 0.9104 - val_rmse_func_tf: 5.4033 - val_bias_func_tf: 1.2978 - val_sdep_func_tf: 4.9340 - 90ms/epoch - 9ms/step\n",
      "Epoch 50/300\n",
      "10/10 - 0s - loss: 63.0405 - mse: 63.0405 - mean_absolute_error: 6.1419 - r2_func_tf: 0.1124 - rmse_func_tf: 7.6697 - bias_func_tf: 0.5543 - sdep_func_tf: 4.9882 - val_loss: 28.9529 - val_mse: 28.9529 - val_mean_absolute_error: 3.9086 - val_r2_func_tf: 0.9170 - val_rmse_func_tf: 5.3041 - val_bias_func_tf: 0.6316 - val_sdep_func_tf: 4.9379 - 88ms/epoch - 9ms/step\n",
      "Epoch 51/300\n",
      "10/10 - 0s - loss: 63.5765 - mse: 63.5765 - mean_absolute_error: 6.2846 - r2_func_tf: 0.6437 - rmse_func_tf: 7.1581 - bias_func_tf: 0.9031 - sdep_func_tf: 4.7364 - val_loss: 28.8405 - val_mse: 28.8405 - val_mean_absolute_error: 3.9063 - val_r2_func_tf: 0.9215 - val_rmse_func_tf: 5.3130 - val_bias_func_tf: -2.7252e-01 - val_sdep_func_tf: 4.9587 - 90ms/epoch - 9ms/step\n",
      "Epoch 52/300\n",
      "10/10 - 0s - loss: 32.5228 - mse: 32.5228 - mean_absolute_error: 4.5338 - r2_func_tf: 0.9232 - rmse_func_tf: 5.7182 - bias_func_tf: 0.4611 - sdep_func_tf: 4.8916 - val_loss: 29.7373 - val_mse: 29.7373 - val_mean_absolute_error: 4.0061 - val_r2_func_tf: 0.9220 - val_rmse_func_tf: 5.4093 - val_bias_func_tf: -7.2516e-01 - val_sdep_func_tf: 5.0046 - 91ms/epoch - 9ms/step\n",
      "Epoch 53/300\n",
      "10/10 - 0s - loss: 48.8069 - mse: 48.8069 - mean_absolute_error: 5.3894 - r2_func_tf: 0.7377 - rmse_func_tf: 6.7919 - bias_func_tf: 0.5906 - sdep_func_tf: 4.8422 - val_loss: 30.2122 - val_mse: 30.2122 - val_mean_absolute_error: 4.0260 - val_r2_func_tf: 0.9239 - val_rmse_func_tf: 5.4542 - val_bias_func_tf: -1.1269e+00 - val_sdep_func_tf: 4.9875 - 88ms/epoch - 9ms/step\n",
      "Epoch 54/300\n",
      "10/10 - 0s - loss: 52.3371 - mse: 52.3371 - mean_absolute_error: 5.7937 - r2_func_tf: 0.7690 - rmse_func_tf: 7.2412 - bias_func_tf: -1.2110e+00 - sdep_func_tf: 4.7885 - val_loss: 32.1046 - val_mse: 32.1046 - val_mean_absolute_error: 4.2309 - val_r2_func_tf: 0.9226 - val_rmse_func_tf: 5.6203 - val_bias_func_tf: -1.7895e+00 - val_sdep_func_tf: 4.9837 - 91ms/epoch - 9ms/step\n",
      "Epoch 55/300\n",
      "10/10 - 0s - loss: 46.4191 - mse: 46.4191 - mean_absolute_error: 5.4809 - r2_func_tf: 0.7368 - rmse_func_tf: 6.6908 - bias_func_tf: 0.1692 - sdep_func_tf: 4.8007 - val_loss: 31.4599 - val_mse: 31.4599 - val_mean_absolute_error: 4.1533 - val_r2_func_tf: 0.9226 - val_rmse_func_tf: 5.5685 - val_bias_func_tf: -1.5334e+00 - val_sdep_func_tf: 5.0089 - 95ms/epoch - 10ms/step\n",
      "Epoch 56/300\n",
      "10/10 - 0s - loss: 48.9614 - mse: 48.9614 - mean_absolute_error: 5.5255 - r2_func_tf: 0.7727 - rmse_func_tf: 6.3116 - bias_func_tf: 0.3176 - sdep_func_tf: 4.4840 - val_loss: 32.3569 - val_mse: 32.3569 - val_mean_absolute_error: 4.2272 - val_r2_func_tf: 0.9208 - val_rmse_func_tf: 5.6481 - val_bias_func_tf: -1.7512e+00 - val_sdep_func_tf: 5.0284 - 89ms/epoch - 9ms/step\n",
      "Epoch 57/300\n",
      "10/10 - 0s - loss: 44.1496 - mse: 44.1496 - mean_absolute_error: 5.1176 - r2_func_tf: 0.8842 - rmse_func_tf: 6.1629 - bias_func_tf: 0.1662 - sdep_func_tf: 4.7932 - val_loss: 33.3929 - val_mse: 33.3929 - val_mean_absolute_error: 4.3150 - val_r2_func_tf: 0.9174 - val_rmse_func_tf: 5.7418 - val_bias_func_tf: -1.8950e+00 - val_sdep_func_tf: 5.0743 - 100ms/epoch - 10ms/step\n",
      "Epoch 58/300\n",
      "10/10 - 0s - loss: 64.3590 - mse: 64.3590 - mean_absolute_error: 6.3478 - r2_func_tf: 0.7292 - rmse_func_tf: 7.7692 - bias_func_tf: -8.9811e-01 - sdep_func_tf: 4.9459 - val_loss: 40.8741 - val_mse: 40.8741 - val_mean_absolute_error: 4.8961 - val_r2_func_tf: 0.9059 - val_rmse_func_tf: 6.3468 - val_bias_func_tf: -3.0469e+00 - val_sdep_func_tf: 5.2395 - 99ms/epoch - 10ms/step\n",
      "Epoch 59/300\n",
      "10/10 - 0s - loss: 43.0255 - mse: 43.0255 - mean_absolute_error: 5.0945 - r2_func_tf: 0.8950 - rmse_func_tf: 6.8526 - bias_func_tf: -6.8040e-01 - sdep_func_tf: 5.0516 - val_loss: 36.7467 - val_mse: 36.7467 - val_mean_absolute_error: 4.4988 - val_r2_func_tf: 0.9136 - val_rmse_func_tf: 6.0236 - val_bias_func_tf: -2.1853e+00 - val_sdep_func_tf: 5.2785 - 92ms/epoch - 9ms/step\n",
      "Epoch 60/300\n",
      "10/10 - 0s - loss: 45.6237 - mse: 45.6237 - mean_absolute_error: 5.3615 - r2_func_tf: 0.7711 - rmse_func_tf: 6.1669 - bias_func_tf: 0.8823 - sdep_func_tf: 4.7715 - val_loss: 31.4253 - val_mse: 31.4253 - val_mean_absolute_error: 4.1124 - val_r2_func_tf: 0.9218 - val_rmse_func_tf: 5.5731 - val_bias_func_tf: -1.1006e+00 - val_sdep_func_tf: 5.1360 - 89ms/epoch - 9ms/step\n",
      "Epoch 61/300\n",
      "10/10 - 0s - loss: 37.6395 - mse: 37.6395 - mean_absolute_error: 4.7090 - r2_func_tf: 0.7816 - rmse_func_tf: 6.2284 - bias_func_tf: 1.3192 - sdep_func_tf: 4.8272 - val_loss: 31.8994 - val_mse: 31.8994 - val_mean_absolute_error: 4.2035 - val_r2_func_tf: 0.9242 - val_rmse_func_tf: 5.6052 - val_bias_func_tf: -1.7373e+00 - val_sdep_func_tf: 5.0135 - 91ms/epoch - 9ms/step\n",
      "Epoch 62/300\n",
      "10/10 - 0s - loss: 40.2666 - mse: 40.2666 - mean_absolute_error: 5.0167 - r2_func_tf: 0.0707 - rmse_func_tf: 6.5439 - bias_func_tf: 0.5203 - sdep_func_tf: 4.8469 - val_loss: 32.3791 - val_mse: 32.3791 - val_mean_absolute_error: 4.2980 - val_r2_func_tf: 0.9244 - val_rmse_func_tf: 5.6392 - val_bias_func_tf: -2.0351e+00 - val_sdep_func_tf: 4.9546 - 93ms/epoch - 9ms/step\n",
      "Epoch 63/300\n",
      "10/10 - 0s - loss: 56.6053 - mse: 56.6053 - mean_absolute_error: 5.6682 - r2_func_tf: 0.7922 - rmse_func_tf: 6.8386 - bias_func_tf: -6.6188e-01 - sdep_func_tf: 4.9473 - val_loss: 36.4919 - val_mse: 36.4919 - val_mean_absolute_error: 4.6690 - val_r2_func_tf: 0.9183 - val_rmse_func_tf: 5.9792 - val_bias_func_tf: -2.7657e+00 - val_sdep_func_tf: 5.0120 - 96ms/epoch - 10ms/step\n",
      "Epoch 64/300\n",
      "10/10 - 0s - loss: 45.5472 - mse: 45.5472 - mean_absolute_error: 5.1268 - r2_func_tf: 0.9034 - rmse_func_tf: 6.3804 - bias_func_tf: -5.2123e-01 - sdep_func_tf: 5.0017 - val_loss: 35.6006 - val_mse: 35.6006 - val_mean_absolute_error: 4.5658 - val_r2_func_tf: 0.9181 - val_rmse_func_tf: 5.9169 - val_bias_func_tf: -2.4724e+00 - val_sdep_func_tf: 5.0626 - 90ms/epoch - 9ms/step\n",
      "Epoch 65/300\n",
      "10/10 - 0s - loss: 46.6280 - mse: 46.6280 - mean_absolute_error: 5.0971 - r2_func_tf: 0.8764 - rmse_func_tf: 7.1835 - bias_func_tf: -1.1552e+00 - sdep_func_tf: 5.2374 - val_loss: 31.1349 - val_mse: 31.1349 - val_mean_absolute_error: 4.1643 - val_r2_func_tf: 0.9244 - val_rmse_func_tf: 5.5383 - val_bias_func_tf: -1.5562e+00 - val_sdep_func_tf: 4.9963 - 88ms/epoch - 9ms/step\n",
      "Epoch 66/300\n",
      "10/10 - 0s - loss: 47.1100 - mse: 47.1100 - mean_absolute_error: 5.1966 - r2_func_tf: 0.7964 - rmse_func_tf: 6.7359 - bias_func_tf: 1.5108 - sdep_func_tf: 4.5340 - val_loss: 29.2216 - val_mse: 29.2216 - val_mean_absolute_error: 3.9962 - val_r2_func_tf: 0.9248 - val_rmse_func_tf: 5.3633 - val_bias_func_tf: -7.8616e-01 - val_sdep_func_tf: 4.9860 - 88ms/epoch - 9ms/step\n",
      "Epoch 67/300\n",
      "10/10 - 0s - loss: 51.0326 - mse: 51.0326 - mean_absolute_error: 5.8078 - r2_func_tf: 0.8170 - rmse_func_tf: 7.0167 - bias_func_tf: -6.2836e-01 - sdep_func_tf: 4.6290 - val_loss: 40.0919 - val_mse: 40.0919 - val_mean_absolute_error: 4.9072 - val_r2_func_tf: 0.9103 - val_rmse_func_tf: 6.2714 - val_bias_func_tf: -3.0983e+00 - val_sdep_func_tf: 5.1509 - 89ms/epoch - 9ms/step\n",
      "Epoch 68/300\n",
      "10/10 - 0s - loss: 46.9321 - mse: 46.9321 - mean_absolute_error: 5.1444 - r2_func_tf: 0.8693 - rmse_func_tf: 6.3338 - bias_func_tf: -9.6624e-03 - sdep_func_tf: 4.9145 - val_loss: 34.9597 - val_mse: 34.9597 - val_mean_absolute_error: 4.4783 - val_r2_func_tf: 0.9184 - val_rmse_func_tf: 5.8689 - val_bias_func_tf: -2.2600e+00 - val_sdep_func_tf: 5.0962 - 89ms/epoch - 9ms/step\n",
      "Epoch 69/300\n",
      "10/10 - 0s - loss: 40.9514 - mse: 40.9514 - mean_absolute_error: 4.9422 - r2_func_tf: 0.8639 - rmse_func_tf: 5.8716 - bias_func_tf: -1.9348e-01 - sdep_func_tf: 4.5574 - val_loss: 35.5541 - val_mse: 35.5541 - val_mean_absolute_error: 4.5271 - val_r2_func_tf: 0.9177 - val_rmse_func_tf: 5.9162 - val_bias_func_tf: -2.4328e+00 - val_sdep_func_tf: 5.0832 - 87ms/epoch - 9ms/step\n",
      "Epoch 70/300\n",
      "10/10 - 0s - loss: 37.7656 - mse: 37.7656 - mean_absolute_error: 4.7254 - r2_func_tf: 0.8486 - rmse_func_tf: 6.0524 - bias_func_tf: 0.6969 - sdep_func_tf: 4.6849 - val_loss: 32.7569 - val_mse: 32.7569 - val_mean_absolute_error: 4.2521 - val_r2_func_tf: 0.9210 - val_rmse_func_tf: 5.6868 - val_bias_func_tf: -1.7680e+00 - val_sdep_func_tf: 5.0905 - 90ms/epoch - 9ms/step\n",
      "Epoch 71/300\n",
      "10/10 - 0s - loss: 44.3956 - mse: 44.3956 - mean_absolute_error: 5.2632 - r2_func_tf: 0.8809 - rmse_func_tf: 6.6541 - bias_func_tf: -4.1599e-01 - sdep_func_tf: 4.7779 - val_loss: 36.2544 - val_mse: 36.2544 - val_mean_absolute_error: 4.5518 - val_r2_func_tf: 0.9163 - val_rmse_func_tf: 5.9772 - val_bias_func_tf: -2.4259e+00 - val_sdep_func_tf: 5.1624 - 89ms/epoch - 9ms/step\n",
      "Epoch 72/300\n",
      "10/10 - 0s - loss: 71.9362 - mse: 71.9362 - mean_absolute_error: 6.5278 - r2_func_tf: 0.4104 - rmse_func_tf: 8.3672 - bias_func_tf: 1.3757 - sdep_func_tf: 5.0785 - val_loss: 34.5266 - val_mse: 34.5266 - val_mean_absolute_error: 4.4149 - val_r2_func_tf: 0.9185 - val_rmse_func_tf: 5.8371 - val_bias_func_tf: -2.1044e+00 - val_sdep_func_tf: 5.1554 - 90ms/epoch - 9ms/step\n",
      "Epoch 73/300\n",
      "10/10 - 0s - loss: 33.4564 - mse: 33.4564 - mean_absolute_error: 4.4729 - r2_func_tf: 0.9203 - rmse_func_tf: 5.3397 - bias_func_tf: -4.0000e-01 - sdep_func_tf: 4.6255 - val_loss: 42.8905 - val_mse: 42.8905 - val_mean_absolute_error: 5.0729 - val_r2_func_tf: 0.9048 - val_rmse_func_tf: 6.4841 - val_bias_func_tf: -3.4323e+00 - val_sdep_func_tf: 5.2500 - 91ms/epoch - 9ms/step\n",
      "Epoch 74/300\n",
      "10/10 - 0s - loss: 57.2939 - mse: 57.2939 - mean_absolute_error: 5.1411 - r2_func_tf: 0.7807 - rmse_func_tf: 7.7658 - bias_func_tf: -2.5680e+00 - sdep_func_tf: 4.9572 - val_loss: 37.1461 - val_mse: 37.1461 - val_mean_absolute_error: 4.6562 - val_r2_func_tf: 0.9156 - val_rmse_func_tf: 6.0399 - val_bias_func_tf: -2.7711e+00 - val_sdep_func_tf: 5.1130 - 86ms/epoch - 9ms/step\n",
      "Epoch 75/300\n",
      "10/10 - 0s - loss: 37.5564 - mse: 37.5564 - mean_absolute_error: 4.6193 - r2_func_tf: 0.8477 - rmse_func_tf: 6.4418 - bias_func_tf: -4.4343e-01 - sdep_func_tf: 4.6881 - val_loss: 28.1710 - val_mse: 28.1710 - val_mean_absolute_error: 3.8779 - val_r2_func_tf: 0.9262 - val_rmse_func_tf: 5.2414 - val_bias_func_tf: -1.8820e-01 - val_sdep_func_tf: 4.9840 - 89ms/epoch - 9ms/step\n",
      "Epoch 76/300\n",
      "10/10 - 0s - loss: 48.3609 - mse: 48.3609 - mean_absolute_error: 5.4312 - r2_func_tf: 0.8593 - rmse_func_tf: 6.5154 - bias_func_tf: 1.6805 - sdep_func_tf: 4.9239 - val_loss: 28.6260 - val_mse: 28.6260 - val_mean_absolute_error: 3.9294 - val_r2_func_tf: 0.9210 - val_rmse_func_tf: 5.2750 - val_bias_func_tf: 0.5777 - val_sdep_func_tf: 4.9961 - 86ms/epoch - 9ms/step\n",
      "Epoch 77/300\n",
      "10/10 - 0s - loss: 52.9853 - mse: 52.9853 - mean_absolute_error: 5.5539 - r2_func_tf: 0.8476 - rmse_func_tf: 7.0401 - bias_func_tf: 0.4460 - sdep_func_tf: 4.7774 - val_loss: 29.2757 - val_mse: 29.2757 - val_mean_absolute_error: 3.9959 - val_r2_func_tf: 0.9262 - val_rmse_func_tf: 5.3661 - val_bias_func_tf: -8.9473e-01 - val_sdep_func_tf: 5.0190 - 90ms/epoch - 9ms/step\n",
      "Epoch 78/300\n",
      "10/10 - 0s - loss: 43.1154 - mse: 43.1154 - mean_absolute_error: 5.2127 - r2_func_tf: 0.7577 - rmse_func_tf: 6.3994 - bias_func_tf: 0.7111 - sdep_func_tf: 4.4472 - val_loss: 30.4038 - val_mse: 30.4038 - val_mean_absolute_error: 4.1114 - val_r2_func_tf: 0.9257 - val_rmse_func_tf: 5.4694 - val_bias_func_tf: -1.3799e+00 - val_sdep_func_tf: 5.0212 - 85ms/epoch - 9ms/step\n",
      "Epoch 79/300\n",
      "10/10 - 0s - loss: 53.0862 - mse: 53.0862 - mean_absolute_error: 5.9365 - r2_func_tf: 0.4748 - rmse_func_tf: 7.0244 - bias_func_tf: 0.4608 - sdep_func_tf: 4.5506 - val_loss: 32.0878 - val_mse: 32.0878 - val_mean_absolute_error: 4.2533 - val_r2_func_tf: 0.9233 - val_rmse_func_tf: 5.6185 - val_bias_func_tf: -1.8197e+00 - val_sdep_func_tf: 5.0554 - 85ms/epoch - 9ms/step\n",
      "Epoch 80/300\n",
      "10/10 - 0s - loss: 36.5725 - mse: 36.5725 - mean_absolute_error: 4.6198 - r2_func_tf: 0.9227 - rmse_func_tf: 5.6387 - bias_func_tf: -5.2484e-02 - sdep_func_tf: 4.6201 - val_loss: 32.5351 - val_mse: 32.5351 - val_mean_absolute_error: 4.2961 - val_r2_func_tf: 0.9232 - val_rmse_func_tf: 5.6561 - val_bias_func_tf: -1.9322e+00 - val_sdep_func_tf: 5.0642 - 83ms/epoch - 8ms/step\n",
      "Epoch 81/300\n",
      "10/10 - 0s - loss: 44.2100 - mse: 44.2100 - mean_absolute_error: 5.1887 - r2_func_tf: 0.7695 - rmse_func_tf: 6.4399 - bias_func_tf: 0.0142 - sdep_func_tf: 4.9930 - val_loss: 33.2385 - val_mse: 33.2385 - val_mean_absolute_error: 4.3354 - val_r2_func_tf: 0.9217 - val_rmse_func_tf: 5.7178 - val_bias_func_tf: -2.0198e+00 - val_sdep_func_tf: 5.0974 - 83ms/epoch - 8ms/step\n",
      "Epoch 82/300\n",
      "10/10 - 0s - loss: 55.2367 - mse: 55.2367 - mean_absolute_error: 5.9295 - r2_func_tf: 0.7188 - rmse_func_tf: 7.0833 - bias_func_tf: 0.2124 - sdep_func_tf: 4.6545 - val_loss: 34.1522 - val_mse: 34.1522 - val_mean_absolute_error: 4.4127 - val_r2_func_tf: 0.9201 - val_rmse_func_tf: 5.7935 - val_bias_func_tf: -2.2263e+00 - val_sdep_func_tf: 5.0983 - 82ms/epoch - 8ms/step\n",
      "Epoch 83/300\n",
      "10/10 - 0s - loss: 45.9974 - mse: 45.9974 - mean_absolute_error: 5.3350 - r2_func_tf: 0.8963 - rmse_func_tf: 6.7636 - bias_func_tf: -8.9955e-01 - sdep_func_tf: 5.0186 - val_loss: 35.6835 - val_mse: 35.6835 - val_mean_absolute_error: 4.5396 - val_r2_func_tf: 0.9185 - val_rmse_func_tf: 5.9184 - val_bias_func_tf: -2.5507e+00 - val_sdep_func_tf: 5.0934 - 85ms/epoch - 8ms/step\n",
      "Epoch 84/300\n",
      "10/10 - 0s - loss: 53.9729 - mse: 53.9729 - mean_absolute_error: 5.7564 - r2_func_tf: 0.8256 - rmse_func_tf: 6.9554 - bias_func_tf: -6.0707e-01 - sdep_func_tf: 4.8033 - val_loss: 31.4134 - val_mse: 31.4134 - val_mean_absolute_error: 4.1968 - val_r2_func_tf: 0.9258 - val_rmse_func_tf: 5.5548 - val_bias_func_tf: -1.6621e+00 - val_sdep_func_tf: 5.0454 - 92ms/epoch - 9ms/step\n",
      "Epoch 85/300\n",
      "10/10 - 0s - loss: 46.7882 - mse: 46.7882 - mean_absolute_error: 5.4604 - r2_func_tf: 0.7315 - rmse_func_tf: 6.3631 - bias_func_tf: 0.7679 - sdep_func_tf: 4.5388 - val_loss: 29.3034 - val_mse: 29.3034 - val_mean_absolute_error: 3.9668 - val_r2_func_tf: 0.9283 - val_rmse_func_tf: 5.3583 - val_bias_func_tf: -9.6222e-01 - val_sdep_func_tf: 5.0159 - 99ms/epoch - 10ms/step\n",
      "Epoch 86/300\n",
      "10/10 - 0s - loss: 46.3558 - mse: 46.3558 - mean_absolute_error: 5.0530 - r2_func_tf: 0.7833 - rmse_func_tf: 6.5750 - bias_func_tf: 1.3700 - sdep_func_tf: 5.0271 - val_loss: 29.9026 - val_mse: 29.9026 - val_mean_absolute_error: 4.0166 - val_r2_func_tf: 0.9278 - val_rmse_func_tf: 5.4126 - val_bias_func_tf: -1.2144e+00 - val_sdep_func_tf: 5.0200 - 92ms/epoch - 9ms/step\n",
      "Epoch 87/300\n",
      "10/10 - 0s - loss: 52.0513 - mse: 52.0513 - mean_absolute_error: 5.6383 - r2_func_tf: 0.7525 - rmse_func_tf: 6.7218 - bias_func_tf: 0.1607 - sdep_func_tf: 4.7079 - val_loss: 33.9568 - val_mse: 33.9568 - val_mean_absolute_error: 4.4088 - val_r2_func_tf: 0.9221 - val_rmse_func_tf: 5.7696 - val_bias_func_tf: -2.3151e+00 - val_sdep_func_tf: 5.0361 - 93ms/epoch - 9ms/step\n",
      "Epoch 88/300\n",
      "10/10 - 0s - loss: 62.5510 - mse: 62.5510 - mean_absolute_error: 6.1904 - r2_func_tf: -2.2412e+00 - rmse_func_tf: 7.4627 - bias_func_tf: -1.9060e-01 - sdep_func_tf: 4.6307 - val_loss: 34.7069 - val_mse: 34.7069 - val_mean_absolute_error: 4.4765 - val_r2_func_tf: 0.9200 - val_rmse_func_tf: 5.8345 - val_bias_func_tf: -2.4221e+00 - val_sdep_func_tf: 5.0608 - 93ms/epoch - 9ms/step\n",
      "Epoch 89/300\n",
      "10/10 - 0s - loss: 40.3988 - mse: 40.3988 - mean_absolute_error: 4.7301 - r2_func_tf: 0.7675 - rmse_func_tf: 6.5017 - bias_func_tf: 0.0811 - sdep_func_tf: 4.8869 - val_loss: 35.3929 - val_mse: 35.3929 - val_mean_absolute_error: 4.5194 - val_r2_func_tf: 0.9180 - val_rmse_func_tf: 5.8914 - val_bias_func_tf: -2.5047e+00 - val_sdep_func_tf: 5.0936 - 91ms/epoch - 9ms/step\n",
      "Epoch 90/300\n",
      "10/10 - 0s - loss: 37.0803 - mse: 37.0803 - mean_absolute_error: 4.7204 - r2_func_tf: 0.9094 - rmse_func_tf: 6.0262 - bias_func_tf: 0.5193 - sdep_func_tf: 4.5434 - val_loss: 34.1982 - val_mse: 34.1982 - val_mean_absolute_error: 4.3881 - val_r2_func_tf: 0.9198 - val_rmse_func_tf: 5.7922 - val_bias_func_tf: -2.2227e+00 - val_sdep_func_tf: 5.1150 - 90ms/epoch - 9ms/step\n",
      "Epoch 91/300\n",
      "10/10 - 0s - loss: 49.2061 - mse: 49.2061 - mean_absolute_error: 5.5656 - r2_func_tf: 0.6650 - rmse_func_tf: 6.5291 - bias_func_tf: -5.0126e-01 - sdep_func_tf: 4.5073 - val_loss: 36.8784 - val_mse: 36.8784 - val_mean_absolute_error: 4.6161 - val_r2_func_tf: 0.9152 - val_rmse_func_tf: 6.0148 - val_bias_func_tf: -2.7300e+00 - val_sdep_func_tf: 5.1336 - 90ms/epoch - 9ms/step\n",
      "Epoch 92/300\n",
      "10/10 - 0s - loss: 54.2736 - mse: 54.2736 - mean_absolute_error: 5.8912 - r2_func_tf: 0.8351 - rmse_func_tf: 6.6480 - bias_func_tf: -7.9278e-02 - sdep_func_tf: 4.5209 - val_loss: 34.8864 - val_mse: 34.8864 - val_mean_absolute_error: 4.4374 - val_r2_func_tf: 0.9184 - val_rmse_func_tf: 5.8539 - val_bias_func_tf: -2.2703e+00 - val_sdep_func_tf: 5.1667 - 87ms/epoch - 9ms/step\n",
      "Epoch 93/300\n",
      "10/10 - 0s - loss: 61.1684 - mse: 61.1684 - mean_absolute_error: 5.6876 - r2_func_tf: 0.5690 - rmse_func_tf: 6.8068 - bias_func_tf: 0.1079 - sdep_func_tf: 4.9994 - val_loss: 30.9718 - val_mse: 30.9718 - val_mean_absolute_error: 4.1360 - val_r2_func_tf: 0.9253 - val_rmse_func_tf: 5.5070 - val_bias_func_tf: -1.4304e+00 - val_sdep_func_tf: 5.0924 - 87ms/epoch - 9ms/step\n",
      "Epoch 94/300\n",
      "10/10 - 0s - loss: 34.7858 - mse: 34.7858 - mean_absolute_error: 4.3385 - r2_func_tf: 0.9105 - rmse_func_tf: 6.1902 - bias_func_tf: -1.2750e+00 - sdep_func_tf: 4.8072 - val_loss: 33.1261 - val_mse: 33.1261 - val_mean_absolute_error: 4.3405 - val_r2_func_tf: 0.9236 - val_rmse_func_tf: 5.6973 - val_bias_func_tf: -2.1014e+00 - val_sdep_func_tf: 5.0612 - 91ms/epoch - 9ms/step\n",
      "Epoch 95/300\n",
      "10/10 - 0s - loss: 43.1426 - mse: 43.1426 - mean_absolute_error: 5.1576 - r2_func_tf: 0.6209 - rmse_func_tf: 6.8797 - bias_func_tf: 1.3359 - sdep_func_tf: 4.6242 - val_loss: 28.1286 - val_mse: 28.1286 - val_mean_absolute_error: 3.8658 - val_r2_func_tf: 0.9275 - val_rmse_func_tf: 5.2188 - val_bias_func_tf: -2.8104e-01 - val_sdep_func_tf: 4.9930 - 96ms/epoch - 10ms/step\n",
      "Epoch 96/300\n",
      "10/10 - 0s - loss: 53.2397 - mse: 53.2397 - mean_absolute_error: 5.5819 - r2_func_tf: 0.4108 - rmse_func_tf: 7.3156 - bias_func_tf: 1.3808 - sdep_func_tf: 4.8454 - val_loss: 31.6295 - val_mse: 31.6295 - val_mean_absolute_error: 4.1758 - val_r2_func_tf: 0.9231 - val_rmse_func_tf: 5.5719 - val_bias_func_tf: -1.5805e+00 - val_sdep_func_tf: 5.1115 - 90ms/epoch - 9ms/step\n",
      "Epoch 97/300\n",
      "10/10 - 0s - loss: 47.0501 - mse: 47.0501 - mean_absolute_error: 5.3296 - r2_func_tf: 0.8753 - rmse_func_tf: 6.4133 - bias_func_tf: -1.1782e+00 - sdep_func_tf: 4.5115 - val_loss: 45.5082 - val_mse: 45.5082 - val_mean_absolute_error: 5.2503 - val_r2_func_tf: 0.8980 - val_rmse_func_tf: 6.6835 - val_bias_func_tf: -3.7538e+00 - val_sdep_func_tf: 5.3070 - 88ms/epoch - 9ms/step\n",
      "Epoch 98/300\n",
      "10/10 - 0s - loss: 52.0856 - mse: 52.0856 - mean_absolute_error: 5.4229 - r2_func_tf: 0.8278 - rmse_func_tf: 6.6036 - bias_func_tf: -7.5647e-01 - sdep_func_tf: 4.7104 - val_loss: 34.9050 - val_mse: 34.9050 - val_mean_absolute_error: 4.3858 - val_r2_func_tf: 0.9164 - val_rmse_func_tf: 5.8653 - val_bias_func_tf: -1.9838e+00 - val_sdep_func_tf: 5.2817 - 90ms/epoch - 9ms/step\n",
      "Epoch 99/300\n",
      "10/10 - 0s - loss: 35.0100 - mse: 35.0100 - mean_absolute_error: 4.5284 - r2_func_tf: 0.8988 - rmse_func_tf: 6.1719 - bias_func_tf: -9.0887e-01 - sdep_func_tf: 4.8373 - val_loss: 31.0827 - val_mse: 31.0827 - val_mean_absolute_error: 4.0539 - val_r2_func_tf: 0.9223 - val_rmse_func_tf: 5.5129 - val_bias_func_tf: -1.1019e+00 - val_sdep_func_tf: 5.1864 - 91ms/epoch - 9ms/step\n",
      "Epoch 100/300\n",
      "10/10 - 0s - loss: 35.7461 - mse: 35.7461 - mean_absolute_error: 4.5337 - r2_func_tf: 0.9011 - rmse_func_tf: 6.1065 - bias_func_tf: 0.0703 - sdep_func_tf: 4.9043 - val_loss: 29.3828 - val_mse: 29.3828 - val_mean_absolute_error: 3.9840 - val_r2_func_tf: 0.9231 - val_rmse_func_tf: 5.3218 - val_bias_func_tf: -7.6706e-02 - val_sdep_func_tf: 5.1295 - 97ms/epoch - 10ms/step\n",
      "Epoch 101/300\n",
      "10/10 - 0s - loss: 45.4688 - mse: 45.4688 - mean_absolute_error: 5.2660 - r2_func_tf: 0.8208 - rmse_func_tf: 6.9855 - bias_func_tf: -3.8641e-01 - sdep_func_tf: 4.8212 - val_loss: 29.5440 - val_mse: 29.5440 - val_mean_absolute_error: 3.9860 - val_r2_func_tf: 0.9242 - val_rmse_func_tf: 5.3494 - val_bias_func_tf: -5.6243e-01 - val_sdep_func_tf: 5.1162 - 94ms/epoch - 9ms/step\n",
      "Epoch 102/300\n",
      "10/10 - 0s - loss: 57.2559 - mse: 57.2559 - mean_absolute_error: 5.6252 - r2_func_tf: 0.8160 - rmse_func_tf: 7.6832 - bias_func_tf: -1.6886e-01 - sdep_func_tf: 5.5256 - val_loss: 30.2431 - val_mse: 30.2431 - val_mean_absolute_error: 4.0635 - val_r2_func_tf: 0.9223 - val_rmse_func_tf: 5.4282 - val_bias_func_tf: -8.1299e-01 - val_sdep_func_tf: 5.1560 - 90ms/epoch - 9ms/step\n",
      "Epoch 103/300\n",
      "10/10 - 0s - loss: 48.3797 - mse: 48.3797 - mean_absolute_error: 5.6717 - r2_func_tf: 0.7747 - rmse_func_tf: 7.0353 - bias_func_tf: 1.6138 - sdep_func_tf: 4.4970 - val_loss: 29.7873 - val_mse: 29.7873 - val_mean_absolute_error: 4.0693 - val_r2_func_tf: 0.9196 - val_rmse_func_tf: 5.3273 - val_bias_func_tf: 0.4972 - val_sdep_func_tf: 5.1350 - 93ms/epoch - 9ms/step\n",
      "Epoch 104/300\n",
      "10/10 - 0s - loss: 37.8000 - mse: 37.8000 - mean_absolute_error: 4.8183 - r2_func_tf: 0.8065 - rmse_func_tf: 5.7680 - bias_func_tf: 1.1158 - sdep_func_tf: 4.6676 - val_loss: 29.7053 - val_mse: 29.7053 - val_mean_absolute_error: 4.0205 - val_r2_func_tf: 0.9243 - val_rmse_func_tf: 5.3484 - val_bias_func_tf: -6.6757e-01 - val_sdep_func_tf: 5.1163 - 99ms/epoch - 10ms/step\n",
      "Epoch 105/300\n",
      "10/10 - 0s - loss: 43.2346 - mse: 43.2346 - mean_absolute_error: 5.2966 - r2_func_tf: 0.8915 - rmse_func_tf: 6.0483 - bias_func_tf: 0.0359 - sdep_func_tf: 4.3029 - val_loss: 32.5583 - val_mse: 32.5583 - val_mean_absolute_error: 4.2496 - val_r2_func_tf: 0.9206 - val_rmse_func_tf: 5.6404 - val_bias_func_tf: -1.7950e+00 - val_sdep_func_tf: 5.1295 - 89ms/epoch - 9ms/step\n",
      "Epoch 106/300\n",
      "10/10 - 0s - loss: 47.2386 - mse: 47.2386 - mean_absolute_error: 5.0612 - r2_func_tf: 0.6944 - rmse_func_tf: 6.9553 - bias_func_tf: 0.6151 - sdep_func_tf: 4.4566 - val_loss: 31.6490 - val_mse: 31.6490 - val_mean_absolute_error: 4.1391 - val_r2_func_tf: 0.9218 - val_rmse_func_tf: 5.5469 - val_bias_func_tf: -1.5323e+00 - val_sdep_func_tf: 5.1231 - 88ms/epoch - 9ms/step\n",
      "Epoch 107/300\n",
      "10/10 - 0s - loss: 40.3994 - mse: 40.3994 - mean_absolute_error: 4.8081 - r2_func_tf: 0.8501 - rmse_func_tf: 6.4302 - bias_func_tf: 0.1214 - sdep_func_tf: 5.0278 - val_loss: 32.7402 - val_mse: 32.7402 - val_mean_absolute_error: 4.2630 - val_r2_func_tf: 0.9208 - val_rmse_func_tf: 5.6558 - val_bias_func_tf: -1.8920e+00 - val_sdep_func_tf: 5.1106 - 85ms/epoch - 9ms/step\n",
      "Epoch 108/300\n",
      "10/10 - 0s - loss: 55.4199 - mse: 55.4199 - mean_absolute_error: 5.8542 - r2_func_tf: 0.7480 - rmse_func_tf: 7.1738 - bias_func_tf: -1.2960e+00 - sdep_func_tf: 4.9030 - val_loss: 36.6717 - val_mse: 36.6717 - val_mean_absolute_error: 4.6200 - val_r2_func_tf: 0.9134 - val_rmse_func_tf: 6.0014 - val_bias_func_tf: -2.6776e+00 - val_sdep_func_tf: 5.1438 - 86ms/epoch - 9ms/step\n",
      "Epoch 109/300\n",
      "10/10 - 0s - loss: 49.0273 - mse: 49.0273 - mean_absolute_error: 5.0599 - r2_func_tf: 0.8690 - rmse_func_tf: 6.2184 - bias_func_tf: -3.5278e-01 - sdep_func_tf: 4.8047 - val_loss: 31.2356 - val_mse: 31.2356 - val_mean_absolute_error: 4.1428 - val_r2_func_tf: 0.9212 - val_rmse_func_tf: 5.5224 - val_bias_func_tf: -1.2593e+00 - val_sdep_func_tf: 5.1618 - 92ms/epoch - 9ms/step\n",
      "Epoch 110/300\n",
      "10/10 - 0s - loss: 36.1540 - mse: 36.1540 - mean_absolute_error: 4.6978 - r2_func_tf: 0.8488 - rmse_func_tf: 5.6014 - bias_func_tf: 0.1565 - sdep_func_tf: 4.8500 - val_loss: 30.8980 - val_mse: 30.8980 - val_mean_absolute_error: 4.1075 - val_r2_func_tf: 0.9213 - val_rmse_func_tf: 5.4928 - val_bias_func_tf: -1.0868e+00 - val_sdep_func_tf: 5.1704 - 88ms/epoch - 9ms/step\n",
      "Epoch 111/300\n",
      "10/10 - 0s - loss: 53.3626 - mse: 53.3626 - mean_absolute_error: 5.7658 - r2_func_tf: 0.3374 - rmse_func_tf: 7.4013 - bias_func_tf: 0.9189 - sdep_func_tf: 4.7789 - val_loss: 30.7823 - val_mse: 30.7823 - val_mean_absolute_error: 4.0992 - val_r2_func_tf: 0.9222 - val_rmse_func_tf: 5.4728 - val_bias_func_tf: -1.2357e+00 - val_sdep_func_tf: 5.1241 - 92ms/epoch - 9ms/step\n",
      "Epoch 112/300\n",
      "10/10 - 0s - loss: 35.2050 - mse: 35.2050 - mean_absolute_error: 4.6740 - r2_func_tf: 0.7560 - rmse_func_tf: 5.7490 - bias_func_tf: -1.5876e-01 - sdep_func_tf: 4.4471 - val_loss: 32.5787 - val_mse: 32.5787 - val_mean_absolute_error: 4.2757 - val_r2_func_tf: 0.9187 - val_rmse_func_tf: 5.6414 - val_bias_func_tf: -1.7423e+00 - val_sdep_func_tf: 5.1624 - 86ms/epoch - 9ms/step\n",
      "Epoch 113/300\n",
      "10/10 - 0s - loss: 35.7910 - mse: 35.7910 - mean_absolute_error: 4.8187 - r2_func_tf: 0.8748 - rmse_func_tf: 5.9592 - bias_func_tf: -8.4009e-01 - sdep_func_tf: 4.6445 - val_loss: 33.2224 - val_mse: 33.2224 - val_mean_absolute_error: 4.3206 - val_r2_func_tf: 0.9172 - val_rmse_func_tf: 5.6924 - val_bias_func_tf: -1.8655e+00 - val_sdep_func_tf: 5.1821 - 87ms/epoch - 9ms/step\n",
      "Epoch 114/300\n",
      "10/10 - 0s - loss: 38.4497 - mse: 38.4497 - mean_absolute_error: 4.8388 - r2_func_tf: 0.9034 - rmse_func_tf: 5.9864 - bias_func_tf: -5.7517e-01 - sdep_func_tf: 4.5757 - val_loss: 31.7910 - val_mse: 31.7910 - val_mean_absolute_error: 4.1487 - val_r2_func_tf: 0.9195 - val_rmse_func_tf: 5.5599 - val_bias_func_tf: -1.3542e+00 - val_sdep_func_tf: 5.2068 - 87ms/epoch - 9ms/step\n",
      "Epoch 115/300\n",
      "10/10 - 0s - loss: 40.1803 - mse: 40.1803 - mean_absolute_error: 5.1246 - r2_func_tf: 0.9060 - rmse_func_tf: 5.8100 - bias_func_tf: 0.2246 - sdep_func_tf: 4.5253 - val_loss: 31.0069 - val_mse: 31.0069 - val_mean_absolute_error: 4.1010 - val_r2_func_tf: 0.9213 - val_rmse_func_tf: 5.4888 - val_bias_func_tf: -1.1154e+00 - val_sdep_func_tf: 5.1911 - 87ms/epoch - 9ms/step\n",
      "Epoch 116/300\n",
      "10/10 - 0s - loss: 43.7010 - mse: 43.7010 - mean_absolute_error: 5.1783 - r2_func_tf: 0.7844 - rmse_func_tf: 6.8813 - bias_func_tf: 1.4412 - sdep_func_tf: 4.6542 - val_loss: 30.1743 - val_mse: 30.1743 - val_mean_absolute_error: 4.0614 - val_r2_func_tf: 0.9233 - val_rmse_func_tf: 5.3993 - val_bias_func_tf: -9.7034e-01 - val_sdep_func_tf: 5.1315 - 89ms/epoch - 9ms/step\n",
      "Epoch 117/300\n",
      "10/10 - 0s - loss: 62.7276 - mse: 62.7276 - mean_absolute_error: 6.1166 - r2_func_tf: 0.7708 - rmse_func_tf: 7.2553 - bias_func_tf: -3.1542e-01 - sdep_func_tf: 5.1146 - val_loss: 31.6003 - val_mse: 31.6003 - val_mean_absolute_error: 4.1977 - val_r2_func_tf: 0.9228 - val_rmse_func_tf: 5.5399 - val_bias_func_tf: -1.7127e+00 - val_sdep_func_tf: 5.0694 - 89ms/epoch - 9ms/step\n",
      "Epoch 118/300\n",
      "10/10 - 0s - loss: 45.4294 - mse: 45.4294 - mean_absolute_error: 4.8567 - r2_func_tf: 0.8845 - rmse_func_tf: 6.7025 - bias_func_tf: -1.0485e+00 - sdep_func_tf: 5.3430 - val_loss: 32.6322 - val_mse: 32.6322 - val_mean_absolute_error: 4.2645 - val_r2_func_tf: 0.9212 - val_rmse_func_tf: 5.6440 - val_bias_func_tf: -1.9044e+00 - val_sdep_func_tf: 5.1083 - 89ms/epoch - 9ms/step\n",
      "Epoch 119/300\n",
      "10/10 - 0s - loss: 32.7931 - mse: 32.7931 - mean_absolute_error: 4.4559 - r2_func_tf: 0.9157 - rmse_func_tf: 5.7470 - bias_func_tf: -5.9672e-01 - sdep_func_tf: 4.7820 - val_loss: 30.3899 - val_mse: 30.3899 - val_mean_absolute_error: 4.0143 - val_r2_func_tf: 0.9245 - val_rmse_func_tf: 5.4258 - val_bias_func_tf: -1.0359e+00 - val_sdep_func_tf: 5.1340 - 91ms/epoch - 9ms/step\n",
      "Epoch 120/300\n",
      "10/10 - 0s - loss: 33.1788 - mse: 33.1788 - mean_absolute_error: 4.5586 - r2_func_tf: 0.8763 - rmse_func_tf: 5.7600 - bias_func_tf: 0.6218 - sdep_func_tf: 4.4473 - val_loss: 29.6840 - val_mse: 29.6840 - val_mean_absolute_error: 3.9758 - val_r2_func_tf: 0.9230 - val_rmse_func_tf: 5.3603 - val_bias_func_tf: -4.0247e-01 - val_sdep_func_tf: 5.1544 - 87ms/epoch - 9ms/step\n",
      "Epoch 121/300\n",
      "10/10 - 0s - loss: 49.4781 - mse: 49.4781 - mean_absolute_error: 5.1703 - r2_func_tf: 0.8369 - rmse_func_tf: 7.3705 - bias_func_tf: -1.1794e+00 - sdep_func_tf: 5.1229 - val_loss: 30.4724 - val_mse: 30.4724 - val_mean_absolute_error: 4.0249 - val_r2_func_tf: 0.9228 - val_rmse_func_tf: 5.4463 - val_bias_func_tf: -8.9141e-01 - val_sdep_func_tf: 5.1731 - 89ms/epoch - 9ms/step\n",
      "Epoch 122/300\n",
      "10/10 - 0s - loss: 44.1473 - mse: 44.1473 - mean_absolute_error: 5.3497 - r2_func_tf: 0.8381 - rmse_func_tf: 6.2785 - bias_func_tf: 0.5995 - sdep_func_tf: 4.7322 - val_loss: 29.4136 - val_mse: 29.4136 - val_mean_absolute_error: 3.9690 - val_r2_func_tf: 0.9223 - val_rmse_func_tf: 5.3170 - val_bias_func_tf: 0.1454 - val_sdep_func_tf: 5.1312 - 86ms/epoch - 9ms/step\n",
      "Epoch 123/300\n",
      "10/10 - 0s - loss: 42.3124 - mse: 42.3124 - mean_absolute_error: 4.9583 - r2_func_tf: 0.8739 - rmse_func_tf: 6.1773 - bias_func_tf: 1.1239 - sdep_func_tf: 4.9231 - val_loss: 29.2876 - val_mse: 29.2876 - val_mean_absolute_error: 3.9448 - val_r2_func_tf: 0.9245 - val_rmse_func_tf: 5.3212 - val_bias_func_tf: -3.1179e-01 - val_sdep_func_tf: 5.1155 - 85ms/epoch - 9ms/step\n",
      "Epoch 124/300\n",
      "10/10 - 0s - loss: 36.1948 - mse: 36.1948 - mean_absolute_error: 4.7342 - r2_func_tf: 0.8422 - rmse_func_tf: 5.8683 - bias_func_tf: 0.2226 - sdep_func_tf: 4.7696 - val_loss: 29.7830 - val_mse: 29.7830 - val_mean_absolute_error: 3.9995 - val_r2_func_tf: 0.9258 - val_rmse_func_tf: 5.3769 - val_bias_func_tf: -9.8661e-01 - val_sdep_func_tf: 5.0766 - 89ms/epoch - 9ms/step\n",
      "Epoch 125/300\n",
      "10/10 - 0s - loss: 34.9061 - mse: 34.9061 - mean_absolute_error: 4.6472 - r2_func_tf: 0.9219 - rmse_func_tf: 5.5087 - bias_func_tf: 0.0223 - sdep_func_tf: 4.4555 - val_loss: 29.8853 - val_mse: 29.8853 - val_mean_absolute_error: 3.9912 - val_r2_func_tf: 0.9262 - val_rmse_func_tf: 5.3755 - val_bias_func_tf: -1.1047e+00 - val_sdep_func_tf: 5.0595 - 90ms/epoch - 9ms/step\n",
      "Epoch 126/300\n",
      "10/10 - 0s - loss: 55.6984 - mse: 55.6984 - mean_absolute_error: 5.0416 - r2_func_tf: 0.8025 - rmse_func_tf: 7.6477 - bias_func_tf: -2.1508e+00 - sdep_func_tf: 5.3699 - val_loss: 30.3695 - val_mse: 30.3695 - val_mean_absolute_error: 4.0415 - val_r2_func_tf: 0.9252 - val_rmse_func_tf: 5.4197 - val_bias_func_tf: -1.3304e+00 - val_sdep_func_tf: 5.0525 - 92ms/epoch - 9ms/step\n",
      "Epoch 127/300\n",
      "10/10 - 0s - loss: 37.7090 - mse: 37.7090 - mean_absolute_error: 4.7447 - r2_func_tf: 0.9124 - rmse_func_tf: 5.7040 - bias_func_tf: 0.4682 - sdep_func_tf: 4.7436 - val_loss: 31.9989 - val_mse: 31.9989 - val_mean_absolute_error: 4.1550 - val_r2_func_tf: 0.9133 - val_rmse_func_tf: 5.4812 - val_bias_func_tf: 1.4912 - val_sdep_func_tf: 5.0895 - 104ms/epoch - 10ms/step\n",
      "Epoch 128/300\n",
      "10/10 - 0s - loss: 42.8210 - mse: 42.8210 - mean_absolute_error: 5.1014 - r2_func_tf: 0.8550 - rmse_func_tf: 6.4350 - bias_func_tf: 1.7041 - sdep_func_tf: 4.6502 - val_loss: 33.0359 - val_mse: 33.0359 - val_mean_absolute_error: 4.2391 - val_r2_func_tf: 0.9094 - val_rmse_func_tf: 5.5802 - val_bias_func_tf: 1.7178 - val_sdep_func_tf: 5.1153 - 113ms/epoch - 11ms/step\n",
      "Epoch 129/300\n",
      "10/10 - 0s - loss: 28.0627 - mse: 28.0627 - mean_absolute_error: 4.0668 - r2_func_tf: 0.6188 - rmse_func_tf: 5.0970 - bias_func_tf: 0.8666 - sdep_func_tf: 4.4960 - val_loss: 29.2599 - val_mse: 29.2599 - val_mean_absolute_error: 3.9292 - val_r2_func_tf: 0.9227 - val_rmse_func_tf: 5.2614 - val_bias_func_tf: 0.4942 - val_sdep_func_tf: 5.0524 - 105ms/epoch - 10ms/step\n",
      "Epoch 130/300\n",
      "10/10 - 0s - loss: 32.7427 - mse: 32.7427 - mean_absolute_error: 4.3263 - r2_func_tf: 0.9231 - rmse_func_tf: 5.6315 - bias_func_tf: 0.1539 - sdep_func_tf: 4.6660 - val_loss: 28.7036 - val_mse: 28.7036 - val_mean_absolute_error: 3.8916 - val_r2_func_tf: 0.9262 - val_rmse_func_tf: 5.2371 - val_bias_func_tf: -1.5129e-01 - val_sdep_func_tf: 5.0423 - 89ms/epoch - 9ms/step\n",
      "Epoch 131/300\n",
      "10/10 - 0s - loss: 30.8127 - mse: 30.8127 - mean_absolute_error: 4.3288 - r2_func_tf: 0.8133 - rmse_func_tf: 5.7548 - bias_func_tf: 0.3745 - sdep_func_tf: 4.9859 - val_loss: 28.7792 - val_mse: 28.7792 - val_mean_absolute_error: 3.8977 - val_r2_func_tf: 0.9261 - val_rmse_func_tf: 5.2518 - val_bias_func_tf: -3.7540e-01 - val_sdep_func_tf: 5.0442 - 86ms/epoch - 9ms/step\n",
      "Epoch 132/300\n",
      "10/10 - 0s - loss: 28.7209 - mse: 28.7209 - mean_absolute_error: 4.2418 - r2_func_tf: 0.9309 - rmse_func_tf: 5.4597 - bias_func_tf: -9.5026e-01 - sdep_func_tf: 4.6472 - val_loss: 30.0603 - val_mse: 30.0603 - val_mean_absolute_error: 4.0384 - val_r2_func_tf: 0.9248 - val_rmse_func_tf: 5.4042 - val_bias_func_tf: -1.1792e+00 - val_sdep_func_tf: 5.0718 - 94ms/epoch - 9ms/step\n",
      "Epoch 133/300\n",
      "10/10 - 0s - loss: 65.4432 - mse: 65.4432 - mean_absolute_error: 6.2657 - r2_func_tf: 0.7470 - rmse_func_tf: 7.2389 - bias_func_tf: -1.0356e-01 - sdep_func_tf: 4.6880 - val_loss: 29.5635 - val_mse: 29.5635 - val_mean_absolute_error: 3.9895 - val_r2_func_tf: 0.9242 - val_rmse_func_tf: 5.3527 - val_bias_func_tf: -7.3745e-01 - val_sdep_func_tf: 5.1128 - 86ms/epoch - 9ms/step\n",
      "Epoch 134/300\n",
      "10/10 - 0s - loss: 40.6831 - mse: 40.6831 - mean_absolute_error: 5.0997 - r2_func_tf: 0.7464 - rmse_func_tf: 6.3161 - bias_func_tf: 0.3969 - sdep_func_tf: 4.5431 - val_loss: 29.2400 - val_mse: 29.2400 - val_mean_absolute_error: 3.9486 - val_r2_func_tf: 0.9239 - val_rmse_func_tf: 5.3058 - val_bias_func_tf: -2.3877e-01 - val_sdep_func_tf: 5.1252 - 90ms/epoch - 9ms/step\n",
      "Epoch 135/300\n",
      "10/10 - 0s - loss: 55.2924 - mse: 55.2924 - mean_absolute_error: 5.8209 - r2_func_tf: 0.6049 - rmse_func_tf: 6.7976 - bias_func_tf: 0.1126 - sdep_func_tf: 4.5509 - val_loss: 28.8935 - val_mse: 28.8935 - val_mean_absolute_error: 3.9187 - val_r2_func_tf: 0.9262 - val_rmse_func_tf: 5.2668 - val_bias_func_tf: -4.5302e-01 - val_sdep_func_tf: 5.0764 - 88ms/epoch - 9ms/step\n",
      "Epoch 136/300\n",
      "10/10 - 0s - loss: 42.9988 - mse: 42.9988 - mean_absolute_error: 5.1045 - r2_func_tf: 0.8813 - rmse_func_tf: 6.6629 - bias_func_tf: -1.1620e+00 - sdep_func_tf: 4.4462 - val_loss: 30.6547 - val_mse: 30.6547 - val_mean_absolute_error: 4.0828 - val_r2_func_tf: 0.9250 - val_rmse_func_tf: 5.4638 - val_bias_func_tf: -1.3877e+00 - val_sdep_func_tf: 5.0941 - 93ms/epoch - 9ms/step\n",
      "Epoch 137/300\n",
      "10/10 - 0s - loss: 26.4107 - mse: 26.4107 - mean_absolute_error: 4.0818 - r2_func_tf: 0.5763 - rmse_func_tf: 5.1672 - bias_func_tf: 0.3525 - sdep_func_tf: 4.5883 - val_loss: 30.0097 - val_mse: 30.0097 - val_mean_absolute_error: 4.0141 - val_r2_func_tf: 0.9237 - val_rmse_func_tf: 5.4042 - val_bias_func_tf: -8.1543e-01 - val_sdep_func_tf: 5.1500 - 92ms/epoch - 9ms/step\n",
      "Epoch 138/300\n",
      "10/10 - 0s - loss: 43.7416 - mse: 43.7416 - mean_absolute_error: 5.1493 - r2_func_tf: 0.8361 - rmse_func_tf: 6.0948 - bias_func_tf: 0.3567 - sdep_func_tf: 4.6427 - val_loss: 29.9016 - val_mse: 29.9016 - val_mean_absolute_error: 3.9955 - val_r2_func_tf: 0.9243 - val_rmse_func_tf: 5.3907 - val_bias_func_tf: -7.4840e-01 - val_sdep_func_tf: 5.1471 - 90ms/epoch - 9ms/step\n",
      "Epoch 139/300\n",
      "10/10 - 0s - loss: 28.9139 - mse: 28.9139 - mean_absolute_error: 4.2446 - r2_func_tf: 0.8606 - rmse_func_tf: 5.0923 - bias_func_tf: 0.3787 - sdep_func_tf: 4.3005 - val_loss: 29.5942 - val_mse: 29.5942 - val_mean_absolute_error: 3.9807 - val_r2_func_tf: 0.9255 - val_rmse_func_tf: 5.3600 - val_bias_func_tf: -7.6311e-01 - val_sdep_func_tf: 5.1120 - 87ms/epoch - 9ms/step\n",
      "Epoch 140/300\n",
      "10/10 - 0s - loss: 31.5975 - mse: 31.5975 - mean_absolute_error: 4.4389 - r2_func_tf: 0.9208 - rmse_func_tf: 5.4517 - bias_func_tf: -1.2133e-01 - sdep_func_tf: 4.3008 - val_loss: 29.8652 - val_mse: 29.8652 - val_mean_absolute_error: 4.0221 - val_r2_func_tf: 0.9261 - val_rmse_func_tf: 5.3861 - val_bias_func_tf: -1.0895e+00 - val_sdep_func_tf: 5.0777 - 87ms/epoch - 9ms/step\n",
      "Epoch 141/300\n",
      "10/10 - 0s - loss: 39.8068 - mse: 39.8068 - mean_absolute_error: 4.9535 - r2_func_tf: 0.8543 - rmse_func_tf: 6.3193 - bias_func_tf: -6.7122e-01 - sdep_func_tf: 4.8706 - val_loss: 30.4808 - val_mse: 30.4808 - val_mean_absolute_error: 4.0773 - val_r2_func_tf: 0.9254 - val_rmse_func_tf: 5.4438 - val_bias_func_tf: -1.3648e+00 - val_sdep_func_tf: 5.0745 - 87ms/epoch - 9ms/step\n",
      "Epoch 142/300\n",
      "10/10 - 0s - loss: 34.3503 - mse: 34.3503 - mean_absolute_error: 4.8020 - r2_func_tf: 0.8892 - rmse_func_tf: 6.0502 - bias_func_tf: 0.7535 - sdep_func_tf: 4.3949 - val_loss: 29.0512 - val_mse: 29.0512 - val_mean_absolute_error: 3.9371 - val_r2_func_tf: 0.9263 - val_rmse_func_tf: 5.2860 - val_bias_func_tf: -5.7751e-01 - val_sdep_func_tf: 5.0781 - 86ms/epoch - 9ms/step\n",
      "Epoch 143/300\n",
      "10/10 - 0s - loss: 39.0493 - mse: 39.0493 - mean_absolute_error: 4.9930 - r2_func_tf: 0.4473 - rmse_func_tf: 6.2856 - bias_func_tf: 1.0924 - sdep_func_tf: 4.8143 - val_loss: 29.1252 - val_mse: 29.1252 - val_mean_absolute_error: 3.9344 - val_r2_func_tf: 0.9265 - val_rmse_func_tf: 5.2919 - val_bias_func_tf: -6.2058e-01 - val_sdep_func_tf: 5.0804 - 93ms/epoch - 9ms/step\n",
      "Epoch 144/300\n",
      "10/10 - 0s - loss: 46.3181 - mse: 46.3181 - mean_absolute_error: 5.3354 - r2_func_tf: 0.8978 - rmse_func_tf: 6.3550 - bias_func_tf: -3.8801e-01 - sdep_func_tf: 4.6201 - val_loss: 33.4175 - val_mse: 33.4175 - val_mean_absolute_error: 4.3093 - val_r2_func_tf: 0.9207 - val_rmse_func_tf: 5.7213 - val_bias_func_tf: -2.0558e+00 - val_sdep_func_tf: 5.1381 - 90ms/epoch - 9ms/step\n",
      "Epoch 145/300\n",
      "10/10 - 0s - loss: 35.2160 - mse: 35.2160 - mean_absolute_error: 4.6576 - r2_func_tf: 0.8759 - rmse_func_tf: 5.8114 - bias_func_tf: -5.8874e-02 - sdep_func_tf: 4.4694 - val_loss: 31.0539 - val_mse: 31.0539 - val_mean_absolute_error: 4.1047 - val_r2_func_tf: 0.9246 - val_rmse_func_tf: 5.5044 - val_bias_func_tf: -1.3974e+00 - val_sdep_func_tf: 5.1323 - 89ms/epoch - 9ms/step\n",
      "Epoch 146/300\n",
      "10/10 - 0s - loss: 50.1761 - mse: 50.1761 - mean_absolute_error: 5.2013 - r2_func_tf: 0.7976 - rmse_func_tf: 7.3214 - bias_func_tf: -1.8971e+00 - sdep_func_tf: 4.8786 - val_loss: 30.6820 - val_mse: 30.6820 - val_mean_absolute_error: 4.0753 - val_r2_func_tf: 0.9258 - val_rmse_func_tf: 5.4658 - val_bias_func_tf: -1.3261e+00 - val_sdep_func_tf: 5.1171 - 87ms/epoch - 9ms/step\n",
      "Epoch 147/300\n",
      "10/10 - 0s - loss: 35.0386 - mse: 35.0386 - mean_absolute_error: 4.6222 - r2_func_tf: 0.9203 - rmse_func_tf: 5.6952 - bias_func_tf: 0.6748 - sdep_func_tf: 4.7090 - val_loss: 28.9771 - val_mse: 28.9771 - val_mean_absolute_error: 3.9729 - val_r2_func_tf: 0.9256 - val_rmse_func_tf: 5.2460 - val_bias_func_tf: 0.3839 - val_sdep_func_tf: 5.0798 - 88ms/epoch - 9ms/step\n",
      "Epoch 148/300\n",
      "10/10 - 0s - loss: 46.1877 - mse: 46.1877 - mean_absolute_error: 5.2221 - r2_func_tf: 0.8259 - rmse_func_tf: 6.4837 - bias_func_tf: 0.5875 - sdep_func_tf: 4.8198 - val_loss: 29.3076 - val_mse: 29.3076 - val_mean_absolute_error: 3.9920 - val_r2_func_tf: 0.9236 - val_rmse_func_tf: 5.2773 - val_bias_func_tf: 0.5885 - val_sdep_func_tf: 5.0903 - 99ms/epoch - 10ms/step\n",
      "Epoch 149/300\n",
      "10/10 - 0s - loss: 71.3386 - mse: 71.3386 - mean_absolute_error: 6.5440 - r2_func_tf: 0.7498 - rmse_func_tf: 7.6664 - bias_func_tf: 0.6642 - sdep_func_tf: 4.7528 - val_loss: 28.7832 - val_mse: 28.7832 - val_mean_absolute_error: 3.9287 - val_r2_func_tf: 0.9258 - val_rmse_func_tf: 5.2447 - val_bias_func_tf: -8.1650e-02 - val_sdep_func_tf: 5.0829 - 97ms/epoch - 10ms/step\n",
      "Epoch 150/300\n",
      "10/10 - 0s - loss: 47.5950 - mse: 47.5950 - mean_absolute_error: 5.5511 - r2_func_tf: 0.7929 - rmse_func_tf: 7.1625 - bias_func_tf: -8.5645e-01 - sdep_func_tf: 4.8367 - val_loss: 29.0740 - val_mse: 29.0740 - val_mean_absolute_error: 3.9331 - val_r2_func_tf: 0.9270 - val_rmse_func_tf: 5.2806 - val_bias_func_tf: -6.9513e-01 - val_sdep_func_tf: 5.0719 - 92ms/epoch - 9ms/step\n",
      "Epoch 151/300\n",
      "10/10 - 0s - loss: 40.4413 - mse: 40.4413 - mean_absolute_error: 4.8089 - r2_func_tf: 0.8990 - rmse_func_tf: 5.7865 - bias_func_tf: -1.3600e-01 - sdep_func_tf: 4.4219 - val_loss: 29.1257 - val_mse: 29.1257 - val_mean_absolute_error: 3.9560 - val_r2_func_tf: 0.9262 - val_rmse_func_tf: 5.2914 - val_bias_func_tf: -5.6250e-01 - val_sdep_func_tf: 5.1017 - 95ms/epoch - 10ms/step\n",
      "Epoch 152/300\n",
      "10/10 - 0s - loss: 33.3306 - mse: 33.3306 - mean_absolute_error: 4.6490 - r2_func_tf: 0.6670 - rmse_func_tf: 5.9554 - bias_func_tf: 0.9894 - sdep_func_tf: 4.6329 - val_loss: 29.2328 - val_mse: 29.2328 - val_mean_absolute_error: 3.9813 - val_r2_func_tf: 0.9252 - val_rmse_func_tf: 5.2900 - val_bias_func_tf: -8.7864e-02 - val_sdep_func_tf: 5.1379 - 89ms/epoch - 9ms/step\n",
      "Epoch 153/300\n",
      "10/10 - 0s - loss: 44.1584 - mse: 44.1584 - mean_absolute_error: 5.3971 - r2_func_tf: 0.8650 - rmse_func_tf: 6.7654 - bias_func_tf: -1.4182e-01 - sdep_func_tf: 4.6106 - val_loss: 29.8886 - val_mse: 29.8886 - val_mean_absolute_error: 3.9968 - val_r2_func_tf: 0.9259 - val_rmse_func_tf: 5.3750 - val_bias_func_tf: -7.2372e-01 - val_sdep_func_tf: 5.1646 - 89ms/epoch - 9ms/step\n",
      "Epoch 154/300\n",
      "10/10 - 0s - loss: 55.8296 - mse: 55.8296 - mean_absolute_error: 5.6447 - r2_func_tf: 0.8748 - rmse_func_tf: 6.6369 - bias_func_tf: 0.1711 - sdep_func_tf: 4.8189 - val_loss: 31.0268 - val_mse: 31.0268 - val_mean_absolute_error: 4.0829 - val_r2_func_tf: 0.9245 - val_rmse_func_tf: 5.4946 - val_bias_func_tf: -1.3095e+00 - val_sdep_func_tf: 5.1690 - 87ms/epoch - 9ms/step\n",
      "Epoch 155/300\n",
      "10/10 - 0s - loss: 33.6779 - mse: 33.6779 - mean_absolute_error: 4.6888 - r2_func_tf: 0.9168 - rmse_func_tf: 5.7463 - bias_func_tf: 0.1432 - sdep_func_tf: 4.5926 - val_loss: 30.0836 - val_mse: 30.0836 - val_mean_absolute_error: 4.0157 - val_r2_func_tf: 0.9258 - val_rmse_func_tf: 5.3970 - val_bias_func_tf: -9.5204e-01 - val_sdep_func_tf: 5.1487 - 88ms/epoch - 9ms/step\n",
      "Epoch 156/300\n",
      "10/10 - 0s - loss: 33.4406 - mse: 33.4406 - mean_absolute_error: 4.4056 - r2_func_tf: 0.7184 - rmse_func_tf: 5.9474 - bias_func_tf: 0.4380 - sdep_func_tf: 4.8095 - val_loss: 29.8550 - val_mse: 29.8550 - val_mean_absolute_error: 4.0042 - val_r2_func_tf: 0.9255 - val_rmse_func_tf: 5.3798 - val_bias_func_tf: -8.2450e-01 - val_sdep_func_tf: 5.1509 - 89ms/epoch - 9ms/step\n",
      "Epoch 157/300\n",
      "10/10 - 0s - loss: 41.6152 - mse: 41.6152 - mean_absolute_error: 4.4991 - r2_func_tf: 0.8659 - rmse_func_tf: 6.5938 - bias_func_tf: -1.6989e+00 - sdep_func_tf: 4.3431 - val_loss: 30.9134 - val_mse: 30.9134 - val_mean_absolute_error: 4.1172 - val_r2_func_tf: 0.9247 - val_rmse_func_tf: 5.4903 - val_bias_func_tf: -1.3899e+00 - val_sdep_func_tf: 5.1376 - 84ms/epoch - 8ms/step\n",
      "Epoch 158/300\n",
      "10/10 - 0s - loss: 48.7114 - mse: 48.7114 - mean_absolute_error: 4.8920 - r2_func_tf: 0.7287 - rmse_func_tf: 7.1531 - bias_func_tf: -1.6838e+00 - sdep_func_tf: 4.2852 - val_loss: 29.7289 - val_mse: 29.7289 - val_mean_absolute_error: 4.0565 - val_r2_func_tf: 0.9261 - val_rmse_func_tf: 5.3756 - val_bias_func_tf: -9.8082e-01 - val_sdep_func_tf: 5.1122 - 87ms/epoch - 9ms/step\n",
      "Epoch 159/300\n",
      "10/10 - 0s - loss: 41.0526 - mse: 41.0526 - mean_absolute_error: 5.0692 - r2_func_tf: 0.7732 - rmse_func_tf: 5.9359 - bias_func_tf: 1.1035 - sdep_func_tf: 4.5109 - val_loss: 29.0221 - val_mse: 29.0221 - val_mean_absolute_error: 3.9964 - val_r2_func_tf: 0.9227 - val_rmse_func_tf: 5.2771 - val_bias_func_tf: 0.3612 - val_sdep_func_tf: 5.1120 - 90ms/epoch - 9ms/step\n",
      "Epoch 160/300\n",
      "10/10 - 0s - loss: 50.4339 - mse: 50.4339 - mean_absolute_error: 5.4530 - r2_func_tf: 0.8312 - rmse_func_tf: 7.4569 - bias_func_tf: -8.5801e-02 - sdep_func_tf: 5.0614 - val_loss: 29.0659 - val_mse: 29.0659 - val_mean_absolute_error: 3.9749 - val_r2_func_tf: 0.9248 - val_rmse_func_tf: 5.3018 - val_bias_func_tf: -3.1930e-01 - val_sdep_func_tf: 5.1262 - 94ms/epoch - 9ms/step\n",
      "Epoch 161/300\n",
      "10/10 - 0s - loss: 65.8110 - mse: 65.8110 - mean_absolute_error: 6.3551 - r2_func_tf: 0.5626 - rmse_func_tf: 7.7868 - bias_func_tf: 1.5490 - sdep_func_tf: 4.3705 - val_loss: 29.0405 - val_mse: 29.0405 - val_mean_absolute_error: 3.9587 - val_r2_func_tf: 0.9244 - val_rmse_func_tf: 5.2856 - val_bias_func_tf: -4.3154e-02 - val_sdep_func_tf: 5.1252 - 91ms/epoch - 9ms/step\n",
      "Epoch 162/300\n",
      "10/10 - 0s - loss: 32.3617 - mse: 32.3617 - mean_absolute_error: 4.5116 - r2_func_tf: 0.9141 - rmse_func_tf: 5.6758 - bias_func_tf: 0.1999 - sdep_func_tf: 4.8704 - val_loss: 29.7986 - val_mse: 29.7986 - val_mean_absolute_error: 4.0535 - val_r2_func_tf: 0.9253 - val_rmse_func_tf: 5.3802 - val_bias_func_tf: -1.0297e+00 - val_sdep_func_tf: 5.1046 - 91ms/epoch - 9ms/step\n",
      "Epoch 163/300\n",
      "10/10 - 0s - loss: 30.5824 - mse: 30.5824 - mean_absolute_error: 4.0659 - r2_func_tf: 0.9355 - rmse_func_tf: 5.0694 - bias_func_tf: 0.2329 - sdep_func_tf: 4.5188 - val_loss: 29.8469 - val_mse: 29.8469 - val_mean_absolute_error: 4.0370 - val_r2_func_tf: 0.9255 - val_rmse_func_tf: 5.3851 - val_bias_func_tf: -1.0667e+00 - val_sdep_func_tf: 5.1048 - 88ms/epoch - 9ms/step\n",
      "Epoch 164/300\n",
      "10/10 - 0s - loss: 33.2784 - mse: 33.2784 - mean_absolute_error: 4.4290 - r2_func_tf: 0.7853 - rmse_func_tf: 5.5164 - bias_func_tf: 0.0563 - sdep_func_tf: 4.7695 - val_loss: 30.2981 - val_mse: 30.2981 - val_mean_absolute_error: 4.0560 - val_r2_func_tf: 0.9247 - val_rmse_func_tf: 5.4311 - val_bias_func_tf: -1.2323e+00 - val_sdep_func_tf: 5.1143 - 85ms/epoch - 9ms/step\n",
      "Epoch 165/300\n",
      "10/10 - 0s - loss: 39.2544 - mse: 39.2544 - mean_absolute_error: 4.8357 - r2_func_tf: 0.9171 - rmse_func_tf: 5.9422 - bias_func_tf: -4.4411e-01 - sdep_func_tf: 4.3793 - val_loss: 30.3418 - val_mse: 30.3418 - val_mean_absolute_error: 4.0677 - val_r2_func_tf: 0.9246 - val_rmse_func_tf: 5.4390 - val_bias_func_tf: -1.2153e+00 - val_sdep_func_tf: 5.1250 - 87ms/epoch - 9ms/step\n",
      "Epoch 166/300\n",
      "10/10 - 0s - loss: 41.6111 - mse: 41.6111 - mean_absolute_error: 5.0724 - r2_func_tf: 0.7515 - rmse_func_tf: 6.1990 - bias_func_tf: -1.0816e-01 - sdep_func_tf: 4.7003 - val_loss: 29.4272 - val_mse: 29.4272 - val_mean_absolute_error: 4.0002 - val_r2_func_tf: 0.9254 - val_rmse_func_tf: 5.3380 - val_bias_func_tf: -7.2959e-01 - val_sdep_func_tf: 5.1245 - 84ms/epoch - 8ms/step\n",
      "Epoch 167/300\n",
      "10/10 - 0s - loss: 29.0690 - mse: 29.0690 - mean_absolute_error: 4.2596 - r2_func_tf: 0.9033 - rmse_func_tf: 5.2181 - bias_func_tf: 0.2914 - sdep_func_tf: 4.5895 - val_loss: 29.3524 - val_mse: 29.3524 - val_mean_absolute_error: 4.0043 - val_r2_func_tf: 0.9255 - val_rmse_func_tf: 5.3273 - val_bias_func_tf: -7.5816e-01 - val_sdep_func_tf: 5.1119 - 92ms/epoch - 9ms/step\n",
      "Epoch 168/300\n",
      "10/10 - 0s - loss: 33.4795 - mse: 33.4795 - mean_absolute_error: 4.6116 - r2_func_tf: 0.8630 - rmse_func_tf: 5.7534 - bias_func_tf: 0.3314 - sdep_func_tf: 4.6303 - val_loss: 29.6461 - val_mse: 29.6461 - val_mean_absolute_error: 4.0122 - val_r2_func_tf: 0.9250 - val_rmse_func_tf: 5.3507 - val_bias_func_tf: -8.4597e-01 - val_sdep_func_tf: 5.1250 - 90ms/epoch - 9ms/step\n",
      "Epoch 169/300\n",
      "10/10 - 0s - loss: 31.7748 - mse: 31.7748 - mean_absolute_error: 4.3348 - r2_func_tf: 0.9288 - rmse_func_tf: 5.2834 - bias_func_tf: -1.3161e-01 - sdep_func_tf: 4.5570 - val_loss: 29.9439 - val_mse: 29.9439 - val_mean_absolute_error: 4.0230 - val_r2_func_tf: 0.9245 - val_rmse_func_tf: 5.3861 - val_bias_func_tf: -9.4137e-01 - val_sdep_func_tf: 5.1408 - 87ms/epoch - 9ms/step\n",
      "Epoch 170/300\n",
      "10/10 - 0s - loss: 35.0718 - mse: 35.0718 - mean_absolute_error: 4.5986 - r2_func_tf: 0.5639 - rmse_func_tf: 5.8385 - bias_func_tf: 0.4072 - sdep_func_tf: 4.5891 - val_loss: 30.1254 - val_mse: 30.1254 - val_mean_absolute_error: 4.0259 - val_r2_func_tf: 0.9234 - val_rmse_func_tf: 5.4032 - val_bias_func_tf: -9.0447e-01 - val_sdep_func_tf: 5.1674 - 87ms/epoch - 9ms/step\n",
      "Epoch 171/300\n",
      "10/10 - 0s - loss: 28.5489 - mse: 28.5489 - mean_absolute_error: 4.1146 - r2_func_tf: 0.9256 - rmse_func_tf: 5.2736 - bias_func_tf: 0.4507 - sdep_func_tf: 4.3474 - val_loss: 30.7663 - val_mse: 30.7663 - val_mean_absolute_error: 4.0768 - val_r2_func_tf: 0.9218 - val_rmse_func_tf: 5.4758 - val_bias_func_tf: -1.1159e+00 - val_sdep_func_tf: 5.1959 - 91ms/epoch - 9ms/step\n",
      "Epoch 172/300\n",
      "10/10 - 0s - loss: 39.4797 - mse: 39.4797 - mean_absolute_error: 5.0091 - r2_func_tf: 0.6896 - rmse_func_tf: 6.3731 - bias_func_tf: 0.5814 - sdep_func_tf: 4.3088 - val_loss: 32.3389 - val_mse: 32.3389 - val_mean_absolute_error: 4.1898 - val_r2_func_tf: 0.9199 - val_rmse_func_tf: 5.6279 - val_bias_func_tf: -1.6745e+00 - val_sdep_func_tf: 5.2030 - 91ms/epoch - 9ms/step\n",
      "Epoch 173/300\n",
      "10/10 - 0s - loss: 38.6254 - mse: 38.6254 - mean_absolute_error: 4.6759 - r2_func_tf: 0.8254 - rmse_func_tf: 5.7985 - bias_func_tf: -5.9381e-01 - sdep_func_tf: 4.7820 - val_loss: 32.6571 - val_mse: 32.6571 - val_mean_absolute_error: 4.2299 - val_r2_func_tf: 0.9200 - val_rmse_func_tf: 5.6553 - val_bias_func_tf: -1.8046e+00 - val_sdep_func_tf: 5.1905 - 92ms/epoch - 9ms/step\n",
      "Epoch 174/300\n",
      "10/10 - 0s - loss: 38.6975 - mse: 38.6975 - mean_absolute_error: 4.8079 - r2_func_tf: 0.8831 - rmse_func_tf: 5.7208 - bias_func_tf: 0.1693 - sdep_func_tf: 4.5701 - val_loss: 31.1598 - val_mse: 31.1598 - val_mean_absolute_error: 4.1042 - val_r2_func_tf: 0.9230 - val_rmse_func_tf: 5.5078 - val_bias_func_tf: -1.3676e+00 - val_sdep_func_tf: 5.1759 - 87ms/epoch - 9ms/step\n",
      "Epoch 175/300\n",
      "10/10 - 0s - loss: 37.3283 - mse: 37.3283 - mean_absolute_error: 4.8051 - r2_func_tf: 0.8042 - rmse_func_tf: 5.9339 - bias_func_tf: 0.1397 - sdep_func_tf: 4.6282 - val_loss: 31.0416 - val_mse: 31.0416 - val_mean_absolute_error: 4.0748 - val_r2_func_tf: 0.9243 - val_rmse_func_tf: 5.4863 - val_bias_func_tf: -1.3983e+00 - val_sdep_func_tf: 5.1513 - 98ms/epoch - 10ms/step\n",
      "Epoch 176/300\n",
      "10/10 - 0s - loss: 39.6059 - mse: 39.6059 - mean_absolute_error: 4.8289 - r2_func_tf: 0.9105 - rmse_func_tf: 6.0871 - bias_func_tf: -5.9766e-03 - sdep_func_tf: 4.8157 - val_loss: 31.5497 - val_mse: 31.5497 - val_mean_absolute_error: 4.1212 - val_r2_func_tf: 0.9234 - val_rmse_func_tf: 5.5485 - val_bias_func_tf: -1.6025e+00 - val_sdep_func_tf: 5.1496 - 99ms/epoch - 10ms/step\n",
      "Epoch 177/300\n",
      "10/10 - 0s - loss: 43.7931 - mse: 43.7931 - mean_absolute_error: 4.9791 - r2_func_tf: 0.8723 - rmse_func_tf: 6.8009 - bias_func_tf: -1.5025e+00 - sdep_func_tf: 4.7477 - val_loss: 31.5616 - val_mse: 31.5616 - val_mean_absolute_error: 4.1220 - val_r2_func_tf: 0.9237 - val_rmse_func_tf: 5.5521 - val_bias_func_tf: -1.5866e+00 - val_sdep_func_tf: 5.1586 - 99ms/epoch - 10ms/step\n",
      "Epoch 178/300\n",
      "10/10 - 0s - loss: 33.9447 - mse: 33.9447 - mean_absolute_error: 4.5052 - r2_func_tf: 0.8032 - rmse_func_tf: 5.3532 - bias_func_tf: 0.2455 - sdep_func_tf: 4.3805 - val_loss: 29.5968 - val_mse: 29.5968 - val_mean_absolute_error: 3.9849 - val_r2_func_tf: 0.9254 - val_rmse_func_tf: 5.3465 - val_bias_func_tf: -4.1528e-01 - val_sdep_func_tf: 5.1858 - 93ms/epoch - 9ms/step\n",
      "Epoch 179/300\n",
      "10/10 - 0s - loss: 38.4713 - mse: 38.4713 - mean_absolute_error: 4.9395 - r2_func_tf: 0.9112 - rmse_func_tf: 5.7132 - bias_func_tf: 0.9187 - sdep_func_tf: 4.2110 - val_loss: 29.2378 - val_mse: 29.2378 - val_mean_absolute_error: 3.9845 - val_r2_func_tf: 0.9254 - val_rmse_func_tf: 5.3089 - val_bias_func_tf: -2.0447e-01 - val_sdep_func_tf: 5.1643 - 95ms/epoch - 9ms/step\n",
      "Epoch 180/300\n",
      "10/10 - 0s - loss: 36.1273 - mse: 36.1273 - mean_absolute_error: 4.7271 - r2_func_tf: 0.8808 - rmse_func_tf: 6.1932 - bias_func_tf: -4.8387e-01 - sdep_func_tf: 4.5264 - val_loss: 29.3287 - val_mse: 29.3287 - val_mean_absolute_error: 3.9678 - val_r2_func_tf: 0.9265 - val_rmse_func_tf: 5.3270 - val_bias_func_tf: -7.4200e-01 - val_sdep_func_tf: 5.1277 - 89ms/epoch - 9ms/step\n",
      "Epoch 181/300\n",
      "10/10 - 0s - loss: 38.4543 - mse: 38.4543 - mean_absolute_error: 4.6964 - r2_func_tf: 0.8150 - rmse_func_tf: 5.8127 - bias_func_tf: -3.7696e-02 - sdep_func_tf: 4.6901 - val_loss: 28.9403 - val_mse: 28.9403 - val_mean_absolute_error: 3.9478 - val_r2_func_tf: 0.9254 - val_rmse_func_tf: 5.2850 - val_bias_func_tf: -3.7416e-01 - val_sdep_func_tf: 5.1238 - 89ms/epoch - 9ms/step\n",
      "Epoch 182/300\n",
      "10/10 - 0s - loss: 33.5037 - mse: 33.5037 - mean_absolute_error: 4.7282 - r2_func_tf: 0.9081 - rmse_func_tf: 5.9414 - bias_func_tf: -5.3008e-01 - sdep_func_tf: 4.3605 - val_loss: 28.6128 - val_mse: 28.6128 - val_mean_absolute_error: 3.9335 - val_r2_func_tf: 0.9261 - val_rmse_func_tf: 5.2454 - val_bias_func_tf: -3.5461e-01 - val_sdep_func_tf: 5.0862 - 88ms/epoch - 9ms/step\n",
      "Epoch 183/300\n",
      "10/10 - 0s - loss: 28.3966 - mse: 28.3966 - mean_absolute_error: 4.1479 - r2_func_tf: 0.8793 - rmse_func_tf: 5.4249 - bias_func_tf: 0.3987 - sdep_func_tf: 4.7264 - val_loss: 28.3337 - val_mse: 28.3337 - val_mean_absolute_error: 3.9391 - val_r2_func_tf: 0.9259 - val_rmse_func_tf: 5.2096 - val_bias_func_tf: -5.9327e-04 - val_sdep_func_tf: 5.0665 - 89ms/epoch - 9ms/step\n",
      "Epoch 184/300\n",
      "10/10 - 0s - loss: 37.7584 - mse: 37.7584 - mean_absolute_error: 4.5998 - r2_func_tf: 0.8210 - rmse_func_tf: 5.6915 - bias_func_tf: 0.2398 - sdep_func_tf: 4.7528 - val_loss: 28.4474 - val_mse: 28.4474 - val_mean_absolute_error: 3.9641 - val_r2_func_tf: 0.9259 - val_rmse_func_tf: 5.2445 - val_bias_func_tf: -3.4918e-01 - val_sdep_func_tf: 5.0793 - 87ms/epoch - 9ms/step\n",
      "Epoch 185/300\n",
      "10/10 - 0s - loss: 44.8090 - mse: 44.8090 - mean_absolute_error: 5.4747 - r2_func_tf: 0.8400 - rmse_func_tf: 6.4487 - bias_func_tf: -1.4919e-02 - sdep_func_tf: 4.4757 - val_loss: 28.5254 - val_mse: 28.5254 - val_mean_absolute_error: 3.9773 - val_r2_func_tf: 0.9268 - val_rmse_func_tf: 5.2543 - val_bias_func_tf: -5.4057e-01 - val_sdep_func_tf: 5.0710 - 88ms/epoch - 9ms/step\n",
      "Epoch 186/300\n",
      "10/10 - 0s - loss: 36.1595 - mse: 36.1595 - mean_absolute_error: 4.7051 - r2_func_tf: 0.8782 - rmse_func_tf: 5.7691 - bias_func_tf: 0.1303 - sdep_func_tf: 4.5804 - val_loss: 29.8149 - val_mse: 29.8149 - val_mean_absolute_error: 4.0647 - val_r2_func_tf: 0.9261 - val_rmse_func_tf: 5.3997 - val_bias_func_tf: -1.0781e+00 - val_sdep_func_tf: 5.1233 - 86ms/epoch - 9ms/step\n",
      "Epoch 187/300\n",
      "10/10 - 0s - loss: 35.0068 - mse: 35.0068 - mean_absolute_error: 4.7009 - r2_func_tf: 0.8847 - rmse_func_tf: 5.6198 - bias_func_tf: 0.3387 - sdep_func_tf: 4.5469 - val_loss: 29.7735 - val_mse: 29.7735 - val_mean_absolute_error: 4.0373 - val_r2_func_tf: 0.9266 - val_rmse_func_tf: 5.3942 - val_bias_func_tf: -9.7740e-01 - val_sdep_func_tf: 5.1366 - 85ms/epoch - 8ms/step\n",
      "Epoch 188/300\n",
      "10/10 - 0s - loss: 34.8085 - mse: 34.8085 - mean_absolute_error: 4.5838 - r2_func_tf: 0.8959 - rmse_func_tf: 5.9548 - bias_func_tf: -2.3116e-01 - sdep_func_tf: 4.7628 - val_loss: 30.3945 - val_mse: 30.3945 - val_mean_absolute_error: 4.0821 - val_r2_func_tf: 0.9263 - val_rmse_func_tf: 5.4516 - val_bias_func_tf: -1.2981e+00 - val_sdep_func_tf: 5.1258 - 86ms/epoch - 9ms/step\n",
      "Epoch 189/300\n",
      "10/10 - 0s - loss: 34.7424 - mse: 34.7424 - mean_absolute_error: 4.6487 - r2_func_tf: 0.7125 - rmse_func_tf: 5.5096 - bias_func_tf: 0.0772 - sdep_func_tf: 4.4418 - val_loss: 29.2259 - val_mse: 29.2259 - val_mean_absolute_error: 3.9716 - val_r2_func_tf: 0.9285 - val_rmse_func_tf: 5.3252 - val_bias_func_tf: -8.3581e-01 - val_sdep_func_tf: 5.1013 - 86ms/epoch - 9ms/step\n",
      "Epoch 190/300\n",
      "10/10 - 0s - loss: 28.7138 - mse: 28.7138 - mean_absolute_error: 3.9048 - r2_func_tf: 0.9233 - rmse_func_tf: 5.0989 - bias_func_tf: -3.9563e-01 - sdep_func_tf: 4.4641 - val_loss: 29.3407 - val_mse: 29.3407 - val_mean_absolute_error: 3.9888 - val_r2_func_tf: 0.9279 - val_rmse_func_tf: 5.3387 - val_bias_func_tf: -8.8825e-01 - val_sdep_func_tf: 5.1046 - 87ms/epoch - 9ms/step\n",
      "Epoch 191/300\n",
      "10/10 - 0s - loss: 59.2879 - mse: 59.2879 - mean_absolute_error: 6.2503 - r2_func_tf: 0.6934 - rmse_func_tf: 7.2572 - bias_func_tf: -1.5154e-01 - sdep_func_tf: 4.5664 - val_loss: 28.8657 - val_mse: 28.8657 - val_mean_absolute_error: 3.9530 - val_r2_func_tf: 0.9275 - val_rmse_func_tf: 5.2837 - val_bias_func_tf: -4.3255e-01 - val_sdep_func_tf: 5.1099 - 87ms/epoch - 9ms/step\n",
      "Epoch 192/300\n",
      "10/10 - 0s - loss: 42.6417 - mse: 42.6417 - mean_absolute_error: 4.9332 - r2_func_tf: 0.8897 - rmse_func_tf: 6.3525 - bias_func_tf: -3.3322e-01 - sdep_func_tf: 4.6848 - val_loss: 29.5507 - val_mse: 29.5507 - val_mean_absolute_error: 4.0081 - val_r2_func_tf: 0.9269 - val_rmse_func_tf: 5.3621 - val_bias_func_tf: -9.1443e-01 - val_sdep_func_tf: 5.1217 - 85ms/epoch - 9ms/step\n",
      "Epoch 193/300\n",
      "10/10 - 0s - loss: 58.0040 - mse: 58.0040 - mean_absolute_error: 5.8985 - r2_func_tf: 0.7067 - rmse_func_tf: 7.6019 - bias_func_tf: -1.1787e+00 - sdep_func_tf: 4.7987 - val_loss: 29.0890 - val_mse: 29.0890 - val_mean_absolute_error: 3.9892 - val_r2_func_tf: 0.9275 - val_rmse_func_tf: 5.3115 - val_bias_func_tf: -8.1071e-01 - val_sdep_func_tf: 5.0869 - 98ms/epoch - 10ms/step\n",
      "Epoch 194/300\n",
      "10/10 - 0s - loss: 36.8440 - mse: 36.8440 - mean_absolute_error: 4.7471 - r2_func_tf: 0.8294 - rmse_func_tf: 6.0382 - bias_func_tf: 1.3974 - sdep_func_tf: 4.2333 - val_loss: 28.7469 - val_mse: 28.7469 - val_mean_absolute_error: 3.9927 - val_r2_func_tf: 0.9245 - val_rmse_func_tf: 5.2400 - val_bias_func_tf: 0.4781 - val_sdep_func_tf: 5.0741 - 89ms/epoch - 9ms/step\n",
      "Epoch 195/300\n",
      "10/10 - 0s - loss: 42.4279 - mse: 42.4279 - mean_absolute_error: 5.1284 - r2_func_tf: 0.8498 - rmse_func_tf: 6.4611 - bias_func_tf: 0.0537 - sdep_func_tf: 4.8412 - val_loss: 28.4569 - val_mse: 28.4569 - val_mean_absolute_error: 3.9328 - val_r2_func_tf: 0.9277 - val_rmse_func_tf: 5.2339 - val_bias_func_tf: -3.6168e-01 - val_sdep_func_tf: 5.0669 - 91ms/epoch - 9ms/step\n",
      "Epoch 196/300\n",
      "10/10 - 0s - loss: 62.2369 - mse: 62.2369 - mean_absolute_error: 6.3276 - r2_func_tf: 0.4857 - rmse_func_tf: 8.0168 - bias_func_tf: 1.4620 - sdep_func_tf: 5.0197 - val_loss: 28.3537 - val_mse: 28.3537 - val_mean_absolute_error: 3.9564 - val_r2_func_tf: 0.9276 - val_rmse_func_tf: 5.2217 - val_bias_func_tf: -3.5825e-01 - val_sdep_func_tf: 5.0563 - 96ms/epoch - 10ms/step\n",
      "Epoch 197/300\n",
      "10/10 - 0s - loss: 35.8333 - mse: 35.8333 - mean_absolute_error: 4.7318 - r2_func_tf: 0.8006 - rmse_func_tf: 5.7397 - bias_func_tf: 0.4204 - sdep_func_tf: 4.8328 - val_loss: 28.9821 - val_mse: 28.9821 - val_mean_absolute_error: 4.0224 - val_r2_func_tf: 0.9277 - val_rmse_func_tf: 5.2977 - val_bias_func_tf: -9.4778e-01 - val_sdep_func_tf: 5.0460 - 88ms/epoch - 9ms/step\n",
      "Epoch 198/300\n",
      "10/10 - 0s - loss: 49.5779 - mse: 49.5779 - mean_absolute_error: 5.5196 - r2_func_tf: 0.8665 - rmse_func_tf: 6.7292 - bias_func_tf: -6.1939e-01 - sdep_func_tf: 4.4283 - val_loss: 30.5377 - val_mse: 30.5377 - val_mean_absolute_error: 4.1268 - val_r2_func_tf: 0.9258 - val_rmse_func_tf: 5.4560 - val_bias_func_tf: -1.4984e+00 - val_sdep_func_tf: 5.0720 - 88ms/epoch - 9ms/step\n",
      "Epoch 199/300\n",
      "10/10 - 0s - loss: 44.6721 - mse: 44.6721 - mean_absolute_error: 5.5125 - r2_func_tf: 0.8000 - rmse_func_tf: 6.3382 - bias_func_tf: 0.0616 - sdep_func_tf: 4.6934 - val_loss: 30.1815 - val_mse: 30.1815 - val_mean_absolute_error: 4.0989 - val_r2_func_tf: 0.9263 - val_rmse_func_tf: 5.4243 - val_bias_func_tf: -1.2583e+00 - val_sdep_func_tf: 5.1053 - 95ms/epoch - 9ms/step\n",
      "Epoch 200/300\n",
      "10/10 - 0s - loss: 33.2483 - mse: 33.2483 - mean_absolute_error: 4.4106 - r2_func_tf: 0.9119 - rmse_func_tf: 5.4116 - bias_func_tf: -1.7090e-01 - sdep_func_tf: 4.3880 - val_loss: 30.9195 - val_mse: 30.9195 - val_mean_absolute_error: 4.1571 - val_r2_func_tf: 0.9256 - val_rmse_func_tf: 5.4959 - val_bias_func_tf: -1.4801e+00 - val_sdep_func_tf: 5.1234 - 89ms/epoch - 9ms/step\n",
      "Epoch 201/300\n",
      "10/10 - 0s - loss: 52.8665 - mse: 52.8665 - mean_absolute_error: 5.5522 - r2_func_tf: 0.8551 - rmse_func_tf: 6.6536 - bias_func_tf: -2.6166e-01 - sdep_func_tf: 5.0711 - val_loss: 30.3014 - val_mse: 30.3014 - val_mean_absolute_error: 4.0966 - val_r2_func_tf: 0.9266 - val_rmse_func_tf: 5.4350 - val_bias_func_tf: -1.2308e+00 - val_sdep_func_tf: 5.1297 - 89ms/epoch - 9ms/step\n",
      "Epoch 202/300\n",
      "10/10 - 0s - loss: 45.2100 - mse: 45.2100 - mean_absolute_error: 5.1057 - r2_func_tf: 0.0081 - rmse_func_tf: 6.7230 - bias_func_tf: 0.8756 - sdep_func_tf: 4.9647 - val_loss: 29.4718 - val_mse: 29.4718 - val_mean_absolute_error: 4.0280 - val_r2_func_tf: 0.9281 - val_rmse_func_tf: 5.3448 - val_bias_func_tf: -9.2777e-01 - val_sdep_func_tf: 5.1076 - 87ms/epoch - 9ms/step\n",
      "Epoch 203/300\n",
      "10/10 - 0s - loss: 41.8392 - mse: 41.8392 - mean_absolute_error: 5.2612 - r2_func_tf: 0.5837 - rmse_func_tf: 6.5017 - bias_func_tf: 0.7773 - sdep_func_tf: 4.5749 - val_loss: 29.5827 - val_mse: 29.5827 - val_mean_absolute_error: 4.0456 - val_r2_func_tf: 0.9283 - val_rmse_func_tf: 5.3554 - val_bias_func_tf: -1.0743e+00 - val_sdep_func_tf: 5.0910 - 88ms/epoch - 9ms/step\n",
      "Epoch 204/300\n",
      "10/10 - 0s - loss: 30.4581 - mse: 30.4581 - mean_absolute_error: 4.2755 - r2_func_tf: 0.9145 - rmse_func_tf: 5.4003 - bias_func_tf: -2.6541e-01 - sdep_func_tf: 4.3787 - val_loss: 31.1871 - val_mse: 31.1871 - val_mean_absolute_error: 4.1677 - val_r2_func_tf: 0.9257 - val_rmse_func_tf: 5.5159 - val_bias_func_tf: -1.6039e+00 - val_sdep_func_tf: 5.1139 - 84ms/epoch - 8ms/step\n",
      "Epoch 205/300\n",
      "10/10 - 0s - loss: 41.2796 - mse: 41.2796 - mean_absolute_error: 4.9254 - r2_func_tf: 0.8802 - rmse_func_tf: 6.2251 - bias_func_tf: -4.0717e-01 - sdep_func_tf: 4.9350 - val_loss: 31.4257 - val_mse: 31.4257 - val_mean_absolute_error: 4.1749 - val_r2_func_tf: 0.9248 - val_rmse_func_tf: 5.5374 - val_bias_func_tf: -1.6394e+00 - val_sdep_func_tf: 5.1270 - 85ms/epoch - 8ms/step\n",
      "Epoch 206/300\n",
      "10/10 - 0s - loss: 38.4819 - mse: 38.4819 - mean_absolute_error: 4.8212 - r2_func_tf: 0.8506 - rmse_func_tf: 6.1604 - bias_func_tf: 0.5230 - sdep_func_tf: 4.5846 - val_loss: 29.5437 - val_mse: 29.5437 - val_mean_absolute_error: 4.0280 - val_r2_func_tf: 0.9271 - val_rmse_func_tf: 5.3505 - val_bias_func_tf: -9.1318e-01 - val_sdep_func_tf: 5.1181 - 99ms/epoch - 10ms/step\n",
      "Epoch 207/300\n",
      "10/10 - 0s - loss: 45.3484 - mse: 45.3484 - mean_absolute_error: 5.3769 - r2_func_tf: 0.8262 - rmse_func_tf: 6.5556 - bias_func_tf: 0.0754 - sdep_func_tf: 4.6937 - val_loss: 29.9117 - val_mse: 29.9117 - val_mean_absolute_error: 4.0539 - val_r2_func_tf: 0.9272 - val_rmse_func_tf: 5.3876 - val_bias_func_tf: -1.1816e+00 - val_sdep_func_tf: 5.0989 - 92ms/epoch - 9ms/step\n",
      "Epoch 208/300\n",
      "10/10 - 0s - loss: 32.9058 - mse: 32.9058 - mean_absolute_error: 4.5279 - r2_func_tf: 0.8052 - rmse_func_tf: 5.6837 - bias_func_tf: -1.0676e-01 - sdep_func_tf: 4.4874 - val_loss: 29.8070 - val_mse: 29.8070 - val_mean_absolute_error: 4.0294 - val_r2_func_tf: 0.9283 - val_rmse_func_tf: 5.3709 - val_bias_func_tf: -1.1760e+00 - val_sdep_func_tf: 5.0888 - 87ms/epoch - 9ms/step\n",
      "Epoch 209/300\n",
      "10/10 - 0s - loss: 31.4676 - mse: 31.4676 - mean_absolute_error: 4.2719 - r2_func_tf: 0.7403 - rmse_func_tf: 5.5933 - bias_func_tf: -9.3851e-02 - sdep_func_tf: 4.8632 - val_loss: 29.9745 - val_mse: 29.9745 - val_mean_absolute_error: 4.0325 - val_r2_func_tf: 0.9281 - val_rmse_func_tf: 5.3815 - val_bias_func_tf: -1.1828e+00 - val_sdep_func_tf: 5.1034 - 88ms/epoch - 9ms/step\n",
      "Epoch 210/300\n",
      "10/10 - 0s - loss: 30.1959 - mse: 30.1959 - mean_absolute_error: 4.3164 - r2_func_tf: 0.9236 - rmse_func_tf: 5.4068 - bias_func_tf: -1.6759e-01 - sdep_func_tf: 4.7535 - val_loss: 30.8569 - val_mse: 30.8569 - val_mean_absolute_error: 4.0880 - val_r2_func_tf: 0.9260 - val_rmse_func_tf: 5.4726 - val_bias_func_tf: -1.4006e+00 - val_sdep_func_tf: 5.1432 - 88ms/epoch - 9ms/step\n",
      "Epoch 211/300\n",
      "10/10 - 0s - loss: 31.1201 - mse: 31.1201 - mean_absolute_error: 4.1503 - r2_func_tf: 0.5888 - rmse_func_tf: 5.8013 - bias_func_tf: 0.5431 - sdep_func_tf: 4.6223 - val_loss: 29.8999 - val_mse: 29.8999 - val_mean_absolute_error: 4.0062 - val_r2_func_tf: 0.9265 - val_rmse_func_tf: 5.3722 - val_bias_func_tf: -8.6125e-01 - val_sdep_func_tf: 5.1623 - 91ms/epoch - 9ms/step\n",
      "Epoch 212/300\n",
      "10/10 - 0s - loss: 42.5847 - mse: 42.5847 - mean_absolute_error: 4.9932 - r2_func_tf: 0.8349 - rmse_func_tf: 6.6487 - bias_func_tf: -1.1134e+00 - sdep_func_tf: 4.5786 - val_loss: 30.7607 - val_mse: 30.7607 - val_mean_absolute_error: 4.0568 - val_r2_func_tf: 0.9254 - val_rmse_func_tf: 5.4564 - val_bias_func_tf: -1.2831e+00 - val_sdep_func_tf: 5.1581 - 87ms/epoch - 9ms/step\n",
      "Epoch 213/300\n",
      "10/10 - 0s - loss: 39.6840 - mse: 39.6840 - mean_absolute_error: 5.0939 - r2_func_tf: 0.8346 - rmse_func_tf: 6.0176 - bias_func_tf: 0.0944 - sdep_func_tf: 4.4523 - val_loss: 29.4252 - val_mse: 29.4252 - val_mean_absolute_error: 3.9859 - val_r2_func_tf: 0.9271 - val_rmse_func_tf: 5.3208 - val_bias_func_tf: -6.4099e-01 - val_sdep_func_tf: 5.1409 - 87ms/epoch - 9ms/step\n",
      "Epoch 214/300\n",
      "10/10 - 0s - loss: 45.0786 - mse: 45.0786 - mean_absolute_error: 5.2741 - r2_func_tf: 0.8708 - rmse_func_tf: 6.7471 - bias_func_tf: -7.6645e-01 - sdep_func_tf: 4.5573 - val_loss: 29.3340 - val_mse: 29.3340 - val_mean_absolute_error: 3.9891 - val_r2_func_tf: 0.9278 - val_rmse_func_tf: 5.3093 - val_bias_func_tf: -6.3289e-01 - val_sdep_func_tf: 5.1302 - 85ms/epoch - 9ms/step\n",
      "Epoch 215/300\n",
      "10/10 - 0s - loss: 34.0424 - mse: 34.0424 - mean_absolute_error: 4.5884 - r2_func_tf: -1.4984e-01 - rmse_func_tf: 5.7707 - bias_func_tf: 0.4679 - sdep_func_tf: 4.2577 - val_loss: 28.8487 - val_mse: 28.8487 - val_mean_absolute_error: 3.9707 - val_r2_func_tf: 0.9282 - val_rmse_func_tf: 5.2484 - val_bias_func_tf: -3.0676e-01 - val_sdep_func_tf: 5.1039 - 88ms/epoch - 9ms/step\n",
      "Epoch 216/300\n",
      "10/10 - 0s - loss: 32.4464 - mse: 32.4464 - mean_absolute_error: 4.4041 - r2_func_tf: 0.8958 - rmse_func_tf: 5.5101 - bias_func_tf: -6.2105e-02 - sdep_func_tf: 4.4613 - val_loss: 29.1557 - val_mse: 29.1557 - val_mean_absolute_error: 3.9813 - val_r2_func_tf: 0.9280 - val_rmse_func_tf: 5.2863 - val_bias_func_tf: -5.7790e-01 - val_sdep_func_tf: 5.1163 - 84ms/epoch - 8ms/step\n",
      "Epoch 217/300\n",
      "10/10 - 0s - loss: 42.6710 - mse: 42.6710 - mean_absolute_error: 5.0785 - r2_func_tf: 0.6427 - rmse_func_tf: 6.5349 - bias_func_tf: 0.5214 - sdep_func_tf: 4.6285 - val_loss: 29.1747 - val_mse: 29.1747 - val_mean_absolute_error: 3.9883 - val_r2_func_tf: 0.9274 - val_rmse_func_tf: 5.2879 - val_bias_func_tf: -4.2926e-01 - val_sdep_func_tf: 5.1336 - 92ms/epoch - 9ms/step\n",
      "Epoch 218/300\n",
      "10/10 - 0s - loss: 40.8861 - mse: 40.8861 - mean_absolute_error: 4.8912 - r2_func_tf: 0.8304 - rmse_func_tf: 6.0129 - bias_func_tf: 0.3727 - sdep_func_tf: 4.6261 - val_loss: 29.8255 - val_mse: 29.8255 - val_mean_absolute_error: 4.0154 - val_r2_func_tf: 0.9269 - val_rmse_func_tf: 5.3603 - val_bias_func_tf: -7.8082e-01 - val_sdep_func_tf: 5.1630 - 87ms/epoch - 9ms/step\n",
      "Epoch 219/300\n",
      "10/10 - 0s - loss: 47.9670 - mse: 47.9670 - mean_absolute_error: 5.0232 - r2_func_tf: 0.7965 - rmse_func_tf: 7.0395 - bias_func_tf: -1.2632e+00 - sdep_func_tf: 4.8804 - val_loss: 31.0734 - val_mse: 31.0734 - val_mean_absolute_error: 4.0938 - val_r2_func_tf: 0.9253 - val_rmse_func_tf: 5.4892 - val_bias_func_tf: -1.3978e+00 - val_sdep_func_tf: 5.1601 - 86ms/epoch - 9ms/step\n",
      "Epoch 220/300\n",
      "10/10 - 0s - loss: 32.5172 - mse: 32.5172 - mean_absolute_error: 4.4842 - r2_func_tf: 0.9101 - rmse_func_tf: 5.7497 - bias_func_tf: -4.0602e-01 - sdep_func_tf: 4.7249 - val_loss: 29.1924 - val_mse: 29.1924 - val_mean_absolute_error: 3.9632 - val_r2_func_tf: 0.9280 - val_rmse_func_tf: 5.2668 - val_bias_func_tf: -1.9680e-01 - val_sdep_func_tf: 5.1310 - 84ms/epoch - 8ms/step\n",
      "Epoch 221/300\n",
      "10/10 - 0s - loss: 44.7649 - mse: 44.7649 - mean_absolute_error: 5.0113 - r2_func_tf: 0.8163 - rmse_func_tf: 6.6107 - bias_func_tf: 0.1840 - sdep_func_tf: 4.9152 - val_loss: 29.2057 - val_mse: 29.2057 - val_mean_absolute_error: 3.9977 - val_r2_func_tf: 0.9263 - val_rmse_func_tf: 5.2644 - val_bias_func_tf: 0.2723 - val_sdep_func_tf: 5.1253 - 85ms/epoch - 9ms/step\n",
      "Epoch 222/300\n",
      "10/10 - 0s - loss: 43.4363 - mse: 43.4363 - mean_absolute_error: 4.8572 - r2_func_tf: 0.8267 - rmse_func_tf: 5.9396 - bias_func_tf: 0.8717 - sdep_func_tf: 4.4779 - val_loss: 28.8693 - val_mse: 28.8693 - val_mean_absolute_error: 3.9673 - val_r2_func_tf: 0.9282 - val_rmse_func_tf: 5.2431 - val_bias_func_tf: -2.1843e-01 - val_sdep_func_tf: 5.1076 - 88ms/epoch - 9ms/step\n",
      "Epoch 223/300\n",
      "10/10 - 0s - loss: 41.0868 - mse: 41.0868 - mean_absolute_error: 4.8666 - r2_func_tf: 0.8260 - rmse_func_tf: 6.7308 - bias_func_tf: -1.2508e+00 - sdep_func_tf: 4.3686 - val_loss: 29.2240 - val_mse: 29.2240 - val_mean_absolute_error: 3.9831 - val_r2_func_tf: 0.9284 - val_rmse_func_tf: 5.2861 - val_bias_func_tf: -7.3180e-01 - val_sdep_func_tf: 5.0999 - 88ms/epoch - 9ms/step\n",
      "Epoch 224/300\n",
      "10/10 - 0s - loss: 36.9297 - mse: 36.9297 - mean_absolute_error: 4.7822 - r2_func_tf: 0.9053 - rmse_func_tf: 6.2636 - bias_func_tf: -3.5054e-01 - sdep_func_tf: 4.8323 - val_loss: 28.6942 - val_mse: 28.6942 - val_mean_absolute_error: 3.9642 - val_r2_func_tf: 0.9282 - val_rmse_func_tf: 5.2247 - val_bias_func_tf: -2.9065e-01 - val_sdep_func_tf: 5.0832 - 86ms/epoch - 9ms/step\n",
      "Epoch 225/300\n",
      "10/10 - 0s - loss: 33.5698 - mse: 33.5698 - mean_absolute_error: 4.5203 - r2_func_tf: 0.9122 - rmse_func_tf: 5.6849 - bias_func_tf: 0.5743 - sdep_func_tf: 4.6170 - val_loss: 28.5752 - val_mse: 28.5752 - val_mean_absolute_error: 3.9548 - val_r2_func_tf: 0.9280 - val_rmse_func_tf: 5.2082 - val_bias_func_tf: -1.1276e-01 - val_sdep_func_tf: 5.0769 - 85ms/epoch - 8ms/step\n",
      "Epoch 226/300\n",
      "10/10 - 0s - loss: 26.9616 - mse: 26.9616 - mean_absolute_error: 3.9197 - r2_func_tf: 0.6780 - rmse_func_tf: 5.2254 - bias_func_tf: 1.5614 - sdep_func_tf: 4.3980 - val_loss: 28.6572 - val_mse: 28.6572 - val_mean_absolute_error: 3.9561 - val_r2_func_tf: 0.9279 - val_rmse_func_tf: 5.2103 - val_bias_func_tf: -9.1057e-02 - val_sdep_func_tf: 5.0833 - 86ms/epoch - 9ms/step\n",
      "Epoch 227/300\n",
      "10/10 - 0s - loss: 37.9978 - mse: 37.9978 - mean_absolute_error: 4.8610 - r2_func_tf: 0.8818 - rmse_func_tf: 5.9425 - bias_func_tf: 0.4670 - sdep_func_tf: 4.4822 - val_loss: 29.2104 - val_mse: 29.2104 - val_mean_absolute_error: 3.9872 - val_r2_func_tf: 0.9280 - val_rmse_func_tf: 5.2844 - val_bias_func_tf: -8.7858e-01 - val_sdep_func_tf: 5.0791 - 88ms/epoch - 9ms/step\n",
      "Epoch 228/300\n",
      "10/10 - 0s - loss: 29.8542 - mse: 29.8542 - mean_absolute_error: 4.1660 - r2_func_tf: 0.9090 - rmse_func_tf: 5.3095 - bias_func_tf: -6.0374e-03 - sdep_func_tf: 4.6629 - val_loss: 29.6850 - val_mse: 29.6850 - val_mean_absolute_error: 4.0208 - val_r2_func_tf: 0.9282 - val_rmse_func_tf: 5.3438 - val_bias_func_tf: -1.2048e+00 - val_sdep_func_tf: 5.0702 - 87ms/epoch - 9ms/step\n",
      "Epoch 229/300\n",
      "10/10 - 0s - loss: 31.7050 - mse: 31.7050 - mean_absolute_error: 4.3736 - r2_func_tf: 0.8897 - rmse_func_tf: 5.6164 - bias_func_tf: -6.9285e-01 - sdep_func_tf: 4.6469 - val_loss: 30.0459 - val_mse: 30.0459 - val_mean_absolute_error: 4.0494 - val_r2_func_tf: 0.9273 - val_rmse_func_tf: 5.3962 - val_bias_func_tf: -1.2632e+00 - val_sdep_func_tf: 5.1039 - 88ms/epoch - 9ms/step\n",
      "Epoch 230/300\n",
      "10/10 - 0s - loss: 36.0462 - mse: 36.0462 - mean_absolute_error: 4.7411 - r2_func_tf: 0.8885 - rmse_func_tf: 5.8279 - bias_func_tf: -2.5109e-01 - sdep_func_tf: 4.5332 - val_loss: 29.6234 - val_mse: 29.6234 - val_mean_absolute_error: 4.0236 - val_r2_func_tf: 0.9279 - val_rmse_func_tf: 5.3559 - val_bias_func_tf: -1.0877e+00 - val_sdep_func_tf: 5.1039 - 91ms/epoch - 9ms/step\n",
      "Epoch 231/300\n",
      "10/10 - 0s - loss: 25.8815 - mse: 25.8815 - mean_absolute_error: 3.8975 - r2_func_tf: 0.8702 - rmse_func_tf: 5.2031 - bias_func_tf: 0.6624 - sdep_func_tf: 4.2796 - val_loss: 28.8939 - val_mse: 28.8939 - val_mean_absolute_error: 3.9570 - val_r2_func_tf: 0.9288 - val_rmse_func_tf: 5.2633 - val_bias_func_tf: -5.7103e-01 - val_sdep_func_tf: 5.1029 - 89ms/epoch - 9ms/step\n",
      "Epoch 232/300\n",
      "10/10 - 0s - loss: 29.9618 - mse: 29.9618 - mean_absolute_error: 4.3397 - r2_func_tf: 0.8839 - rmse_func_tf: 5.3296 - bias_func_tf: -2.6443e-01 - sdep_func_tf: 4.5196 - val_loss: 29.1704 - val_mse: 29.1704 - val_mean_absolute_error: 3.9792 - val_r2_func_tf: 0.9287 - val_rmse_func_tf: 5.2949 - val_bias_func_tf: -8.7038e-01 - val_sdep_func_tf: 5.0945 - 88ms/epoch - 9ms/step\n",
      "Epoch 233/300\n",
      "10/10 - 0s - loss: 46.7667 - mse: 46.7667 - mean_absolute_error: 5.3948 - r2_func_tf: 0.8547 - rmse_func_tf: 7.1443 - bias_func_tf: -1.2656e+00 - sdep_func_tf: 4.8351 - val_loss: 29.2764 - val_mse: 29.2764 - val_mean_absolute_error: 3.9714 - val_r2_func_tf: 0.9281 - val_rmse_func_tf: 5.2992 - val_bias_func_tf: -8.5140e-01 - val_sdep_func_tf: 5.1032 - 88ms/epoch - 9ms/step\n",
      "Epoch 234/300\n",
      "10/10 - 0s - loss: 35.0774 - mse: 35.0774 - mean_absolute_error: 4.6046 - r2_func_tf: 0.7313 - rmse_func_tf: 5.6233 - bias_func_tf: 0.7622 - sdep_func_tf: 4.2727 - val_loss: 28.7223 - val_mse: 28.7223 - val_mean_absolute_error: 3.9589 - val_r2_func_tf: 0.9276 - val_rmse_func_tf: 5.2372 - val_bias_func_tf: -2.0425e-01 - val_sdep_func_tf: 5.1085 - 89ms/epoch - 9ms/step\n",
      "Epoch 235/300\n",
      "10/10 - 0s - loss: 30.4025 - mse: 30.4025 - mean_absolute_error: 4.2356 - r2_func_tf: 0.9140 - rmse_func_tf: 5.0478 - bias_func_tf: 0.6252 - sdep_func_tf: 4.3133 - val_loss: 28.6869 - val_mse: 28.6869 - val_mean_absolute_error: 3.9518 - val_r2_func_tf: 0.9277 - val_rmse_func_tf: 5.2419 - val_bias_func_tf: -3.4988e-01 - val_sdep_func_tf: 5.1036 - 96ms/epoch - 10ms/step\n",
      "Epoch 236/300\n",
      "10/10 - 0s - loss: 30.3807 - mse: 30.3807 - mean_absolute_error: 4.3509 - r2_func_tf: 0.9229 - rmse_func_tf: 5.5003 - bias_func_tf: 0.1794 - sdep_func_tf: 4.5595 - val_loss: 29.0076 - val_mse: 29.0076 - val_mean_absolute_error: 3.9720 - val_r2_func_tf: 0.9282 - val_rmse_func_tf: 5.2856 - val_bias_func_tf: -7.5176e-01 - val_sdep_func_tf: 5.1023 - 88ms/epoch - 9ms/step\n",
      "Epoch 237/300\n",
      "10/10 - 0s - loss: 30.9219 - mse: 30.9219 - mean_absolute_error: 4.4550 - r2_func_tf: 0.9160 - rmse_func_tf: 5.5554 - bias_func_tf: 0.6834 - sdep_func_tf: 4.4382 - val_loss: 29.0978 - val_mse: 29.0978 - val_mean_absolute_error: 3.9863 - val_r2_func_tf: 0.9283 - val_rmse_func_tf: 5.2998 - val_bias_func_tf: -8.7910e-01 - val_sdep_func_tf: 5.0948 - 87ms/epoch - 9ms/step\n",
      "Epoch 238/300\n",
      "10/10 - 0s - loss: 54.6051 - mse: 54.6051 - mean_absolute_error: 5.9225 - r2_func_tf: 0.5720 - rmse_func_tf: 7.0804 - bias_func_tf: 0.6429 - sdep_func_tf: 4.4420 - val_loss: 29.4816 - val_mse: 29.4816 - val_mean_absolute_error: 4.0169 - val_r2_func_tf: 0.9281 - val_rmse_func_tf: 5.3390 - val_bias_func_tf: -1.0797e+00 - val_sdep_func_tf: 5.0959 - 85ms/epoch - 9ms/step\n",
      "Epoch 239/300\n",
      "10/10 - 0s - loss: 43.8776 - mse: 43.8776 - mean_absolute_error: 5.0153 - r2_func_tf: 0.8191 - rmse_func_tf: 6.2736 - bias_func_tf: -1.2780e-01 - sdep_func_tf: 4.7833 - val_loss: 29.6836 - val_mse: 29.6836 - val_mean_absolute_error: 4.0406 - val_r2_func_tf: 0.9282 - val_rmse_func_tf: 5.3596 - val_bias_func_tf: -1.1911e+00 - val_sdep_func_tf: 5.0926 - 95ms/epoch - 9ms/step\n",
      "Epoch 240/300\n",
      "10/10 - 0s - loss: 33.1634 - mse: 33.1634 - mean_absolute_error: 4.3436 - r2_func_tf: 0.3956 - rmse_func_tf: 5.5201 - bias_func_tf: 0.1665 - sdep_func_tf: 4.4805 - val_loss: 30.9487 - val_mse: 30.9487 - val_mean_absolute_error: 4.1431 - val_r2_func_tf: 0.9260 - val_rmse_func_tf: 5.4894 - val_bias_func_tf: -1.6103e+00 - val_sdep_func_tf: 5.1077 - 101ms/epoch - 10ms/step\n",
      "Epoch 241/300\n",
      "10/10 - 0s - loss: 29.1066 - mse: 29.1066 - mean_absolute_error: 4.0833 - r2_func_tf: 0.9208 - rmse_func_tf: 5.4443 - bias_func_tf: -1.1048e+00 - sdep_func_tf: 4.1601 - val_loss: 31.0967 - val_mse: 31.0967 - val_mean_absolute_error: 4.1438 - val_r2_func_tf: 0.9262 - val_rmse_func_tf: 5.5017 - val_bias_func_tf: -1.6593e+00 - val_sdep_func_tf: 5.1076 - 93ms/epoch - 9ms/step\n",
      "Epoch 242/300\n",
      "10/10 - 0s - loss: 43.8581 - mse: 43.8581 - mean_absolute_error: 4.7608 - r2_func_tf: 0.7608 - rmse_func_tf: 6.0049 - bias_func_tf: -1.1566e-01 - sdep_func_tf: 4.4485 - val_loss: 29.0500 - val_mse: 29.0500 - val_mean_absolute_error: 3.9786 - val_r2_func_tf: 0.9294 - val_rmse_func_tf: 5.2885 - val_bias_func_tf: -8.1933e-01 - val_sdep_func_tf: 5.0983 - 93ms/epoch - 9ms/step\n",
      "Epoch 243/300\n",
      "10/10 - 0s - loss: 33.3692 - mse: 33.3692 - mean_absolute_error: 4.4131 - r2_func_tf: 0.8714 - rmse_func_tf: 5.2918 - bias_func_tf: 0.1545 - sdep_func_tf: 4.3683 - val_loss: 28.4857 - val_mse: 28.4857 - val_mean_absolute_error: 3.9446 - val_r2_func_tf: 0.9301 - val_rmse_func_tf: 5.2147 - val_bias_func_tf: -3.1260e-01 - val_sdep_func_tf: 5.0866 - 89ms/epoch - 9ms/step\n",
      "Epoch 244/300\n",
      "10/10 - 0s - loss: 32.1502 - mse: 32.1502 - mean_absolute_error: 4.5717 - r2_func_tf: 0.8324 - rmse_func_tf: 5.2494 - bias_func_tf: 0.2612 - sdep_func_tf: 4.2594 - val_loss: 28.5906 - val_mse: 28.5906 - val_mean_absolute_error: 3.9400 - val_r2_func_tf: 0.9301 - val_rmse_func_tf: 5.2222 - val_bias_func_tf: -4.0923e-01 - val_sdep_func_tf: 5.0881 - 87ms/epoch - 9ms/step\n",
      "Epoch 245/300\n",
      "10/10 - 0s - loss: 40.3887 - mse: 40.3887 - mean_absolute_error: 5.0162 - r2_func_tf: 0.8193 - rmse_func_tf: 6.0122 - bias_func_tf: 0.5501 - sdep_func_tf: 4.3578 - val_loss: 28.6545 - val_mse: 28.6545 - val_mean_absolute_error: 3.9520 - val_r2_func_tf: 0.9295 - val_rmse_func_tf: 5.2235 - val_bias_func_tf: -1.8771e-01 - val_sdep_func_tf: 5.1032 - 89ms/epoch - 9ms/step\n",
      "Epoch 246/300\n",
      "10/10 - 0s - loss: 33.6019 - mse: 33.6019 - mean_absolute_error: 4.4334 - r2_func_tf: 0.8959 - rmse_func_tf: 5.9123 - bias_func_tf: -3.2338e-01 - sdep_func_tf: 4.7814 - val_loss: 28.8255 - val_mse: 28.8255 - val_mean_absolute_error: 3.9637 - val_r2_func_tf: 0.9302 - val_rmse_func_tf: 5.2539 - val_bias_func_tf: -6.4672e-01 - val_sdep_func_tf: 5.0940 - 85ms/epoch - 8ms/step\n",
      "Epoch 247/300\n",
      "10/10 - 0s - loss: 26.5345 - mse: 26.5345 - mean_absolute_error: 3.9349 - r2_func_tf: 0.9344 - rmse_func_tf: 5.0775 - bias_func_tf: 0.2381 - sdep_func_tf: 4.4246 - val_loss: 28.6304 - val_mse: 28.6304 - val_mean_absolute_error: 3.9461 - val_r2_func_tf: 0.9308 - val_rmse_func_tf: 5.2222 - val_bias_func_tf: -4.8106e-01 - val_sdep_func_tf: 5.0873 - 96ms/epoch - 10ms/step\n",
      "Epoch 248/300\n",
      "10/10 - 0s - loss: 30.9638 - mse: 30.9638 - mean_absolute_error: 4.2845 - r2_func_tf: 0.8398 - rmse_func_tf: 5.4827 - bias_func_tf: -1.0994e-02 - sdep_func_tf: 4.6910 - val_loss: 28.7201 - val_mse: 28.7201 - val_mean_absolute_error: 3.9426 - val_r2_func_tf: 0.9303 - val_rmse_func_tf: 5.2300 - val_bias_func_tf: -4.3957e-01 - val_sdep_func_tf: 5.0987 - 94ms/epoch - 9ms/step\n",
      "Epoch 249/300\n",
      "10/10 - 0s - loss: 36.9843 - mse: 36.9843 - mean_absolute_error: 4.5557 - r2_func_tf: 0.9003 - rmse_func_tf: 6.0088 - bias_func_tf: 0.5912 - sdep_func_tf: 4.4898 - val_loss: 29.0174 - val_mse: 29.0174 - val_mean_absolute_error: 3.9596 - val_r2_func_tf: 0.9294 - val_rmse_func_tf: 5.2796 - val_bias_func_tf: -7.7927e-01 - val_sdep_func_tf: 5.1026 - 94ms/epoch - 9ms/step\n",
      "Epoch 250/300\n",
      "10/10 - 0s - loss: 35.9641 - mse: 35.9641 - mean_absolute_error: 4.6442 - r2_func_tf: 0.9075 - rmse_func_tf: 5.5269 - bias_func_tf: -1.6425e-01 - sdep_func_tf: 4.4472 - val_loss: 29.6863 - val_mse: 29.6863 - val_mean_absolute_error: 4.0120 - val_r2_func_tf: 0.9280 - val_rmse_func_tf: 5.3592 - val_bias_func_tf: -1.1500e+00 - val_sdep_func_tf: 5.1106 - 95ms/epoch - 10ms/step\n",
      "Epoch 251/300\n",
      "10/10 - 0s - loss: 38.8506 - mse: 38.8506 - mean_absolute_error: 4.8885 - r2_func_tf: 0.8636 - rmse_func_tf: 5.7113 - bias_func_tf: -5.0960e-01 - sdep_func_tf: 4.4290 - val_loss: 29.4722 - val_mse: 29.4722 - val_mean_absolute_error: 3.9976 - val_r2_func_tf: 0.9279 - val_rmse_func_tf: 5.3364 - val_bias_func_tf: -9.5353e-01 - val_sdep_func_tf: 5.1288 - 90ms/epoch - 9ms/step\n",
      "Epoch 252/300\n",
      "10/10 - 0s - loss: 33.4902 - mse: 33.4902 - mean_absolute_error: 4.4420 - r2_func_tf: 0.9067 - rmse_func_tf: 5.6731 - bias_func_tf: -5.4457e-01 - sdep_func_tf: 4.3071 - val_loss: 29.3314 - val_mse: 29.3314 - val_mean_absolute_error: 4.0031 - val_r2_func_tf: 0.9280 - val_rmse_func_tf: 5.3274 - val_bias_func_tf: -9.3036e-01 - val_sdep_func_tf: 5.1228 - 99ms/epoch - 10ms/step\n",
      "Epoch 253/300\n",
      "10/10 - 0s - loss: 22.2488 - mse: 22.2488 - mean_absolute_error: 3.6271 - r2_func_tf: 0.9168 - rmse_func_tf: 4.5769 - bias_func_tf: 0.1443 - sdep_func_tf: 4.1735 - val_loss: 28.5621 - val_mse: 28.5621 - val_mean_absolute_error: 3.9598 - val_r2_func_tf: 0.9286 - val_rmse_func_tf: 5.2449 - val_bias_func_tf: -4.3848e-01 - val_sdep_func_tf: 5.1075 - 89ms/epoch - 9ms/step\n",
      "Epoch 254/300\n",
      "10/10 - 0s - loss: 29.7496 - mse: 29.7496 - mean_absolute_error: 4.2376 - r2_func_tf: 0.3053 - rmse_func_tf: 5.2595 - bias_func_tf: 0.5997 - sdep_func_tf: 4.4867 - val_loss: 28.4482 - val_mse: 28.4482 - val_mean_absolute_error: 3.9543 - val_r2_func_tf: 0.9287 - val_rmse_func_tf: 5.2309 - val_bias_func_tf: -3.2399e-01 - val_sdep_func_tf: 5.1028 - 86ms/epoch - 9ms/step\n",
      "Epoch 255/300\n",
      "10/10 - 0s - loss: 25.4519 - mse: 25.4519 - mean_absolute_error: 3.9161 - r2_func_tf: 0.9073 - rmse_func_tf: 4.9534 - bias_func_tf: -1.0247e-01 - sdep_func_tf: 4.4731 - val_loss: 28.5349 - val_mse: 28.5349 - val_mean_absolute_error: 3.9446 - val_r2_func_tf: 0.9292 - val_rmse_func_tf: 5.2341 - val_bias_func_tf: -5.2985e-01 - val_sdep_func_tf: 5.0917 - 90ms/epoch - 9ms/step\n",
      "Epoch 256/300\n",
      "10/10 - 0s - loss: 36.3221 - mse: 36.3221 - mean_absolute_error: 4.6463 - r2_func_tf: 0.9084 - rmse_func_tf: 5.7612 - bias_func_tf: -1.1079e-01 - sdep_func_tf: 4.5830 - val_loss: 28.6516 - val_mse: 28.6516 - val_mean_absolute_error: 3.9465 - val_r2_func_tf: 0.9286 - val_rmse_func_tf: 5.2449 - val_bias_func_tf: -4.2086e-01 - val_sdep_func_tf: 5.1142 - 86ms/epoch - 9ms/step\n",
      "Epoch 257/300\n",
      "10/10 - 0s - loss: 30.6364 - mse: 30.6364 - mean_absolute_error: 4.2092 - r2_func_tf: 0.9201 - rmse_func_tf: 5.3592 - bias_func_tf: 0.1863 - sdep_func_tf: 4.6786 - val_loss: 28.9898 - val_mse: 28.9898 - val_mean_absolute_error: 3.9606 - val_r2_func_tf: 0.9284 - val_rmse_func_tf: 5.2863 - val_bias_func_tf: -6.6649e-01 - val_sdep_func_tf: 5.1287 - 87ms/epoch - 9ms/step\n",
      "Epoch 258/300\n",
      "10/10 - 0s - loss: 28.2358 - mse: 28.2358 - mean_absolute_error: 4.1039 - r2_func_tf: 0.9246 - rmse_func_tf: 5.2644 - bias_func_tf: 0.2943 - sdep_func_tf: 4.4711 - val_loss: 28.9110 - val_mse: 28.9110 - val_mean_absolute_error: 3.9691 - val_r2_func_tf: 0.9274 - val_rmse_func_tf: 5.2700 - val_bias_func_tf: -2.6858e-01 - val_sdep_func_tf: 5.1521 - 88ms/epoch - 9ms/step\n",
      "Epoch 259/300\n",
      "10/10 - 0s - loss: 35.9940 - mse: 35.9940 - mean_absolute_error: 4.3903 - r2_func_tf: 0.7466 - rmse_func_tf: 5.9484 - bias_func_tf: 0.6361 - sdep_func_tf: 4.5265 - val_loss: 28.9753 - val_mse: 28.9753 - val_mean_absolute_error: 3.9677 - val_r2_func_tf: 0.9278 - val_rmse_func_tf: 5.2857 - val_bias_func_tf: -5.2355e-01 - val_sdep_func_tf: 5.1463 - 96ms/epoch - 10ms/step\n",
      "Epoch 260/300\n",
      "10/10 - 0s - loss: 29.5895 - mse: 29.5895 - mean_absolute_error: 4.3814 - r2_func_tf: 0.9203 - rmse_func_tf: 5.2692 - bias_func_tf: -1.3908e-01 - sdep_func_tf: 4.2727 - val_loss: 29.6668 - val_mse: 29.6668 - val_mean_absolute_error: 4.0066 - val_r2_func_tf: 0.9278 - val_rmse_func_tf: 5.3703 - val_bias_func_tf: -1.0757e+00 - val_sdep_func_tf: 5.1394 - 92ms/epoch - 9ms/step\n",
      "Epoch 261/300\n",
      "10/10 - 0s - loss: 25.3088 - mse: 25.3088 - mean_absolute_error: 3.7687 - r2_func_tf: 0.9349 - rmse_func_tf: 4.9697 - bias_func_tf: -1.7655e-01 - sdep_func_tf: 4.1957 - val_loss: 29.7132 - val_mse: 29.7132 - val_mean_absolute_error: 4.0123 - val_r2_func_tf: 0.9276 - val_rmse_func_tf: 5.3722 - val_bias_func_tf: -1.0653e+00 - val_sdep_func_tf: 5.1426 - 90ms/epoch - 9ms/step\n",
      "Epoch 262/300\n",
      "10/10 - 0s - loss: 31.3297 - mse: 31.3297 - mean_absolute_error: 4.1738 - r2_func_tf: 0.9173 - rmse_func_tf: 5.7939 - bias_func_tf: -1.2216e+00 - sdep_func_tf: 4.5105 - val_loss: 29.7933 - val_mse: 29.7933 - val_mean_absolute_error: 4.0298 - val_r2_func_tf: 0.9276 - val_rmse_func_tf: 5.3826 - val_bias_func_tf: -1.1411e+00 - val_sdep_func_tf: 5.1372 - 94ms/epoch - 9ms/step\n",
      "Epoch 263/300\n",
      "10/10 - 0s - loss: 30.4043 - mse: 30.4043 - mean_absolute_error: 4.2594 - r2_func_tf: 0.8925 - rmse_func_tf: 5.1661 - bias_func_tf: -5.5388e-01 - sdep_func_tf: 4.3293 - val_loss: 29.1422 - val_mse: 29.1422 - val_mean_absolute_error: 3.9985 - val_r2_func_tf: 0.9275 - val_rmse_func_tf: 5.3088 - val_bias_func_tf: -5.3560e-01 - val_sdep_func_tf: 5.1681 - 91ms/epoch - 9ms/step\n",
      "Epoch 264/300\n",
      "10/10 - 0s - loss: 24.8860 - mse: 24.8860 - mean_absolute_error: 3.9313 - r2_func_tf: 0.9434 - rmse_func_tf: 4.5289 - bias_func_tf: 0.0722 - sdep_func_tf: 4.0461 - val_loss: 29.2778 - val_mse: 29.2778 - val_mean_absolute_error: 4.0245 - val_r2_func_tf: 0.9264 - val_rmse_func_tf: 5.3249 - val_bias_func_tf: -3.9789e-01 - val_sdep_func_tf: 5.1959 - 87ms/epoch - 9ms/step\n",
      "Epoch 265/300\n",
      "10/10 - 0s - loss: 30.9638 - mse: 30.9638 - mean_absolute_error: 4.3104 - r2_func_tf: 0.9190 - rmse_func_tf: 5.5184 - bias_func_tf: 0.3318 - sdep_func_tf: 4.7436 - val_loss: 29.1202 - val_mse: 29.1202 - val_mean_absolute_error: 4.0301 - val_r2_func_tf: 0.9267 - val_rmse_func_tf: 5.3010 - val_bias_func_tf: -1.5738e-01 - val_sdep_func_tf: 5.1863 - 91ms/epoch - 9ms/step\n",
      "Epoch 266/300\n",
      "10/10 - 0s - loss: 35.7739 - mse: 35.7739 - mean_absolute_error: 4.4081 - r2_func_tf: 0.5211 - rmse_func_tf: 6.2401 - bias_func_tf: 1.7128 - sdep_func_tf: 4.3329 - val_loss: 29.0829 - val_mse: 29.0829 - val_mean_absolute_error: 4.0192 - val_r2_func_tf: 0.9277 - val_rmse_func_tf: 5.2930 - val_bias_func_tf: -2.3246e-01 - val_sdep_func_tf: 5.1747 - 91ms/epoch - 9ms/step\n",
      "Epoch 267/300\n",
      "10/10 - 0s - loss: 41.3069 - mse: 41.3069 - mean_absolute_error: 4.9518 - r2_func_tf: 0.8892 - rmse_func_tf: 6.4980 - bias_func_tf: -8.0035e-01 - sdep_func_tf: 4.7955 - val_loss: 30.0111 - val_mse: 30.0111 - val_mean_absolute_error: 4.0450 - val_r2_func_tf: 0.9282 - val_rmse_func_tf: 5.4022 - val_bias_func_tf: -1.1613e+00 - val_sdep_func_tf: 5.1512 - 90ms/epoch - 9ms/step\n",
      "Epoch 268/300\n",
      "10/10 - 0s - loss: 29.4783 - mse: 29.4783 - mean_absolute_error: 4.1829 - r2_func_tf: 0.3270 - rmse_func_tf: 5.2441 - bias_func_tf: 0.0036 - sdep_func_tf: 4.5413 - val_loss: 29.5406 - val_mse: 29.5406 - val_mean_absolute_error: 4.0079 - val_r2_func_tf: 0.9282 - val_rmse_func_tf: 5.3553 - val_bias_func_tf: -8.5164e-01 - val_sdep_func_tf: 5.1644 - 90ms/epoch - 9ms/step\n",
      "Epoch 269/300\n",
      "10/10 - 0s - loss: 27.7439 - mse: 27.7439 - mean_absolute_error: 3.9661 - r2_func_tf: 0.7276 - rmse_func_tf: 5.4045 - bias_func_tf: 0.5207 - sdep_func_tf: 4.3955 - val_loss: 29.3824 - val_mse: 29.3824 - val_mean_absolute_error: 3.9981 - val_r2_func_tf: 0.9281 - val_rmse_func_tf: 5.3395 - val_bias_func_tf: -7.0837e-01 - val_sdep_func_tf: 5.1729 - 89ms/epoch - 9ms/step\n",
      "Epoch 270/300\n",
      "10/10 - 0s - loss: 35.3592 - mse: 35.3592 - mean_absolute_error: 4.5075 - r2_func_tf: 0.8929 - rmse_func_tf: 5.2579 - bias_func_tf: 0.0184 - sdep_func_tf: 4.3650 - val_loss: 29.7262 - val_mse: 29.7262 - val_mean_absolute_error: 4.0057 - val_r2_func_tf: 0.9275 - val_rmse_func_tf: 5.3750 - val_bias_func_tf: -8.7661e-01 - val_sdep_func_tf: 5.1838 - 87ms/epoch - 9ms/step\n",
      "Epoch 271/300\n",
      "10/10 - 0s - loss: 35.4467 - mse: 35.4467 - mean_absolute_error: 4.6825 - r2_func_tf: 0.8384 - rmse_func_tf: 5.8963 - bias_func_tf: -3.5377e-01 - sdep_func_tf: 4.7686 - val_loss: 30.0263 - val_mse: 30.0263 - val_mean_absolute_error: 4.0282 - val_r2_func_tf: 0.9269 - val_rmse_func_tf: 5.4062 - val_bias_func_tf: -1.0130e+00 - val_sdep_func_tf: 5.1905 - 91ms/epoch - 9ms/step\n",
      "Epoch 272/300\n",
      "10/10 - 0s - loss: 40.5907 - mse: 40.5907 - mean_absolute_error: 4.8066 - r2_func_tf: 0.7600 - rmse_func_tf: 6.3013 - bias_func_tf: 0.4764 - sdep_func_tf: 4.6709 - val_loss: 29.4797 - val_mse: 29.4797 - val_mean_absolute_error: 4.0001 - val_r2_func_tf: 0.9276 - val_rmse_func_tf: 5.3444 - val_bias_func_tf: -6.5451e-01 - val_sdep_func_tf: 5.1894 - 89ms/epoch - 9ms/step\n",
      "Epoch 273/300\n",
      "10/10 - 0s - loss: 43.5688 - mse: 43.5688 - mean_absolute_error: 5.0471 - r2_func_tf: 0.8642 - rmse_func_tf: 5.8639 - bias_func_tf: -4.8684e-01 - sdep_func_tf: 4.3856 - val_loss: 29.5017 - val_mse: 29.5017 - val_mean_absolute_error: 4.0119 - val_r2_func_tf: 0.9275 - val_rmse_func_tf: 5.3492 - val_bias_func_tf: -8.2459e-01 - val_sdep_func_tf: 5.1688 - 89ms/epoch - 9ms/step\n",
      "Epoch 274/300\n",
      "10/10 - 0s - loss: 44.9604 - mse: 44.9604 - mean_absolute_error: 5.2015 - r2_func_tf: 0.8677 - rmse_func_tf: 6.8598 - bias_func_tf: -9.1679e-01 - sdep_func_tf: 4.5275 - val_loss: 28.9381 - val_mse: 28.9381 - val_mean_absolute_error: 3.9884 - val_r2_func_tf: 0.9284 - val_rmse_func_tf: 5.2824 - val_bias_func_tf: -5.8039e-01 - val_sdep_func_tf: 5.1389 - 88ms/epoch - 9ms/step\n",
      "Epoch 275/300\n",
      "10/10 - 0s - loss: 24.0676 - mse: 24.0676 - mean_absolute_error: 3.7105 - r2_func_tf: 0.9427 - rmse_func_tf: 4.7397 - bias_func_tf: 0.0291 - sdep_func_tf: 4.3991 - val_loss: 28.4021 - val_mse: 28.4021 - val_mean_absolute_error: 3.9763 - val_r2_func_tf: 0.9292 - val_rmse_func_tf: 5.2187 - val_bias_func_tf: -2.4994e-01 - val_sdep_func_tf: 5.1042 - 89ms/epoch - 9ms/step\n",
      "Epoch 276/300\n",
      "10/10 - 0s - loss: 29.1056 - mse: 29.1056 - mean_absolute_error: 4.1761 - r2_func_tf: 0.7270 - rmse_func_tf: 5.5541 - bias_func_tf: 1.0106 - sdep_func_tf: 4.4363 - val_loss: 28.3708 - val_mse: 28.3708 - val_mean_absolute_error: 3.9856 - val_r2_func_tf: 0.9291 - val_rmse_func_tf: 5.2005 - val_bias_func_tf: 0.0250 - val_sdep_func_tf: 5.0973 - 86ms/epoch - 9ms/step\n",
      "Epoch 277/300\n",
      "10/10 - 0s - loss: 43.2877 - mse: 43.2877 - mean_absolute_error: 5.3180 - r2_func_tf: 0.7918 - rmse_func_tf: 6.2313 - bias_func_tf: 0.3428 - sdep_func_tf: 4.3580 - val_loss: 28.4407 - val_mse: 28.4407 - val_mean_absolute_error: 3.9725 - val_r2_func_tf: 0.9299 - val_rmse_func_tf: 5.2125 - val_bias_func_tf: -2.6963e-01 - val_sdep_func_tf: 5.1041 - 90ms/epoch - 9ms/step\n",
      "Epoch 278/300\n",
      "10/10 - 0s - loss: 29.5250 - mse: 29.5250 - mean_absolute_error: 4.2579 - r2_func_tf: 0.9285 - rmse_func_tf: 5.2454 - bias_func_tf: 0.2735 - sdep_func_tf: 4.2639 - val_loss: 28.5784 - val_mse: 28.5784 - val_mean_absolute_error: 3.9813 - val_r2_func_tf: 0.9300 - val_rmse_func_tf: 5.2411 - val_bias_func_tf: -4.8404e-01 - val_sdep_func_tf: 5.1138 - 91ms/epoch - 9ms/step\n",
      "Epoch 279/300\n",
      "10/10 - 0s - loss: 26.9755 - mse: 26.9755 - mean_absolute_error: 3.9173 - r2_func_tf: 0.6560 - rmse_func_tf: 5.2298 - bias_func_tf: 0.2139 - sdep_func_tf: 4.2969 - val_loss: 28.7893 - val_mse: 28.7893 - val_mean_absolute_error: 3.9813 - val_r2_func_tf: 0.9298 - val_rmse_func_tf: 5.2683 - val_bias_func_tf: -6.4921e-01 - val_sdep_func_tf: 5.1222 - 93ms/epoch - 9ms/step\n",
      "Epoch 280/300\n",
      "10/10 - 0s - loss: 43.2464 - mse: 43.2464 - mean_absolute_error: 4.8342 - r2_func_tf: 0.7990 - rmse_func_tf: 6.9550 - bias_func_tf: -1.7544e+00 - sdep_func_tf: 4.6032 - val_loss: 29.5024 - val_mse: 29.5024 - val_mean_absolute_error: 4.0152 - val_r2_func_tf: 0.9291 - val_rmse_func_tf: 5.3451 - val_bias_func_tf: -1.1254e+00 - val_sdep_func_tf: 5.1164 - 88ms/epoch - 9ms/step\n",
      "Epoch 281/300\n",
      "10/10 - 0s - loss: 29.8579 - mse: 29.8579 - mean_absolute_error: 4.4088 - r2_func_tf: 0.9240 - rmse_func_tf: 5.3278 - bias_func_tf: 0.3498 - sdep_func_tf: 4.4846 - val_loss: 28.4971 - val_mse: 28.4971 - val_mean_absolute_error: 3.9906 - val_r2_func_tf: 0.9294 - val_rmse_func_tf: 5.2079 - val_bias_func_tf: 0.1598 - val_sdep_func_tf: 5.1095 - 89ms/epoch - 9ms/step\n",
      "Epoch 282/300\n",
      "10/10 - 0s - loss: 32.0406 - mse: 32.0406 - mean_absolute_error: 4.4727 - r2_func_tf: 0.9050 - rmse_func_tf: 5.7682 - bias_func_tf: -3.1757e-02 - sdep_func_tf: 4.6876 - val_loss: 28.9243 - val_mse: 28.9243 - val_mean_absolute_error: 4.0238 - val_r2_func_tf: 0.9282 - val_rmse_func_tf: 5.2341 - val_bias_func_tf: 0.5025 - val_sdep_func_tf: 5.1149 - 91ms/epoch - 9ms/step\n",
      "Epoch 283/300\n",
      "10/10 - 0s - loss: 54.8917 - mse: 54.8917 - mean_absolute_error: 5.5133 - r2_func_tf: 0.6174 - rmse_func_tf: 7.0479 - bias_func_tf: 0.5557 - sdep_func_tf: 4.9223 - val_loss: 28.7344 - val_mse: 28.7344 - val_mean_absolute_error: 3.9964 - val_r2_func_tf: 0.9289 - val_rmse_func_tf: 5.2153 - val_bias_func_tf: 0.2430 - val_sdep_func_tf: 5.1171 - 91ms/epoch - 9ms/step\n",
      "Epoch 284/300\n",
      "10/10 - 0s - loss: 28.3642 - mse: 28.3642 - mean_absolute_error: 4.1591 - r2_func_tf: 0.8590 - rmse_func_tf: 5.3166 - bias_func_tf: 0.5755 - sdep_func_tf: 4.4255 - val_loss: 28.5048 - val_mse: 28.5048 - val_mean_absolute_error: 3.9838 - val_r2_func_tf: 0.9296 - val_rmse_func_tf: 5.2105 - val_bias_func_tf: -6.4290e-02 - val_sdep_func_tf: 5.1162 - 100ms/epoch - 10ms/step\n",
      "Epoch 285/300\n",
      "10/10 - 0s - loss: 29.6572 - mse: 29.6572 - mean_absolute_error: 4.1323 - r2_func_tf: 0.8975 - rmse_func_tf: 5.1656 - bias_func_tf: -4.0684e-01 - sdep_func_tf: 4.3490 - val_loss: 28.6735 - val_mse: 28.6735 - val_mean_absolute_error: 3.9802 - val_r2_func_tf: 0.9299 - val_rmse_func_tf: 5.2454 - val_bias_func_tf: -5.1046e-01 - val_sdep_func_tf: 5.1208 - 96ms/epoch - 10ms/step\n",
      "Epoch 286/300\n",
      "10/10 - 0s - loss: 53.7706 - mse: 53.7706 - mean_absolute_error: 5.6608 - r2_func_tf: 0.4208 - rmse_func_tf: 7.5392 - bias_func_tf: 0.9053 - sdep_func_tf: 4.5352 - val_loss: 28.7832 - val_mse: 28.7832 - val_mean_absolute_error: 3.9933 - val_r2_func_tf: 0.9294 - val_rmse_func_tf: 5.2524 - val_bias_func_tf: -3.7381e-01 - val_sdep_func_tf: 5.1382 - 89ms/epoch - 9ms/step\n",
      "Epoch 287/300\n",
      "10/10 - 0s - loss: 36.9915 - mse: 36.9915 - mean_absolute_error: 4.5842 - r2_func_tf: 0.7908 - rmse_func_tf: 5.9265 - bias_func_tf: -6.1052e-01 - sdep_func_tf: 4.8020 - val_loss: 30.1031 - val_mse: 30.1031 - val_mean_absolute_error: 4.0672 - val_r2_func_tf: 0.9276 - val_rmse_func_tf: 5.4120 - val_bias_func_tf: -1.2057e+00 - val_sdep_func_tf: 5.1616 - 87ms/epoch - 9ms/step\n",
      "Epoch 288/300\n",
      "10/10 - 0s - loss: 33.3535 - mse: 33.3535 - mean_absolute_error: 4.6398 - r2_func_tf: 0.9026 - rmse_func_tf: 5.5430 - bias_func_tf: -4.7881e-02 - sdep_func_tf: 4.3757 - val_loss: 29.6822 - val_mse: 29.6822 - val_mean_absolute_error: 4.0195 - val_r2_func_tf: 0.9277 - val_rmse_func_tf: 5.3645 - val_bias_func_tf: -8.6920e-01 - val_sdep_func_tf: 5.1834 - 85ms/epoch - 9ms/step\n",
      "Epoch 289/300\n",
      "10/10 - 0s - loss: 47.6615 - mse: 47.6615 - mean_absolute_error: 5.1385 - r2_func_tf: 0.8138 - rmse_func_tf: 7.2794 - bias_func_tf: -1.1348e+00 - sdep_func_tf: 4.8964 - val_loss: 29.7046 - val_mse: 29.7046 - val_mean_absolute_error: 4.0206 - val_r2_func_tf: 0.9281 - val_rmse_func_tf: 5.3670 - val_bias_func_tf: -8.2628e-01 - val_sdep_func_tf: 5.1901 - 84ms/epoch - 8ms/step\n",
      "Epoch 290/300\n",
      "10/10 - 0s - loss: 49.4718 - mse: 49.4718 - mean_absolute_error: 5.2023 - r2_func_tf: 0.7414 - rmse_func_tf: 6.0756 - bias_func_tf: 0.0229 - sdep_func_tf: 4.2896 - val_loss: 29.5168 - val_mse: 29.5168 - val_mean_absolute_error: 4.0315 - val_r2_func_tf: 0.9281 - val_rmse_func_tf: 5.3391 - val_bias_func_tf: -2.2957e-01 - val_sdep_func_tf: 5.2181 - 85ms/epoch - 8ms/step\n",
      "Epoch 291/300\n",
      "10/10 - 0s - loss: 29.8273 - mse: 29.8273 - mean_absolute_error: 4.1984 - r2_func_tf: 0.8970 - rmse_func_tf: 5.0900 - bias_func_tf: 0.7032 - sdep_func_tf: 4.3548 - val_loss: 29.5470 - val_mse: 29.5470 - val_mean_absolute_error: 4.0168 - val_r2_func_tf: 0.9288 - val_rmse_func_tf: 5.3504 - val_bias_func_tf: -4.8955e-01 - val_sdep_func_tf: 5.2076 - 85ms/epoch - 9ms/step\n",
      "Epoch 292/300\n",
      "10/10 - 0s - loss: 35.8135 - mse: 35.8135 - mean_absolute_error: 4.6803 - r2_func_tf: 0.9095 - rmse_func_tf: 5.6816 - bias_func_tf: 0.6788 - sdep_func_tf: 4.4838 - val_loss: 29.3583 - val_mse: 29.3583 - val_mean_absolute_error: 4.0024 - val_r2_func_tf: 0.9295 - val_rmse_func_tf: 5.3307 - val_bias_func_tf: -5.6733e-01 - val_sdep_func_tf: 5.1831 - 90ms/epoch - 9ms/step\n",
      "Epoch 293/300\n",
      "10/10 - 0s - loss: 34.8162 - mse: 34.8162 - mean_absolute_error: 4.4485 - r2_func_tf: 0.8950 - rmse_func_tf: 6.1271 - bias_func_tf: -9.6805e-01 - sdep_func_tf: 4.7640 - val_loss: 29.5561 - val_mse: 29.5561 - val_mean_absolute_error: 4.0202 - val_r2_func_tf: 0.9299 - val_rmse_func_tf: 5.3458 - val_bias_func_tf: -9.3078e-01 - val_sdep_func_tf: 5.1518 - 89ms/epoch - 9ms/step\n",
      "Epoch 294/300\n",
      "10/10 - 0s - loss: 37.0817 - mse: 37.0817 - mean_absolute_error: 4.7084 - r2_func_tf: 0.8998 - rmse_func_tf: 5.6589 - bias_func_tf: -2.2460e-01 - sdep_func_tf: 4.4732 - val_loss: 28.6902 - val_mse: 28.6902 - val_mean_absolute_error: 3.9966 - val_r2_func_tf: 0.9306 - val_rmse_func_tf: 5.2355 - val_bias_func_tf: -8.6581e-02 - val_sdep_func_tf: 5.1279 - 88ms/epoch - 9ms/step\n",
      "Epoch 295/300\n",
      "10/10 - 0s - loss: 51.1439 - mse: 51.1439 - mean_absolute_error: 5.2785 - r2_func_tf: 0.7914 - rmse_func_tf: 6.4756 - bias_func_tf: 0.9252 - sdep_func_tf: 4.6635 - val_loss: 28.6237 - val_mse: 28.6237 - val_mean_absolute_error: 3.9948 - val_r2_func_tf: 0.9302 - val_rmse_func_tf: 5.2270 - val_bias_func_tf: -5.4506e-02 - val_sdep_func_tf: 5.1197 - 87ms/epoch - 9ms/step\n",
      "Epoch 296/300\n",
      "10/10 - 0s - loss: 35.3958 - mse: 35.3958 - mean_absolute_error: 4.4964 - r2_func_tf: 0.5352 - rmse_func_tf: 5.7483 - bias_func_tf: 0.7710 - sdep_func_tf: 4.5092 - val_loss: 28.4878 - val_mse: 28.4878 - val_mean_absolute_error: 3.9834 - val_r2_func_tf: 0.9305 - val_rmse_func_tf: 5.2210 - val_bias_func_tf: -2.6542e-01 - val_sdep_func_tf: 5.1069 - 86ms/epoch - 9ms/step\n",
      "Epoch 297/300\n",
      "10/10 - 0s - loss: 36.8286 - mse: 36.8286 - mean_absolute_error: 4.9116 - r2_func_tf: 0.9118 - rmse_func_tf: 5.9351 - bias_func_tf: 0.3573 - sdep_func_tf: 4.6114 - val_loss: 28.9273 - val_mse: 28.9273 - val_mean_absolute_error: 3.9910 - val_r2_func_tf: 0.9299 - val_rmse_func_tf: 5.2804 - val_bias_func_tf: -7.4069e-01 - val_sdep_func_tf: 5.1177 - 88ms/epoch - 9ms/step\n",
      "Epoch 298/300\n",
      "10/10 - 0s - loss: 38.6689 - mse: 38.6689 - mean_absolute_error: 4.7790 - r2_func_tf: 0.8863 - rmse_func_tf: 6.1868 - bias_func_tf: 0.4800 - sdep_func_tf: 4.5507 - val_loss: 28.6474 - val_mse: 28.6474 - val_mean_absolute_error: 3.9670 - val_r2_func_tf: 0.9298 - val_rmse_func_tf: 5.2452 - val_bias_func_tf: -4.9558e-01 - val_sdep_func_tf: 5.1156 - 88ms/epoch - 9ms/step\n",
      "Epoch 299/300\n",
      "10/10 - 0s - loss: 35.4815 - mse: 35.4815 - mean_absolute_error: 4.2427 - r2_func_tf: 0.8989 - rmse_func_tf: 6.2784 - bias_func_tf: -1.6388e+00 - sdep_func_tf: 4.7964 - val_loss: 29.4493 - val_mse: 29.4493 - val_mean_absolute_error: 4.0024 - val_r2_func_tf: 0.9295 - val_rmse_func_tf: 5.3291 - val_bias_func_tf: -1.1014e+00 - val_sdep_func_tf: 5.1063 - 88ms/epoch - 9ms/step\n",
      "Epoch 300/300\n",
      "10/10 - 0s - loss: 31.7737 - mse: 31.7737 - mean_absolute_error: 4.3780 - r2_func_tf: 0.8530 - rmse_func_tf: 5.9216 - bias_func_tf: -1.1823e+00 - sdep_func_tf: 4.7203 - val_loss: 28.8319 - val_mse: 28.8319 - val_mean_absolute_error: 3.9865 - val_r2_func_tf: 0.9295 - val_rmse_func_tf: 5.2514 - val_bias_func_tf: -2.4400e-01 - val_sdep_func_tf: 5.1431 - 87ms/epoch - 9ms/step\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Load Hyper parameters for final model\n",
    "hp = kt.HyperParameters()\n",
    "\n",
    "model_type1 = hp.Choice(\"model_type1\", [best_hps.values[0, 0]])\n",
    "model_type = hp.Choice(\"model_type\", [best_hps.values[0, 1]])\n",
    "hp_layer_1= hp.Choice(f'layer_1', values=[best_hps.values[0, 4]])\n",
    "hp_layer_2_2= hp.Choice(f'layer_2_2', values=[best_hps.values[0, 3]])\n",
    "hp_layer_3_3= hp.Choice(f'layer_3_3',  values=[best_hps.values[0, 2]])\n",
    "\n",
    "# Build final model\n",
    "test_model=build_model(hp)\n",
    "\n",
    "# Inputs for training final Model\n",
    "epochs = 300\n",
    "# batch  = 16\n",
    "# TODO: Use path lib to create path\n",
    "resample_path = path_resample(home,resample)\n",
    "\n",
    "# model_name = architecture of - Single task/RF/KNN + dH/dG/dS/Tm or - Multitask  \n",
    "# prop = 'dH' \n",
    "# model_name = f\"1DConv_st_{prop}\" \n",
    "\n",
    "\n",
    "# Define the directory path\n",
    "directory_path = Path(f\"{os.getcwd()}/CV/{resample}/{desc}/{model_name}/\")\n",
    "\n",
    "# Define Paths for call backs\n",
    "csv_logger_path  = Path(f'{directory_path}/csv_logger/')\n",
    "cp_callback_path = Path(f'{directory_path}/model_checkpoint/')\n",
    "tensorboard_path = Path(f'{directory_path}/tensorboard_logs/')\n",
    "\n",
    "# Ensure the directory exists, create it if necessary\n",
    "csv_logger_path.mkdir(parents=True, exist_ok=True)\n",
    "cp_callback_path.mkdir(parents=True, exist_ok=True)\n",
    "tensorboard_path.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "\n",
    "#### CALL BACKS!\n",
    "es = EarlyStopping(monitor      = 'val_loss', \n",
    "                        mode     = 'min', \n",
    "                        verbose  = 1, \n",
    "                        patience = 2000, \n",
    "                    restore_best_weights = True)\n",
    "# CSV Logger\n",
    "csv_logger = CSVLogger(f'{csv_logger_path}/model_history.csv' , append=True)\n",
    "\n",
    "# CP_callbacks      not required when using a tunner       \n",
    "# cp_callback = tf.keras.callbacks.ModelCheckpoint(filepath=f'{cp_callback_path}/cp.ckpt',\n",
    "#                                                  save_weights_only=True,\n",
    "#                                                  verbose=1)\n",
    "\n",
    "# TensorBoard\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=tensorboard_path, \n",
    "                                                       #/{batch}', # _ADAPTIVELEARNIGNRATE_01_10_Dense3_64_3CNN_lr_3_es\n",
    "                                                      update_freq = 1,\n",
    "                                                      # histogram_freq=1, \n",
    "                                                      write_graph=False, \n",
    "                                                      write_images=False)\n",
    "# https://www.tensorflow.org/api_docs/python/tf/keras/callbacks/TensorBoard\n",
    "\n",
    "# Covert to list and provide to Keras Regressor\n",
    "keras_callbacks = [es, csv_logger, tensorboard_callback]\n",
    "\n",
    "# Load resample data\n",
    "y_1_train, y_2_train, y_3_train, y_4_train, Y_train, X_padded_train, X_train = load_xy(train,desc)\n",
    "y_1_val,   y_2_val,   y_3_val,   y_4_val,   Y_val,   X_padded_val,   X_val   = load_xy(val,desc)\n",
    "y_1_test,  y_2_test,  y_3_test,  y_4_test,  Y_test,  X_padded_test,  X_test  = load_xy(test,desc)\n",
    "\n",
    "# Train model on resample data\n",
    "\n",
    "ys_train = [y_1_train,y_2_train,y_3_train,y_4_train] \n",
    "ys_val   = [y_1_val,y_2_val,y_3_val,y_4_val]\n",
    "ys_test  = [y_1_test,y_2_test,y_3_test,y_4_test]\n",
    "GSHT_list.index(f'{prop}')+1\n",
    "\n",
    "hp = kt.HyperParameters()\n",
    "\n",
    "model_type1 = hp.Choice(\"model_type1\", [best_hps.values[0, 0]])\n",
    "model_type = hp.Choice(\"model_type\", [best_hps.values[0, 1]])\n",
    "hp_layer_1= hp.Choice(f'layer_1', values=[best_hps.values[0, 4]])\n",
    "hp_layer_2_2= hp.Choice(f'layer_2_2', values=[best_hps.values[0, 3]])\n",
    "hp_layer_3_3= hp.Choice(f'layer_3_3',  values=[best_hps.values[0, 2]])\n",
    "\n",
    "# Build final model\n",
    "test_model=build_model(hp)\n",
    "\n",
    "history=test_model.fit(X_padded_train, ys_train[GSHT_list.index(f'{prop}')],\n",
    "            epochs = epochs,\n",
    "            batch_size=batch,\n",
    "            verbose = 2,\n",
    "            validation_data =(X_padded_val, ys_val[GSHT_list.index(f'{prop}')]),\n",
    "             # validation_split = 0.2,\n",
    "            callbacks=keras_callbacks)\n",
    "# Make predictions\n",
    "\n",
    "\n",
    "# Store stats\n",
    "\n",
    "\n",
    "# Store csv files (predictions vs true)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 369,
   "id": "f628ba6c-fd31-4462-b50c-64c4e4f9403c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ -46.3,  -55.4,  -89.9,  -59.8,  -78.9,  -62.8,  -51.7,  -60.7,\n",
       "        -69.7,  -44.2,  -54.6,  -37. ,  -59.3,  -66.9,  -58.6,  -68. ,\n",
       "        -53.1,  -58.6,  -47. ,  -73.3,  -69.6,  -66.8,  -70.6,  -67.9,\n",
       "       -102. , -115.2, -125.6, -123.9,  -60.5,  -84.8,  -57.7,  -41.4,\n",
       "        -62.1,  -36.3, -102.8,  -46.4, -112.4, -104.4,  -60.3,  -76.7,\n",
       "        -47. ,  -62.6,  -40.4,  -35.9,  -56.8,  -57.7, -120.5,  -55.6,\n",
       "       -120.2,  -59.7,  -56.1,  -57.5,  -67.4,  -68.8, -142.7,  -64.3,\n",
       "        -61. ,  -61.4,  -62.3,  -60.4,  -63.1,  -66.4,  -59.3,  -59.6])"
      ]
     },
     "execution_count": 369,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ys_val[GSHT_list.index(f'{prop}')]\n",
    "ys_val[GSHT_list.index(f'{prop}')]\n",
    "# ys_val[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 381,
   "id": "57e8af4e-b67b-4419-8bd7-f784d83e41e0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model_type1</th>\n",
       "      <th>model_type</th>\n",
       "      <th>layer_3_3</th>\n",
       "      <th>layer_2_2</th>\n",
       "      <th>r2_dH_0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>CNN3</td>\n",
       "      <td>Dense3</td>\n",
       "      <td>16.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>0.935</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  model_type1 model_type layer_3_3 layer_2_2 r2_dH_0\n",
       "7        CNN3     Dense3      16.0      32.0   0.935"
      ]
     },
     "execution_count": 381,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history.params\n",
    "history.model\n",
    "history.validation_data\n",
    "# history.history\n",
    "test_model.get_config()\n",
    "hp = kt.HyperParameters()\n",
    "\n",
    "model_type1 = hp.Choice(\"model_type1\", [best_hps.values[0, 0]])\n",
    "model_type = hp.Choice(\"model_type\", [best_hps.values[0, 1]])\n",
    "hp_layer_1= hp.Choice(f'layer_1', values=[best_hps.values[0, 4]])\n",
    "hp_layer_2_2= hp.Choice(f'layer_2_2', values=[best_hps.values[0, 3]])\n",
    "hp_layer_3_3= hp.Choice(f'layer_3_3',  values=[best_hps.values[0, 2]])\n",
    "\n",
    "# Build final model\n",
    "# test_model=build_model(hp)\n",
    "hp_layer_3_3\n",
    "best_hps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90b8f69f-bf97-4da7-a78b-1c78cd81689a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def stats_csv(y_test_pred, Y_test, prop, csv_name, set_type,resample):\n",
    "    y_test_np = Y_test[f'{prop}'].to_numpy()\n",
    "    y_pred_test_np = y_test_pred\n",
    "\n",
    "    r2_test = r2_score(y_test_np, y_pred_test_np)\n",
    "    rmsd_test = (mean_squared_error(y_test_np, y_pred_test_np))**0.5\n",
    "    bias_test = np.mean(y_pred_test_np - y_test_np)\n",
    "    sdep_test = (np.mean((y_pred_test_np - y_test_np - bias_test)**2))**0.5\n",
    "    r2 = '{:.3f}'.format(r2_test)\n",
    "    rmsd = '{:.3f}'.format(rmsd_test)\n",
    "    bias = '{:.3f}'.format(bias_test)\n",
    "    sdep = '{:.3f}'.format(sdep_test)\n",
    "    \n",
    "    \n",
    "    mse=mean_squared_error(y_test_np, y_pred_test_np)\n",
    "    mse='{:.3f}'.format(mse)\n",
    "    mae=mean_absolute_error(y_test_np, y_pred_test_np)\n",
    "    mae='{:.3f}'.format(mae)\n",
    "    try:\n",
    "        a, b = np.polyfit(y_test_np, y_pred_test_np, 1)\n",
    "        plot_a = '{:.3f}'.format(a[0])\n",
    "        plot_b = '{:.3f}'.format(b[0])\n",
    "    except np.linalg.LinAlgError:\n",
    "        pass\n",
    "        # 'index':np.array(Y_test.index),'ID':np.array(Y_test.index +1),\n",
    "    y_pred_test_np = y_test_pred.squeeze()\n",
    "    csv_df=pd.DataFrame({'index':np.array(Y_test.index),'ID':np.array(Y_test.index +1),'y_true': y_test_np, 'y_pred': y_pred_test_np})\n",
    "    csv_df.to_csv(csv_name,index=None)\n",
    "\n",
    "    csv_df_stats=pd.DataFrame(data=np.array([[resample, r2, rmsd, bias, sdep, plot_a, plot_b, mse, mae]]),\n",
    "                              # index=None, \n",
    "                              columns=['resample','r2','rmsd', 'bias', 'sdep', 'plot_a', 'plot_b', 'mse', 'mae'])\n",
    "    csv_df_stats.to_csv(f'{csv_name[:-4]}_stats.csv',mode='a',index='resample')\n",
    "    \n",
    "    return csv_df\n",
    "\n",
    "\n",
    "\n",
    "set_types = ['train','val','test']\n",
    "# set_type = 'test'\n",
    "# csv_name=f'{directory_path}/{set_type}.csv'\n",
    "# csv_name=f'{set_type}.csv'\n",
    "\n",
    "list_indexes = [train, val, test]\n",
    "index_counter=-1\n",
    "for indexes in list_indexes:\n",
    "    index_counter+=1\n",
    "    csv_name=f'{directory_path}/{set_types[index_counter]}.csv'\n",
    "    y_1,  y_2,  y_3,  y_4,  Y,  X_padded,  X  = load_xy(indexes,desc)\n",
    "    predictions = test_model.predict(X_padded)\n",
    "    csv_df = stats_csv(predictions, Y, prop, csv_name, set_types[index_counter],resample)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7557ed72-4b56-4790-8677-a3b281c351d2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a54c0ab0-88b2-4a1a-b5cc-941f6a14fad0",
   "metadata": {},
   "source": [
    "## Analysis on Resample -> Test, train, val / True vs Predicted (CSV) / Store Stats (CSV). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "id": "bb0f617b-771a-4502-a0e4-63d2fb306739",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/users/qdb16186/CNN_stk/CV/0/4/Granulated/1DConv_st_dH/dH_4.csv'"
      ]
     },
     "execution_count": 340,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# trial_number_fin_model = df_summary.loc[df_summary[f'r2_{prop}_mean'].idxmax()]['trial_id']\n",
    "df_read=pd.read_csv(f'{dir}/{desc}/{model_name}/{prop}_{fold}.csv')\n",
    "df_read\n",
    "f'{dir}/{desc}/{model_name}/{prop}_{fold}.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "id": "e78eb6eb-fe2d-45be-802d-6767a400538d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 344,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prop='Tm'\n",
    "GSHT_list.index(f'{prop}')+1\n",
    "# prop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "id": "c6d75810-2cb4-473c-a1cc-0a1180ff2f43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dH\n",
      "  Unnamed: 0  trial  model_type1  model_type  layer_3_3  layer_2_2  layer_1  \\\n",
      "0          a    NaN          NaN         NaN        NaN        NaN      NaN   \n",
      "\n",
      "   r2_dH_0  rmsd_dH_0  bias_dH_0  ...  layer_2_2  layer_1  r2_dH_4  rmsd_dH_4  \\\n",
      "0      NaN        NaN        NaN  ...        NaN      NaN      NaN        NaN   \n",
      "\n",
      "   bias_dH_4 SDEP_dH_4  gradient_dH_4  b_dH_4  mse_dH_4  mae_dH_4  \n",
      "0        NaN       NaN            NaN     NaN       NaN       NaN  \n",
      "\n",
      "[1 rows x 75 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1706250/748949086.py:37: FutureWarning: The behavior of Series.idxmax with all-NA values, or any-NA and skipna=False, is deprecated. In a future version this will raise ValueError\n",
      "  trial_number_fin_model = df_summary.loc[df_summary[f'r2_{prop}_mean'].idxmax()]['trial_id']\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "nan",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[336], line 37\u001b[0m\n\u001b[1;32m     35\u001b[0m df_summary[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrial_id\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m=\u001b[39mdf_combine[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mUnnamed: 0\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m     36\u001b[0m \u001b[38;5;66;03m#  Find the trial number with the best hyper paramteres\u001b[39;00m\n\u001b[0;32m---> 37\u001b[0m trial_number_fin_model \u001b[38;5;241m=\u001b[39m \u001b[43mdf_summary\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mloc\u001b[49m\u001b[43m[\u001b[49m\u001b[43mdf_summary\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mr2_\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mprop\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m_mean\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43midxmax\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrial_id\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m     39\u001b[0m \u001b[38;5;66;03m# Load best hyper parameters into a dataframe\u001b[39;00m\n\u001b[1;32m     40\u001b[0m best_hps\u001b[38;5;241m=\u001b[39mdf_combine\u001b[38;5;241m.\u001b[39mloc[df_combine[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mUnnamed: 0\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m==\u001b[39mtrial_number_fin_model][df_combine\u001b[38;5;241m.\u001b[39mcolumns[\u001b[38;5;241m2\u001b[39m:\u001b[38;5;241m7\u001b[39m]]\n",
      "File \u001b[0;32m~/.conda/envs/tf/lib/python3.9/site-packages/pandas/core/indexing.py:1153\u001b[0m, in \u001b[0;36m_LocationIndexer.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   1150\u001b[0m axis \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maxis \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m   1152\u001b[0m maybe_callable \u001b[38;5;241m=\u001b[39m com\u001b[38;5;241m.\u001b[39mapply_if_callable(key, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj)\n\u001b[0;32m-> 1153\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_getitem_axis\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmaybe_callable\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.conda/envs/tf/lib/python3.9/site-packages/pandas/core/indexing.py:1393\u001b[0m, in \u001b[0;36m_LocIndexer._getitem_axis\u001b[0;34m(self, key, axis)\u001b[0m\n\u001b[1;32m   1391\u001b[0m \u001b[38;5;66;03m# fall thru to straight lookup\u001b[39;00m\n\u001b[1;32m   1392\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_key(key, axis)\n\u001b[0;32m-> 1393\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_label\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.conda/envs/tf/lib/python3.9/site-packages/pandas/core/indexing.py:1343\u001b[0m, in \u001b[0;36m_LocIndexer._get_label\u001b[0;34m(self, label, axis)\u001b[0m\n\u001b[1;32m   1341\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_get_label\u001b[39m(\u001b[38;5;28mself\u001b[39m, label, axis: AxisInt):\n\u001b[1;32m   1342\u001b[0m     \u001b[38;5;66;03m# GH#5567 this will fail if the label is not present in the axis.\u001b[39;00m\n\u001b[0;32m-> 1343\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mobj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mxs\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlabel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.conda/envs/tf/lib/python3.9/site-packages/pandas/core/generic.py:4236\u001b[0m, in \u001b[0;36mNDFrame.xs\u001b[0;34m(self, key, axis, level, drop_level)\u001b[0m\n\u001b[1;32m   4234\u001b[0m             new_index \u001b[38;5;241m=\u001b[39m index[loc]\n\u001b[1;32m   4235\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 4236\u001b[0m     loc \u001b[38;5;241m=\u001b[39m \u001b[43mindex\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   4238\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(loc, np\u001b[38;5;241m.\u001b[39mndarray):\n\u001b[1;32m   4239\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m loc\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;241m==\u001b[39m np\u001b[38;5;241m.\u001b[39mbool_:\n",
      "File \u001b[0;32m~/.conda/envs/tf/lib/python3.9/site-packages/pandas/core/indexes/range.py:418\u001b[0m, in \u001b[0;36mRangeIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    416\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[1;32m    417\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(key, Hashable):\n\u001b[0;32m--> 418\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key)\n\u001b[1;32m    419\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n\u001b[1;32m    420\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key)\n",
      "\u001b[0;31mKeyError\u001b[0m: nan"
     ]
    }
   ],
   "source": [
    "df_combine = pd.DataFrame()\n",
    "df_summary = pd.DataFrame()\n",
    "df_combine_all = pd.DataFrame()\n",
    "\n",
    "df_combine_all = pd.DataFrame()\n",
    "df_summary = pd.DataFrame()\n",
    "for prop in GSHT_list[0:1]:\n",
    "    print(prop)\n",
    "for fold in range(5):\n",
    "    dir = path_fold(home, resample, fold)\n",
    "    model_name = f\"1DConv_st_{prop}\"\n",
    "    try:\n",
    "        df_read=pd.read_csv(f'{dir}/{desc}/{model_name}/{prop}_{fold}.csv')\n",
    "        # Combine\n",
    "        df_combine=pd.concat([df_combine,df_read],\n",
    "                            axis=1)\n",
    "    except:\n",
    "        pass\n",
    "print(df_combine)    \n",
    "    # count=0\n",
    "df_combine = df_combine.T.drop_duplicates().T\n",
    "stats_list=['r2','rmsd','bias','SDEP','gradient','b','mse','mae']\n",
    "for stat in stats_list:\n",
    "    columns_to_compute = df_combine.filter(regex=f'^{stat}_{prop}')\n",
    "    # print(columns_to_compute)\n",
    "    # Compute mean and std for the specified columns\n",
    "    mean_values = df_combine.filter(regex=f'^{stat}_{prop}').mean(axis=1)\n",
    "    std_values = df_combine.filter(regex=f'^{stat}_{prop}').std(axis=1)\n",
    "    df_combine_all[f'{stat}_{prop}_mean'] = mean_values\n",
    "    df_combine_all[f'{stat}_{prop}_std']  = std_values\n",
    "    if stat == 'r2' or stat =='rmsd':\n",
    "        df_summary[f'{stat}_{prop}_mean'] = mean_values\n",
    "        df_summary[f'{stat}_{prop}_std']  = std_values\n",
    "\n",
    "df_summary['trial_id']=df_combine['Unnamed: 0']\n",
    "#  Find the trial number with the best hyper paramteres\n",
    "trial_number_fin_model = df_summary.loc[df_summary[f'r2_{prop}_mean'].idxmax()]['trial_id']\n",
    "\n",
    "# Load best hyper parameters into a dataframe\n",
    "best_hps=df_combine.loc[df_combine['Unnamed: 0']==trial_number_fin_model][df_combine.columns[2:7]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc36f2a4-32f7-4e22-9ccf-20d38a6f4ae8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "17ccd59a-ee17-46a8-a916-2d96db48d879",
   "metadata": {},
   "source": [
    "# Other"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "836f1c0a-8ca7-45bf-b865-71c5676d8aaa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{}"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "97f759c1-c27e-47b2-a97b-27eb3bd9cb65",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'model_type1': 'CNN1',\n",
       " 'model_type': 'Dense3',\n",
       " 'layer_1': 64.0,\n",
       " 'layer_2_2': 128.0,\n",
       " 'layer_3_3': 64.0}"
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hp.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e6218c7-2211-42c6-94dd-24a038230d39",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a92a8e3b-9576-4e6f-b824-1b0a369c6b04",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02da12e1-0092-480d-a34c-c795b73f3ea4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09ecd03c-6256-4a04-ab25-8aa6ac435bc1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9164be0-31df-4952-84a5-fdbfc0e54190",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "    keyList = ['trial',\n",
    "                 'model_type1',\n",
    "                 'model_type',\n",
    "                     'layer_3_3',\n",
    "                     'layer_2_2',\n",
    "                     'layer_1',\n",
    "               'r2_dH_0','rmsd_dH_0','bias_dH_0','SDEP_dH_0','gradient_dH_0','b_dH_0','mse_dH_0','mae_dH_0',\n",
    "               'r2_dH_1','rmsd_dH_1','bias_dH_1','SDEP_dH_1','gradient_dH_1','b_dH_1','mse_dH_1','mae_dH_1',\n",
    "               'r2_dH_2','rmsd_dH_2','bias_dH_2','SDEP_dH_2','gradient_dH_2','b_dH_2','mse_dH_2','mae_dH_2',\n",
    "               'r2_dH_3','rmsd_dH_3','bias_dH_3','SDEP_dH_3','gradient_dH_3','b_dH_3','mse_dH_3','mae_dH_3',\n",
    "               'r2_dH_4','rmsd_dH_4','bias_dH_4','SDEP_dH_4','gradient_dH_4','b_dH_4','mse_dH_4','mae_dH_4',\n",
    "               'r2_dH_mean','rmsd_dH_mean','bias_dH_mean','SDEP_dH_mean','gradient_dH_mean','b_dH_mean','mse_dH_mean','mae_dH_mean',\n",
    "               'r2_dH_std','rmsd_dH_std','bias_dH_std','SDEP_dH_std','gradient_dH_std','b_dH_std','mse_dH_std','mae_dH_std',\n",
    "               \n",
    "               'r2_dS_0','rmsd_dS_0','bias_dS_0','SDEP_dS_0','gradient_dS_0','b_dS_0','mse_dS_0','mae_dS_0',\n",
    "               'r2_dS_1','rmsd_dS_1','bias_dS_1','SDEP_dS_1','gradient_dS_1','b_dS_1','mse_dS_1','mae_dS_1',\n",
    "               'r2_dS_2','rmsd_dS_2','bias_dS_2','SDEP_dS_2','gradient_dS_2','b_dS_2','mse_dS_2','mae_dS_2',\n",
    "               'r2_dS_3','rmsd_dS_3','bias_dS_3','SDEP_dS_3','gradient_dS_3','b_dS_3','mse_dS_3','mae_dS_3',\n",
    "               'r2_dS_4','rmsd_dS_4','bias_dS_4','SDEP_dS_4','gradient_dS_4','b_dS_4','mse_dS_4','mae_dS_4',\n",
    "               'r2_dS_mean','rmsd_dS_mean','bias_dS_mean','SDEP_dS_mean','gradient_dS_mean','b_dS_mean','mse_dS_mean','mae_dS_mean',\n",
    "               'r2_dS_std','rmsd_dS_std','bias_dS_std','SDEP_dS_std','gradient_dS_std','b_dS_std','mse_dS_std','mae_dS_std',\n",
    "               \n",
    "               'r2_dG_0','rmsd_dG_0','bias_dG_0','SDEP_dG_0','gradient_dG_0','b_dG_0','mse_dG_0','mae_dG_0',\n",
    "               'r2_dG_1','rmsd_dG_1','bias_dG_1','SDEP_dG_1','gradient_dG_1','b_dG_1','mse_dG_1','mae_dG_1',\n",
    "               'r2_dG_2','rmsd_dG_2','bias_dG_2','SDEP_dG_2','gradient_dG_2','b_dG_2','mse_dG_2','mae_dG_2',\n",
    "               'r2_dG_3','rmsd_dG_3','bias_dG_3','SDEP_dG_3','gradient_dG_3','b_dG_3','mse_dG_3','mae_dG_3',\n",
    "               'r2_dG_4','rmsd_dG_4','bias_dG_4','SDEP_dG_4','gradient_dG_4','b_dG_4','mse_dG_4','mae_dG_4',\n",
    "               'r2_dG_mean','rmsd_dG_mean','bias_dG_mean','SDEP_dG_mean','gradient_dG_mean','b_dG_mean','mse_dG_mean','mae_dG_mean',\n",
    "               'r2_dG_std','rmsd_dG_std','bias_dG_std','SDEP_dG_std','gradient_dG_std','b_dG_std','mse_dG_std','mae_dG_std',\n",
    "\n",
    "               'r2_Tm_0','rmsd_Tm_0','bias_Tm_0','SDEP_Tm_0','gradient_Tm_0','b_Tm_0','mse_Tm_0','mae_Tm_0',\n",
    "               'r2_Tm_1','rmsd_Tm_1','bias_Tm_1','SDEP_Tm_1','gradient_Tm_1','b_Tm_1','mse_Tm_1','mae_Tm_1',\n",
    "               'r2_Tm_2','rmsd_Tm_2','bias_Tm_2','SDEP_Tm_2','gradient_Tm_2','b_Tm_2','mse_Tm_2','mae_Tm_2',\n",
    "               'r2_Tm_3','rmsd_Tm_3','bias_Tm_3','SDEP_Tm_3','gradient_Tm_3','b_Tm_3','mse_Tm_3','mae_Tm_3',\n",
    "               'r2_Tm_4','rmsd_Tm_4','bias_Tm_4','SDEP_Tm_4','gradient_Tm_4','b_Tm_4','mse_Tm_4','mae_Tm_4',\n",
    "               'r2_Tm_mean','rmsd_Tm_mean','bias_Tm_mean','SDEP_Tm_mean','gradient_Tm_mean','b_Tm_mean','mse_Tm_mean','mae_Tm_mean',\n",
    "               'r2_Tm_std','rmsd_Tm_std','bias_Tm_std','SDEP_Tm_std','gradient_Tm_std','b_Tm_std','mse_Tm_std','mae_Tm_std',\n",
    "              ]\n",
    "    n = dict(zip(keyList, [None]*len(keyList)))\n",
    "    df_grid=pd.DataFrame(n,index=['a'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53e8eee0-490c-412c-a752-8c8931246018",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4818935-0bfa-4a70-8b4a-fcce677a4f29",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "df=pd.read_csv(\"Lomzov_dataset_IY.csv\")\n",
    "home=os.getcwd()\n",
    "resample=4\n",
    "fold=4\n",
    "train, val, test = access_resample_csv(df,home,resample)\n",
    "train_fold, val_fold, test_fold = access_fold_csv(df,home,resample,fold)\n",
    "\n",
    "y_1_train, y_2_train, y_3_train, y_4_train, Y_train, X_padded_train, X_train = load_xy(train_fold,desc)\n",
    "y_1_val,   y_2_val,   y_3_val,   y_4_val,   Y_val,   X_padded_val,   X_val   = load_xy(val_fold,desc)\n",
    "y_1_test,  y_2_test,  y_3_test,  y_4_test,  Y_test,  X_padded_test,  X_test  = load_xy(test_fold,desc)\n",
    "\n",
    "\n",
    "\n",
    "tunner_path =f\"{dir}/{desc}/{model_name}/tunner\"\n",
    "tuner = kt.GridSearch(build_model,\n",
    "                   objective=kt.Objective('val_loss', 'min'),\n",
    "                    # loss = 'val_loss',\n",
    "                   # objective = ['val_mse','epoch_entropy_pred_mse','val_free_energy_pred_mse'],\n",
    "                  direcddstory=tunner_path,\n",
    "                  overwrite=False,\n",
    "                  project_name=f'{batch}')\n",
    "trial_number='0036'\n",
    "trial=tuner.oracle.get_trial(trial_number)\n",
    "model=tuner.load_model(trial)\n",
    "y_test_pred = model.predict(X_padded_test)\n",
    "# Calc stats and Store predicitons only for the best model\n",
    "y_test_pred\n",
    "Y_test\n",
    "prop\n",
    "\n",
    "r2, rmsd, bias, sdep, plot_a, plot_b, mse, mae = stats_hp(y_test_pred, Y_test, prop)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "e70a0557-3c26-4020-b703-c9cdeff675bd",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0.951'"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "365adc8f-3c14-4bf6-b164-3a9bc1fd0268",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19aa6a02-5bb2-4dd3-9a06-0ae635ce1ce5",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "tuner = kt.GridSearch(build_model,\n",
    "                                   objective=kt.Objective('val_loss', 'min'),\n",
    "                                    # loss = 'val_loss',\n",
    "                                   # objective = ['val_mse','epoch_entropy_pred_mse','val_free_energy_pred_mse'],\n",
    "                                  directory=f'{path}/hyper_param_tunning_tunner_fold_{i_fold}',\n",
    "                                  overwrite=False,\n",
    "                                  project_name=f'{batch}')\n",
    "        # Find all trial number and cycle through them\n",
    "        selection=os.listdir(tuner.project_dir)\n",
    "        for dir_ in selection:\n",
    "            if \"trial_\" not in dir_:\n",
    "                continue\n",
    "            # trial_number='0036'\n",
    "            trial_number=str(dir_.replace(\"trial_\",\"\"))\n",
    "            trial=tuner.oracle.get_trial(trial_number)\n",
    "            model=tuner.load_model(trial)\n",
    "            \n",
    "            y_pred_train_cv = model.predict(x_fold_test)\n",
    "            y_pred_train_cv_enthalpy = y_pred_train_cv[0].squeeze()\n",
    "y_train_resample_output = pd.DataFrame()\n",
    "            y_train_resample_output['ID'] = train_idx[fold_test_index]\n",
    "            # y_train_resample_output['Temp'] = train_resample['Temp']\n",
    "            \n",
    "            y_train_resample_output['y_dH'] = y_fold_test[0]\n",
    "y_train_resample_output[\"y_dH_pred\"]=y_pred_train_cv_enthalpy\n",
    "y_train_resample_output.to_csv(f'{path}/true_pred_fold_{i_fold}_trial_{trial_number}.csv')\n",
    "            for string in GSHT_list:\n",
    "                r2, rmsd, bias, sdep, plot_a, plot_b, mse, mae = stats(y_train_resample_output,string)\n",
    "                if trial_number in df_grid.index:\n",
    "                    n = df_grid.loc[trial_number].to_dict()\n",
    "                # else:\n",
    "                # n = df.loc[trial_number].to_dict() if trial_number in df_grid.index else {}\n",
    "                n.update({\"trial\":trial_number,})\n",
    "                n.update({f'r2_{string}_{i_fold}':r2,f'rmsd_{string}_{i_fold}': rmsd, \n",
    "                          f'bias_{string}_{i_fold}': bias, f'SDEP_{string}_{i_fold}': sdep,\n",
    "                          f'gradient_{string}_{i_fold}': plot_a, f'b_{string}_{i_fold}': plot_b, \n",
    "                          f'mse_{string}_{i_fold}':mse, f'mae_{string}_{i_fold}':mae,})\n",
    "                \n",
    "                original_stdout = sys.stdout \t\n",
    "    \n",
    "                with open('temp.txt', 'w') as f:\n",
    "sys.stdout = f\n",
    "                    # tunner.results_summary(5)\n",
    "                    trial.display_hyperparameters()\n",
    "                    # Reset the standard output\n",
    "                    sys.stdout = original_stdout \n",
    "                f.close\n",
    " data = open('temp.txt', 'r').read()\n",
    "                data_hyp_param=data.replace(': ','\\n').split('\\n')\n",
    "                i_index=0\n",
    "                while i_index+1 < len(data_hyp_param):\n",
    "                    # print(i_index,len(data_hyp_param))\n",
    "                    n.update({data_hyp_param[i_index]:data_hyp_param[i_index+1]})\n",
    "                    i_index+=2\n",
    "                    \n",
    "                df_grid.loc[f'{trial_number}']=n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
